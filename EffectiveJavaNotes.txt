If you have ever studied a second language yourself and then tried to use it
outside the classroom, you know that there are three things you must master: how
the language is structured (grammar), how to name things you want to talk about
(vocabulary), and the customary and effective ways to say everyday things
(usage). Too often only the first two are covered in the classroom, and you find
native speakers constantly suppressing their laughter as you try to make yourself
understood.

It is much the same with a programming language. You need to understand the
core language: is it algorithmic, functional, object-oriented? You need to know the
vocabulary: what data structures, operations, and facilities are provided by the
standard libraries? And you need to be familiar with the customary and effective
ways to structure your code. Books about programming languages often cover
only the first two, or discuss usage only spottily. Maybe that’s because the first
two are in some ways easier to write about. Grammar and vocabulary are properties of the language alone,
but usage is characteristic of a community that uses it.

This book addresses your third need: customary and effective usage. Joshua
Bloch has spent years extending, implementing, and using the Java programming
language at Sun Microsystems; he has also read a lot of other people’s code,
including mine. Here he offers good advice, systematically organized, on how to
structure your code so that it works well, so that other people can understand it, so
that future modifications and improvements are less likely to cause headaches—
perhaps, even, so that your programs will be pleasant, elegant, and graceful.


I still like Java, though my ardor has cooled a bit as the platform has grown.
Given its increased size and complexity, the need for an up-to-date best-practices
guide is all the more critical. With this third edition of Effective Java, I did my
best to provide you with one. I hope this edition continues to satisfy the need,
while staying true to the spirit of the first two editions.
Small is beautiful, but simple ain’t easy.

I naturally think in terms of exported APIs (Application Programming
Interfaces), and I encourage you to do likewise. Even if you aren’t developing
reusable components, thinking in these terms tends to improve the quality of the
software you write


===============================================================================================================
===============================================================================================================
Chapter 1 - Introduction
    This book consists of ninety items, each of which conveys one rule. The rules
    capture practices generally held to be beneficial by the best and most experienced
    programmers

    Feature                             Items               Release
    Lambdas                             Items 42–44         Java 8
    Streams                             Items 45–48         Java 8
    Optionals                           Item 55             Java 8
    Default methods in interfaces       Item 21             Java 8
    try-with-resources                  Item 9              Java 7
    @SafeVarargs                        Item 32             Java 7
    Modules                             Item 15             Java 9

!!!
Most of the rules in this book derive from a few fundamental principles.
Clarity and simplicity are of paramount importance. The user of a component
should never be surprised by its behavior.
Components should be as small as possible but no smaller.
(As used in this book, the term component refers to any reusable software element, from an individual method
to a complex framework consisting of multiple packages.) Code should be reused rather than copied. The
dependencies between components should be kept to a minimum. Errors should
be detected as soon as possible after they are made, ideally at compile time.

!!!
While the rules in this book do not apply 100 percent of the time, they do
characterize best programming practices in the great majority of cases. You
should not slavishly follow these rules, but violate them only occasionally and
with good reason. Learning the art of programming, like most other disciplines,
consists of first learning the rules and then learning when to break them

For the most part, this book uses technical terms as they are defined in The
Java Language Specification, Java SE 8 Edition [JLS]. A few terms deserve
special mention. The language supports four kinds of types: interfaces (including
annotations), classes (including enums), arrays, and primitives. The first three are
known as reference types. Class instances and arrays are objects; primitive values
are not. A class’s members consist of its fields, methods, member classes, and
member interfaces. A method’s signature consists of its name and the types of its
formal parameters; the signature does not include the method’s return type.

This book uses a few terms differently from The Java Language Specification.
Unlike The Java Language Specification, this book uses inheritance as a synonym
for subclassing. Instead of using the term inheritance for interfaces, this book
simply states that a class implements an interface or that one interface extends
another. To describe the access level that applies when none is specified, this book
uses the traditional package-private instead of the technically correct package
access

This book uses a few technical terms that are not defined in The Java Language Specification. The term exported API,
or simply API, refers to the classes, interfaces, constructors, members, and serialized forms by which a programmer
accesses a class, interface, or package.

An exported API consists of the API elements that are accessible outside of the package that defines the API. These are
the API elements that any client can use and the author of the API commits to support

In Java 9, a module system was added to the platform. If a library makes use of
the module system, its exported API is the union of the exported APIs of all the
packages exported by the library’s module declaration.


===============================================================================================================
===============================================================================================================
Chapter 2 - Creating and destroying objects

Item 1 - consider static factory methods instead of constructors

    example:
        public static Boolean valueOf(boolean b) {
            return b ? Boolean.TRUE : Boolean.FALSE;
        }

    !!!
    Note that a static factory method is not the same as the Factory Method pattern from Design Patterns. The
    static factory method described in this item has no direct equivalent in Design Patterns.

Advantages
    + One advantage of static factory methods is that, unlike constructors, they have names.
    A class can have only a single constructor with a given signature (Because they have names, static factory methods
    don’t share the restriction).  In cases where a class seems to require multiple constructors with the same signature,
    replace the constructors with static factory methods and carefully chosen names to highlight their differences.

    + A second advantage of static factory methods is that, unlike constructors, they are not required to create a new
    object each time they’re invoked.
    This technique is similar to the Flyweight pattern. It can greatly improve performance if equivalent
    objects are requested often, especially if they are expensive to create.
    The ability of static factory methods to return the same object from repeated
    invocations allows classes to maintain strict control over what instances exist at
    any time. Classes that do this are said to be instance-controlled. Instance control allows a class to guarantee that
    it is a singleton (Item 3) or noninstantiable (Item 4). Also, it allows an immutable value class (Item 17) to make
    the guarantee that no two equal instances exist: a.equals(b) if and only if a == b. Enum types (Item 34) provide
    this guarantee.

    +A third advantage of static factory methods is that, unlike constructors, they can return an object of any subtype
    of their return type.
    One application of this flexibility is that an API can return objects without making their classes public.
    Furthermore, using such a static factory method requires the client to refer to the returned object by interface
    rather than implementation class, which is generally good practice (Item 64).

    +A fourth advantage of static factories is that the class of the returned object can vary from call to call as a
    function of the input parameters

    +A fifth advantage of static factories is that the class of the returned object need not exist when the class
    containing the method is written.
    Such flexible static factory methods form the basis of service provider frameworks, like the Java
    Database Connectivity API (JDBC). A service provider framework is a system in which providers implement a service,
    and the system makes the implementations available to clients, decoupling the clients from the implementations.

    There are three essential components in a service provider framework: a
    service interface, which represents an implementation; a provider registration
    API, which providers use to register implementations; and a service access API,
    which clients use to obtain instances of the service. The service access API may
    allow clients to specify criteria for choosing an implementation. In the absence of
    such criteria, the API returns an instance of a default implementation, or allows
    the client to cycle through all available implementations. The service access API
    is the flexible static factory that forms the basis of the service provider framework.

    In the case of JDBC, Connection plays the part of the service interface, DriverManager.registerDriver is the
    provider registration API, DriverManager.getConnection is the service access API, and Driver is the service provider
    interface.

Disadvantages
    - The main limitation of providing only static factory methods is that classes without public or protected
    constructors cannot be subclassed.

    -A second shortcoming of static factory methods is that they are hard for programmers to find.

    Often static factories are preferable, so avoid the reflex to provide public constructors without first
    considering static factories.


Item 2 - Consider a builder when faced with many constructor parameters

    A second alternative (first is the Telescope Constructor pattern) when you’re faced with many optional parameters in
    a constructor is the JavaBeans pattern, in which you call a parameterless constructor to create the object and then
    call setter methods to set each required parameter and each optional parameter of interest:

    Unfortunately, the JavaBeans pattern has serious disadvantages of its own.
    Because construction is split across multiple calls, a JavaBean may be in an
    inconsistent state partway through its construction. The class does not have
    the option of enforcing consistency merely by checking the validity of the
    constructor parameters. Attempting to use an object when it’s in an inconsistent
    state may cause failures that are far removed from the code containing the bug and
    hence difficult to debug. A related disadvantage is that the JavaBeans pattern
    precludes the possibility of making a class immutable (Item 17) and requires
    added effort on the part of the programmer to ensure thread safety.

    Luckily, there is a third alternative that combines the safety of the telescoping
    constructor pattern with the readability of the JavaBeans pattern. It is a form of the
    Builder pattern


    (basically the builder pattern that I also worked on in Design patterns project)

    To detect invalid parameters as soon as possible, check parameter validity in the builder’s constructor and methods.
    If a check fails, throw an IllegalArgumentException (Item 72) whose detail message indicates which
    parameters are invalid (Item 75).

    The Builder pattern is well suited to class hierarchies.  (example in the book)

    + A minor advantage of builders over constructors is that builders can have multiple varargs parameters because each parameter is specified in its own method.
    Alternatively, builders can aggregate the parameters passed into multiple calls to a
    method into a single field, as demonstrated in the addTopping method earlier.

    The Builder pattern is quite flexible. A single builder can be used repeatedly
    to build multiple objects. The parameters of the builder can be tweaked between
    invocations of the build method to vary the objects that are created. A builder can
    fill in some fields automatically upon object creation, such as a serial number that
    increases each time an object is created.

    But if you start out with constructors or static factories and switch to a builder when the class evolves to the
    point where the number of parameters gets out of hand, the obsolete constructors or static factories will stick out
    like a sore thumb. Therefore, it’s often better to start with a builder in the first place.

    In summary, the Builder pattern is a good choice when designing classes whose constructors or static
    factories would have more than a handful of parameters, especially if many of the parameters are optional or
    of identical type.


Item 3 - Enforce the singleton property with a private constructor or an enum type

    A singleton is simply a class that is instantiated exactly once [Gamma95]. Singletons typically represent either a
    stateless object such as a function (Item 24) or a system component that is intrinsically unique. Making a class
    a singleton can make it difficult to test its clients because it’s impossible to substitute a mock
    implementation for a singleton unless it implements an interface that serves as its type.

    Presents 3 ways to create a singleton
       Static field
        public class Elvis {
            public static final Elvis INSTANCE = new Elvis();
            private Elvis() { ... }
            public void leaveTheBuilding() { ... }
        }

        + The main advantage of the public field approach is that the API makes it clear
          that the class is a singleton: the public static field is final, so it will always contain
          the same object reference. The second advantage is that it’s simpler.

        Singleton with static factory
       public class Elvis {
           private static final Elvis INSTANCE = new Elvis();
           private Elvis() { ... }
           public static Elvis getInstance() { return INSTANCE; }
           public void leaveTheBuilding() { ... }
       }

    + One advantage of the static factory approach is that it gives you the flexibility
      to change your mind about whether the class is a singleton without changing its
      API. The factory method returns the sole instance, but it could be modified to
      return, say, a separate instance for each thread that invokes it. A second advantage
      is that you can write a generic singleton factory if your application requires it
      (Item 30). A final advantage of using a static factory is that a method reference can
      be used as a supplier, for example Elvis::instance is a Supplier<Elvis>.
      Unless one of these advantages is relevant, the public field approach is preferable.

    // Enum singleton - the preferred approach
    public enum Elvis {
        INSTANCE;
        public void leaveTheBuilding() { ... }
    }

    + This approach is similar to the public field approach, but it is more concise,
      provides the serialization machinery for free, and provides an ironclad guarantee
      against multiple instantiation, even in the face of sophisticated serialization or
      reflection attacks. This approach may feel a bit unnatural, but a single-element
      enum type is often the best way to implement a singleton. Note that you can’t
      use this approach if your singleton must extend a superclass other than Enum
      (though you can declare an enum to implement interfaces).


Item 4 - Enforce non instantiability with a private constructor

    Such utility classes were not designed to be instantiated: an instance would be nonsensical. In the absence of
    explicit constructors, however, the compiler provides a public, parameterless default constructor. To a user, this
    constructor is indistinguishable from any other. It is not uncommon to see unintentionally instantiable classes in
    published APIs.

    Attempting to enforce noninstantiability by making a class abstract does
    not work. The class can be subclassed and the subclass instantiated. Furthermore,
    it misleads the user into thinking the class was designed for inheritance (Item 19).
    There is, however, a simple idiom to ensure noninstantiability. A default constructor is generated only if a class
    contains no explicit constructors, so a class can be made noninstantiable by including a private constructor:

        // Noninstantiable utility class
        public class UtilityClass {
            // Suppress default constructor for noninstantiability
            private UtilityClass() {
                throw new AssertionError();
            }
            ... // Remainder omitted
        }

!!!
    Because the explicit constructor is private, it is inaccessible outside the class.
    The AssertionError isn’t strictly required, but it provides insurance in case the
    constructor is accidentally invoked from within the class. It guarantees the class
    will never be instantiated under any circumstances. This idiom is mildly counterintuitive because the constructor is
    provided expressly so that it cannot be invoked. It is therefore wise to include a comment, as shown earlier


Item 5 - Prefer dependency injection to hardwiring resources

    Many classes depend on one or more underlying resources. For example, a spell
    checker depends on a dictionary. It is not uncommon to see such classes implemented as static utility classes (Item 4):
        // Inappropriate use of static utility - inflexible & untestable!
        public class SpellChecker {
            private static final Lexicon dictionary = ...;
            private SpellChecker() {} // Noninstantiable
            public static boolean isValid(String word) { ... }
            public static List<String> suggestions(String typo) { ... }
        }

    Neither of these approaches is satisfactory, because they assume that there is only one dictionary worth using. In
    practice, each language has its own dictionary, and special dictionaries are used for special vocabularies. Also,
    it may be desirable to use a special dictionary for testing. It is wishful thinking to assume
    that a single dictionary will suffice for all time

    Static utility classes and singletons are inappropriate for classes whose behavior is parameterized by an underlying
    resource.

!!
    A simple pattern that satisfies this requirement is to pass the resource into the constructor when creating a new
    instance. This is one form of dependency injection: the dictionary is a dependency of the spell
    checker and is injected into the spell checker when it is created.
    The dependency injection pattern is so simple that many programmers use it for years without knowing it has a name.
    Dependency injection is equally applicable to constructors, static factories (Item 1), and builders (Item 2).

    A useful variant of the pattern is to pass a resource factory to the constructor.
    A factory is an object that can be called repeatedly to create instances of a type.
    Such factories embody the Factory Method pattern [Gamma95]. The
    Supplier<T> interface, introduced in Java 8, is perfect for representing factories.
    Methods that take a Supplier<T> on input should typically constrain the factory’s
    type parameter using a bounded wildcard type (Item 31) to allow the client to pass
    in a factory that creates any subtype of a specified type. For example, here is a
    method that makes a mosaic using a client-provided factory to produce each tile:

        Mosaic create(Supplier<? extends Tile> tileFactory) { ... }

    This clutter can be all but eliminated by using a dependency injection framework, such as Dagger [Dagger], Guice
    [Guice], or Spring [Spring].

    This practice, known as dependency injection, will greatly enhance the flexibility, reusability, and testability of a class.


Item 6 - Avoid creating unnecessary objects (when you can reuse existing ones)

    As an extreme example of what not to do, consider this statement:
        String s = new String("bikini"); // DON'T DO THIS!
    The statement creates a new String instance each time it is executed, and none
    of those object creations is necessary. The argument to the String constructor
    ("bikini") is itself a String instance, functionally identical to all of the objects
    created by the constructor. If this usage occurs in a loop or in a frequently invoked
    method, millions of String instances can be created needlessly.
    The improved version is simply the following:
        String s = "bikini";
    This version uses a single String instance, rather than creating a new one
    each time it is executed. Furthermore, it is guaranteed that the object will be
    reused by any other code running in the same virtual machine that happens to
    contain the same string literal
!!!
    You can often avoid creating unnecessary objects by using static factory methods (Item 1) in preference to
    constructors on immutable classes that provide both.
    For example, the factory method Boolean.valueOf(String) is preferable to the constructor Boolean(String),
    which was deprecated in Java 9.

    The constructor must create a new object each time it’s called, while the factory method is never
    required to do so and won’t in practice

    Some object creations are much more expensive than others. If you’re going to need such an “expensive object”
    repeatedly, it may be advisable to cache it for reuse. Unfortunately, it’s not always obvious when you’re creating
    such an object..... While String.matches is the easiest way to check if a string matches a regular expression,
    it’s not suitable for repeated use in performance-critical situations. The problem is that it internally creates a
    Pattern instance for the regular expression and uses it only once, after which it becomes eligible for garbage collection.

!!!!
    Another way to create unnecessary objects is autoboxing, which allows the programmer to mix primitive and boxed
    primitive types, boxing and unboxing automatically as needed. Autoboxing blurs but does not erase the distinction
    between primitive and boxed primitive types. There are subtle semantic distinctions and not-so-subtle performance
    differences (Item 61). Consider the following method, which calculates the sum of all the positive int values. To do
    this, the program has to use long arithmetic because an int is not big enough to hold the sum of all the positive int values:
        // Hideously slow! Can you spot the object creation?
        private static long sum() {
            Long sum = 0L;
            for (long i = 0; i <= Integer.MAX_VALUE; i++)
                sum += i;
            return sum;
        }
!!!
    This program gets the right answer, but it is much slower than it should be, due to a one-character typographical error.
    The variable sum is declared as a Long instead of a long, which means that the program constructs about 231 unnecessary
    Long instances (roughly one for each time the long i is added to the Long sum).
    Changing the declaration of sum from Long to long reduces the runtime from 6.3 seconds to 0.59 seconds on my machine.
!!! The lesson is clear: prefer primitives to boxed primitives, and watch out for unintentional autoboxing.

    Conversely, avoiding object creation by maintaining your own object pool is a
    bad idea unless the objects in the pool are extremely heavyweight. The classic
    example of an object that does justify an object pool is a database connection. The
    cost of establishing the connection is sufficiently high that it makes sense to reuse
    these objects. Generally speaking, however, maintaining your own object pools
    clutters your code, increases memory footprint, and harms performance.

    The counterpoint to this item is Item 50 on defensive copying. The present
    item says, “Don’t create a new object when you should reuse an existing one,”
    while Item 50 says, “Don’t reuse an existing object when you should create a new
    one.” Note that the penalty for reusing an object when defensive copying is called
    for is far greater than the penalty for needlessly creating a duplicate object. Failing
    to make defensive copies where required can lead to insidious bugs and security
    holes; creating objects unnecessarily merely affects style and performance.


Item 7 - Eliminate obsolete object references

    If you switched from a language with manual memory management, such as C or C++, to a garbage-collected language
    such as Java, your job as a programmer was made much easier by the fact that your objects are automatically reclaimed when
    you’re through with them. It seems almost like magic when you first experience it. It can easily lead to the
    impression that you don’t have to think about memory management, but this isn’t quite true.

    If an object reference is unintentionally retained, not only is that object excluded from garbage collection, but so
    too are any objects referenced by that object, and so on. Even if only a few object references are unintentionally
    retained, many, many objects may be prevented from being garbage collected, with potentially large effects on performance

    The fix for this sort of problem is simple: null out references once they become obsolete. In the case of our Stack
    class, the reference to an item becomes obsolete as soon as it’s popped off the stack. The corrected version of the pop
    method looks like this:
        public Object pop() {
            if (size == 0)
                throw new EmptyStackException();
            Object result = elements[--size];
            elements[size] = null; // Eliminate obsolete reference
            return result;
        }

!!!!
    When programmers are first stung by this problem, they may overcompensate by nulling out every object reference as
    soon as the program is finished using it.
!!! This is neither necessary nor desirable; it clutters up the program unnecessarily.
    Nulling out object references should be the exception rather than the norm.
    The best way to eliminate an obsolete reference is to let the variable that contained the reference fall out of scope.
    This occurs naturally if you define each variable in the narrowest possible scope (Item 57).

!!!
    So when should you null out a reference? What aspect of a class makes it susceptible to memory leaks?
    Generally speaking, whenever a class manages its own memory, the programmer should be alert for memory leaks. Whenever
    an element is freed, any object references contained in the element should be nulled out.
    Another common source of memory leaks is caches. Once you put an object reference into a cache, it’s easy to forget
    that it’s there and leave it in the cache long after it becomes irrelevant.

    If you’re lucky enough to implement a cache for which an entry is relevant exactly so long as there are references
    to its key outside of the cache, represent the cache as a WeakHashMap; entries will be removed automatically after
    they become obsolete. Remember that WeakHashMap is useful only if the desired lifetime of cache entries is determined
    by external references to the key, not the value.
    More commonly, the useful lifetime of a cache entry is less well defined, with entries becoming less valuable over
    time. Under these circumstances, the cache should occasionally be cleansed of entries that have fallen into disuse.
    This can be done by a background thread (perhaps a ScheduledThreadPoolExecutor) or as a side effect of adding
    new entries to the cache. The LinkedHashMap class facilitates the latter approach with its removeEldestEntry method.

    A third common source of memory leaks is listeners and other callbacks.
    If you implement an API where clients register callbacks but don’t deregister them explicitly, they will accumulate
    unless you take some action. One way to ensure that callbacks are garbage collected promptly is to store only weak
    references to them, for instance, by storing them only as keys in a WeakHashMap.
    Because memory leaks typically do not manifest themselves as obvious failures, they may remain present in a system
    for years. They are typically discovered only as a result of careful code inspection or with the aid of a
    debugging tool known as a heap profiler. Therefore, it is very desirable to learn to
    anticipate problems like this before they occur and prevent them from happening


Item 8 - Avoid finalizers and cleaners

    Finalizers are unpredictable, often dangerous, and generally unnecessary.
    Their use can cause erratic behavior, poor performance, and portability problems.
    Finalizers have a few valid uses, which we’ll cover later in this item, but as a rule,
    you should avoid them. As of Java 9, finalizers have been deprecated, but they are
    still being used by the Java libraries. The Java 9 replacement for finalizers is
    cleaners. Cleaners are less dangerous than finalizers, but still unpredictable,
    slow, and generally unnecessary.

    One shortcoming of finalizers and cleaners is that there is no guarantee they’ll
    be executed promptly [JLS, 12.6]. It can take arbitrarily long between the time
    that an object becomes unreachable and the time its finalizer or cleaner runs. This
    means that you should never do anything time-critical in a finalizer or cleaner.
    For example, it is a grave error to depend on a finalizer or cleaner to close files
    because open file descriptors are a limited resource. If many files are left open as a
    result of the system’s tardiness in running finalizers or cleaners, a program may
    fail because it can no longer open files

    Not only does the specification provide no guarantee that finalizers or
    cleaners will run promptly; it provides no guarantee that they’ll run at all. It is
    entirely possible, even likely, that a program terminates without running them on
    some objects that are no longer reachable. As a consequence, you should never
    depend on a finalizer or cleaner to update persistent state. For example,
    depending on a finalizer or cleaner to release a persistent lock on a shared
    resource such as a database is a good way to bring your entire distributed system
    to a grinding halt.

    Another problem with finalizers is that an uncaught exception thrown during
    finalization is ignored, and finalization of that object terminates [JLS, 12.6].
    Uncaught exceptions can leave other objects in a corrupt state. Normally, an uncaught exception will terminate the
    thread and print a stack trace, but not if it occurs in a finalizer—it won’t even print a warning. Cleaners do
    not have this problem because a library using a cleaner has control over its thread.

    Finalizers have a serious security problem: they open your class up to
    finalizer attacks. The idea behind a finalizer attack is simple: If an exception is
    thrown from a constructor or its serialization equivalents—the readObject and
    readResolve methods (Chapter 12)—the finalizer of a malicious subclass can run
    on the partially constructed object that should have “died on the vine.” This finalizer can record a reference to
    the object in a static field, preventing it from being garbage collected. Once the malformed object has been recorded,
    it is a simple matter to invoke arbitrary methods on this object that should never have been
    allowed to exist in the first place. Throwing an exception from a constructor
    should be sufficient to prevent an object from coming into existence; in the
    presence of finalizers, it is not. Such attacks can have dire consequences. Final
    classes are immune to finalizer attacks because no one can write a malicious
    subclass of a final class. To protect nonfinal classes from finalizer attacks,
    write a final finalize method that does nothing.

!!!
    So what should you do instead of writing a finalizer or cleaner for a class
    whose objects encapsulate resources that require termination, such as files or
    threads? Just have your class implement AutoCloseable, and require its clients
    to invoke the close method on each instance when it is no longer needed,
    typically using try-with-resources to ensure termination even in the face of
    exceptions (Item 9). One detail worth mentioning is that the instance must keep
    track of whether it has been closed: the close method must record in a field that
    the object is no longer valid, and other methods must check this field and throw an
    IllegalStateException if they are called after the object has been closed

    A second legitimate use of cleaners concerns objects with native peers. A
    native peer is a native (non-Java) object to which a normal object delegates via
    native methods. Because a native peer is not a normal object, the garbage collector
    doesn’t know about it and can’t reclaim it when its Java peer is reclaimed. A
    cleaner or finalizer may be an appropriate vehicle for this task, assuming the
    performance is acceptable and the native peer holds no critical resources. If the
    performance is unacceptable or the native peer holds resources that must be
    reclaimed promptly, the class should have a close method, as described earlier

    In summary, don’t use cleaners, or in releases prior to Java 9, finalizers,
    except as a safety net or to terminate noncritical native resources. Even then,
    beware the indeterminacy and performance consequences


Item 9 - Prefer try-with-resources to try-finally

    The Java libraries include many resources that must be closed manually by invoking a close method. Examples include
    InputStream, OutputStream, and java.sql.Connection. Closing resources is often overlooked by clients, with
    predictably dire performance consequences. While many of these resources use
    finalizers as a safety net, finalizers don’t work very well (Item 8).

    Java 7 introduced the try-with-resources statement [JLS, 14.20.3]. To be usable with this construct,
    a resource must implement the AutoCloseable interface, which consists of a
    single void-returning close method. Many classes and interfaces in the Java
    libraries and in third-party libraries now implement or extend AutoCloseable. If
    you write a class that represents a resource that must be closed, your class should
    implement AutoCloseable too

        // try-with-resources - the the best way to close resources!
        static String firstLineOfFile(String path) throws IOException {
            try (BufferedReader br = new BufferedReader(new FileReader(path))) {
                return br.readLine();
            }
        }

    The lesson is clear: Always use try-with-resources in preference to try finally when working with resources that must
    be closed. The resulting code is shorter and clearer, and the exceptions that it generates are more useful.
    The try-with-resources statement makes it easy to write correct code using resources that
    must be closed, which was practically impossible using try-finally



===============================================================================================================
===============================================================================================================
Chapter 3 - Methods common to all objects

This chapter tells you when and how to override the nonfinal Object methods. The finalize method is omitted from this
chapter because it was discussed in Item 8. While not an Object method, Comparable.compareTo is discussed in this
chapter because it has a similar character.


Item 10 - Obey the general contract when overriding "equals"

!!!
    When to not override "equals" ?
         1. Each instance of the class is inherently unique. This is true for classes such
            as Thread that represent active entities rather than values. The equals implementation provided by Object
            has exactly the right behavior for these classes.
        2. There is no need for the class to provide a “logical equality” test. For example, java.util.regex.Pattern
            could have overridden equals to check whether two Pattern instances represented exactly the same regular
            expression, but the designers didn’t think that clients would need or want this functionality. Under these
            circumstances, the equals implementation inherited from Object is ideal.
        3. A superclass has already overridden equals, and the superclass behavior is appropriate for this class. For
            example, most Set implementations inherit their equals implementation from AbstractSet, List implementations from
            AbstractList, and Map implementations from AbstractMap.
        4. The class is private or package-private, and you are certain that its equals method will never be invoked. If
            you are extremely risk-averse, you can override the equals method to ensure that it isn’t invoked accidentally:

                @Override public boolean equals(Object o) {
                    throw new AssertionError(); // Method is never called
                }

!!!
    So when is it appropriate to override equals? It is when a class has a notion of logical equality that differs from
    mere object identity and a superclass has not already overridden equals. This is generally the case for "value
    classes". A "value class" is simply a class that represents a value, such as Integer or String. A
    programmer who compares references to value objects using the equals method expects to find out whether they are
    logically equivalent, not whether they refer to the same object. Not only is overriding the equals method necessary
    to satisfy programmer expectations, it enables instances to serve as map keys or set elements with predictable,
    desirable behavior.

    One kind of value class that does not require the equals method to be overridden is a class that uses instance
    control (Item 1) to ensure that at most one object exists with each value. Enum types (Item 34) fall into this
    category. For these classes, logical equality is the same as object identity, so Object’s equals method
    functions as a logical equals method.

!!!!!!!!
    When you override the equals method, you must adhere to its general contract. Here is the contract, from the
    specification for Object :
    The equals method implements an equivalence relation. It has these properties:
        • Reflexive: For any non-null reference value x, x.equals(x) must return true.
        • Symmetric: For any non-null reference values x and y, x.equals(y) must return true if and only if
            y.equals(x) returns true.
        • Transitive: For any non-null reference values x, y, z, if x.equals(y) returns true and y.equals(z) returns
            true, then x.equals(z) must return true.
        • Consistent: For any non-null reference values x and y, multiple invocations of x.equals(y) must consistently
            return true or consistently return false, provided no information used in equals comparisons is modified.
        • For any non-null reference value x, x.equals(null) must return false.

    Reflexivity—The first requirement says merely that an object must be equal to itself. It’s hard to imagine
    violating this one unintentionally. If you were to violate it and then add an instance of your class to a collection,
    the contains method might well say that the collection didn’t contain the instance that you just added.

    Symmetry—The second requirement says that any two objects must agree on whether they are equal. Unlike the first
    requirement, it’s not hard to imagine violating this one unintentionally

!!! Once you’ve violated the equals contract, you simply don’t know how other objects will behave when confronted with
    your object.

    Transitivity—The third requirement of the equals contract says that if one object is equal to a second and the
    second object is equal to a third, then the first object must be equal to the third. Again, it’s not hard to
    imagine violating this requirement unintentionally

        (in the book an example is present where problems might occur concerning transitivity - at the inheritance
        of instantiable classes that are extended by other classes which also add important value fields (that should
        be taken into consideration when doing equals)...only solution in these cases is presented below...basically do
        composition not inheritance..)

        While there is no satisfactory way to extend an instantiable class and add a value component, there is a fine
        workaround: Follow the advice of Item 18, “Favor composition over inheritance.” Instead of having ColorPoint
        extend Point, give ColorPoint a private Point field and a public view method (Item 6)
        that returns the point at the same position as this color point:

        Note that you can add a value component to a subclass of an abstract class
        without violating the equals contract. This is important for the sort of class hierarchies that you get by
        following the advice in Item 23, “Prefer class hierarchies to tagged classes.” For example, you could have an
        abstract class Shape with no value components, a subclass Circle that adds a radius field, and a subclass
        Rectangle that adds length and width fields. Problems of the sort shown earlier
        won’t occur so long as it is impossible to create a superclass instance directly.

    Consistency—The fourth requirement of the equals contract says that if two objects are equal, they must remain
    equal for all time unless one (or both) of them is modified. In other words, mutable objects can be equal to
    different objects at different times while immutable objects can’t. When you write a class, think hard
    about whether it should be immutable (Item 17). If you conclude that it should, make sure that your equals method
    enforces the restriction that equal objects remain equal and unequal objects remain unequal for all time

        For example, java.net.URL’s equals method relies on comparison of the IP addresses of the hosts associated
        with the URLs. Translating a host name to an IP address can require network access, and it isn’t guaranteed to
        yield the same results over time. This can cause the URL equals method to violate the equals contract and has
        caused problems in practice. The behavior of URL’s equals method was a big mistake and should not
        be emulated. Unfortunately, it cannot be changed due to compatibility requirements. To avoid this sort of
        problem, equals methods should perform only deterministic computations on memory-resident objects.

    Non-nullity—The final requirement lacks an official name, so I have taken the liberty of calling it “non-nullity.”
    It says that all objects must be unequal to null.

!!!!!!!!!
    Putting it all together, here’s a recipe for a high-quality equals method:
        1. Use the == operator to check if the argument is a reference to this object.
            If so, return true. This is just a performance optimization but one that is worth doing if the comparison is
            potentially expensive.
        2. Use the instanceof operator to check if the argument has the correct type.
            If not, return false. Typically, the correct type is the class in which the method occurs. Occasionally, it
            is some interface implemented by this class. Use an interface if the class implements an interface that
            refines the equals contract to permit comparisons across classes that implement the interface. Collection
            interfaces such as Set, List, Map, and Map.Entry have this property.
        3. Cast the argument to the correct type. Because this cast was preceded by an instanceof test, it is guaranteed
            to succeed.
        4. For each “significant” field in the class, check if that field of the argument matches the corresponding field
            of this object. If all these tests succeed, return true; otherwise, return false. If the type in Step 2 is
            an interface, you must access the argument’s fields via interface methods; if the type is a class,
            you may be able to access the fields directly, depending on their accessibility.
        !!!!!!
            For primitive fields whose type is not float or double, use the == operator for comparisons; for object
            reference fields, call the "equals" method recursively; for float fields, use the static
            Float.compare(float, float) method; and for double fields, use Double.compare(double, double).
            For array fields, apply these guidelines to each element. If every element in an array field is significant,
            use one of the Arrays.equals methods
            Some object reference fields may legitimately contain null. To avoid the
            possibility of a NullPointerException, check such fields for equality using
            the static method Objects.equals(Object, Object).
        !!!
            The performance of the equals method may be affected by the order in which
            fields are compared. For best performance, you should first compare fields that
            are more likely to differ, less expensive to compare, or, ideally, both.

            You need not compare derived fields, which can be calculated from “significant fields,” but doing so may
            improve the performance of the equals method. If a derived field amounts to a summary description of the
            entire object, comparing this field will save you the expense of comparing the actual data if the comparison
            fails. For example, suppose you have a Polygon class, and you cache the area. If two polygons
            have unequal areas, you needn’t bother comparing their edges and vertices.

    When you are finished writing your equals method, ask yourself three questions:
    Is it symmetric? Is it transitive? Is it consistent?
    And don’t just ask yourself; write unit tests to check, unless you used AutoValue (page 49) to generate your
    equals method, in which case you can safely omit the tests.

!!!!!
    Writing and testing equals (and hashCode) methods is tedious, and the resulting code is mundane. An excellent
    alternative to writing and testing these methods manually is to use Google’s open source AutoValue framework,
    which automatically generates these methods for you, triggered by a single annotation on the
    class . In most cases, the methods generated by AutoValue are essentially identical to those you’d write yourself.
!!!!
    IDEs, too, have facilities to generate equals and hashCode methods, but the resulting source code is more verbose
    and less readable than code that uses AutoValue, does not track changes in the class automatically, and therefore
    requires testing. That said, having IDEs generate equals (and hashCode) methods is generally preferable to
    implementing them manually because IDEs do not make careless mistakes, and humans do.


Item 11 - Always override hashCode when you override equals

    You must override hashCode in every class that overrides equals. If you fail to do so, your class will violate the
    general contract for hashCode, which will prevent it from functioning properly in collections such as HashMap and
    HashSet.
    Here is the contract, adapted from the Object specification :
!!!!
        • When the hashCode method is invoked on an object repeatedly during an execution of an application, it must
            consistently return the same value, provided no information used in equals comparisons is modified. This value
            need not remain consistent from one execution of an application to another.
        • If two objects are equal according to the equals(Object) method, then calling hashCode on the two objects must
            produce the same integer result.
        • If two objects are unequal according to the equals(Object) method, it is not required that calling hashCode
            on each of the objects must produce distinct results. However, the programmer should be aware that producing
            distinct results for unequal objects may improve the performance of hash tables.

    The key provision that is violated when you fail to override hashCode is the second one: equal objects must have
    equal hash codes

        // The worst possible legal hashCode implementation - never use!
        @Override
        public int hashCode() { return 42; }
    It’s legal because it ensures that equal objects have the same hash code. It’s
    atrocious because it ensures that every object has the same hash code. Therefore,
    every object hashes to the same bucket, and hash tables degenerate to linked lists.
    Programs that should run in linear time instead run in quadratic time. For large
    hash tables, this is the difference between working and not working

    Here is a simple recipe:
    1. Declare an int variable named result, and initialize it to the hash code c for the first significant field in
    your object, as computed in step 2.a. (Recall from Item 10 that a significant field is a field that affects equals
    comparisons.)
    2. For every remaining significant field f in your object, do the following:
        a. Compute an int hash code c for the field:
            i. If the field is of a primitive type, compute Type.hashCode(f), where Type is the boxed primitive class
            corresponding to f’s type.
            ii. If the field is an object reference and this class’s equals method compares the field by recursively
            invoking equals, recursively invoke hashCode on the field. If a more complex comparison is required, compute
            a “canonical representation” for this field and invoke hashCode on the canonical representation. If the value
             of the field is null, use 0 (or some other constant, but 0 is traditional).
            iii. If the field is an array, treat it as if each significant element were a separate field. That is, compute
             a hash code for each significant element by applying these rules recursively, and combine the values
            per step 2.b. If the array has no significant elements, use a constant,  preferably not 0. If all elements are
            significant, use Arrays.hashCode.
        b. Combine the hash code c computed in step 2.a into result as follows:
             result = 31 * result + c;
    3. Return result.

    You must exclude any fields that are not used in equals comparisons, or you risk violating the second provision of
    the hashCode contract.
!!!
        // Typical hashCode method
        @Override public int hashCode() {
            int result = Short.hashCode(areaCode);
            result = 31 * result + Short.hashCode(prefix);
            result = 31 * result + Short.hashCode(lineNum);
            return result;
        }

    This method is, in fact, a perfectly good hashCode implementation for PhoneNumber, on par with
    those in the Java platform libraries. It is simple, is reasonably fast, and does a reasonable job of dispersing
    unequal phone numbers into different hash buckets.

!!!
    The Objects class has a static method that takes an arbitrary number of
    objects and returns a hash code for them. This method, named hash, lets you write
    one-line hashCode methods whose quality is comparable to those written according to the recipe in this item.
    Unfortunately, they run more slowly because they entail array creation to pass a variable number of arguments, as
    well as boxing and unboxing if any of the arguments are of primitive type. This style of hash function
    is recommended for use only in situations where performance is not critical. Here
    is a hash function for PhoneNumber written using this technique:

        // One-line hashCode method - mediocre performance
        @Override public int hashCode() {
            return Objects.hash(lineNum, prefix, areaCode);
        }

    If a class is immutable and the cost of computing the hash code is significant,
    you might consider caching the hash code in the object rather than recalculating it
    each time it is requested. If you believe that most objects of this type will be used
    as hash keys, then you should calculate the hash code when the instance is created.

        // hashCode method with lazily initialized cached hash code
        private int hashCode; // Automatically initialized to 0
        @Override public int hashCode() {
            int result = hashCode;
            if (result == 0) {
                result = Short.hashCode(areaCode);
                result = 31 * result + Short.hashCode(prefix);
                result = 31 * result + Short.hashCode(lineNum);
                hashCode = result;
            }
            return result;
        }

!!!
    Do not be tempted to exclude significant fields from the hash code computation to improve performance. While the
    resulting hash function may run faster, its poor quality may degrade hash tables’ performance to the point where
    they become unusable.

    As mentioned in Item 10, the AutoValue framework provides a fine alternative to writing equals and hashCode methods
    manually, and IDEs also provide some of this functionality.


Item 12 - Always override toString

    The general contract for toString says that the returned string should be “a concise but informative representation
    that is easy for a person to read.” While it could be argued that PhoneNumber@163b91 is concise and easy to read,
    it isn’t very informative when compared to 707-867-5309. The toString contract goes on to say, “It is recommended
    that all subclasses override this method.” Good advice, indeed!

!!! While it isn’t as critical as obeying the equals and hashCode contracts (Items 10 and 11), providing a good toString
    implementation makes your class much more pleasant to use and makes systems using the class easier to debug.
    The toString method is automatically invoked when an object is passed to println, printf, the string concatenation
    operator, or assert, or is printed by a debugger.

    When practical, the toString method should return all of the interesting information contained in the object, as
    shown in the phone number example. It is impractical if the object is large or if it contains state that is not
    conducive to string representation. Under these circumstances, toString should return a summary such as Manhattan
    residential phone directory (1487536 listings) or Thread[main,5,main].
    Ideally, the string should be self-explanatory. (The Thread example flunks this test.)

    Whether or not you decide to specify the format, you should clearly document your intentions.
        (aka put a nice comment explaining what the values returned by toString mean in a comment on the method)

        /**
        * Returns a brief description of this potion. The exact details
        * of the representation are unspecified and subject to change,
        * but the following may be regarded as typical:
        *
        * "[Potion #9: type=love, smell=turpentine, look=india ink]"
        */
        @Override
        public String toString() { ... }

    Google’s open source AutoValue facility, discussed in Item 10, will generate a toString method for you, as will
    most IDEs. These methods are great for telling you the contents of each field but aren’t specialized to the meaning
    of the class.


Item 13 - Override clone judiciously  (with good judgement or sense.)

    This item tells you how to implement a well-behaved clone method, discusses when it is appropriate to do so, and
    presents alternatives.
!!
    So what does Cloneable do, given that it contains no methods? It determines the behavior of Object’s protected clone
    implementation: if a class implements Cloneable, Object’s clone method returns a field-by-field copy of the object;
    otherwise it throws CloneNotSupportedException. This is a highly atypical use of interfaces and not one to be emulated.
    Normally, implementing an interface says something about what a class can do for its clients. In this case, it modifies
    the behavior of a protected method on a superclass.

!!!
    Though the specification doesn’t say it, in practice, a class implementing Cloneable is expected to provide a
    properly functioning public clone method. In order to achieve this, the class and all of its superclasses must obey
    a complex, unenforceable, thinly documented protocol. The resulting mechanism is fragile, dangerous, and
    extralinguistic: it creates objects without calling a constructor.

    immutable classes should never provide a clone method because it would merely encourage wasteful copying.

            // Clone method for class with no references to mutable state
            @Override public PhoneNumber clone() {
                try {
                    return (PhoneNumber) super.clone();
                } catch (CloneNotSupportedException e) {
                    throw new AssertionError(); // Can't happen
                }
            }

    In order for this method to work, the class declaration for PhoneNumber would have to be modified to indicate that
    it implements Cloneable. Though Object’s clone method returns Object, this clone method returns PhoneNumber. It is legal
    and desirable to do this because Java supports covariant return types. In other words, an overriding method’s return
    type can be a subclass of the overridden method’s return type. This eliminates the need for casting in the client.

    The call to super.clone is contained in a try-catch block. This is because Object declares its clone method to
    throw CloneNotSupportedException, which is a checked exception. Because PhoneNumber implements Cloneable, we
    know the call to super.clone will succeed. The need for this boilerplate indicates that CloneNotSupportedException
    should have been unchecked (Item 71).

        // Clone method for class with references to mutable state
        @Override public Stack clone() {
            try {
                Stack result = (Stack) super.clone();
                result.elements = elements.clone();
                return result;
            } catch (CloneNotSupportedException e) {
            throw new AssertionError();
            }
        }

    This is the preferred idiom to duplicate an array. In fact, arrays are the sole compelling use of the clone facility.

    Note also that the earlier solution would not work if the elements field were final because clone would be prohibited
    from assigning a new value to the field. This is a fundamental problem: like serialization, the Cloneable architecture is
    incompatible with normal use of final fields referring to mutable objects, except in cases where the mutable objects
    may be safely shared between an object and its clone.

!!!
    Object’s clone method is declared to throw CloneNotSupportedException,  but overriding methods need not. Public
    clone methods should omit the throws clause, as methods that don’t throw checked exceptions are easier to use (Item 71).

    To recap, all classes that implement Cloneable should override clone with a public method whose return type is the
    class itself. This method should first call super.clone, then fix any fields that need fixing. Typically, this means
    copying any mutable objects that comprise the internal “deep structure” of the object and
    replacing the clone’s references to these objects with references to their copies
!!!
    Is all this complexity really necessary? Rarely. If you extend a class that already implements Cloneable, you have
    little choice but to implement a wellbehaved clone method. Otherwise, you are usually better off providing an
    alternative means of object copying. A better approach to object copying is to
    provide a copy constructor or copy factory. A copy constructor is simply a constructor that takes a single argument
    whose type is the class containing the constructor, for example,

    // Copy constructor
    public Yum(Yum yum) { ... };

    A copy factory is the static factory (Item 1) analogue of a copy constructor:
    // Copy factory
    public static Yum newInstance(Yum yum) { ... };
!!
    The copy constructor approach and its static factory variant have many advantages over Cloneable/clone: they don’t
    rely on a risk-prone extralinguistic object creation mechanism; they don’t demand unenforceable adherence to thinly
    documented conventions; they don’t conflict with the proper use of final fields;
    they don’t throw unnecessary checked exceptions; and they don’t require casts.
    Furthermore, a copy constructor or factory can take an argument whose type is an interface implemented by the class.
    Interface-based copy constructors and factories, more properly known as conversion constructors and conversion
    factories, allow the client to choose the implementation type of the copy rather than forcing the client
    to accept the implementation type of the original.
!!!
    Given all the problems associated with Cloneable, new interfaces should not extend it, and new extendable classes
    should not implement it. While it’s less harmful for final classes to implement Cloneable, this should be viewed as
    a performance optimization, reserved for the rare cases where it is justified (Item 67).
    As a rule, copy functionality is best provided by constructors or factories. A notable exception to this rule is
    arrays, which are best copied with the clone method.


Item 14 - Consider implementing Comparable

    Unlike the other methods discussed in this chapter, the compareTo method is not declared in Object. Rather, it is
    the sole method in the Comparable interface. It is similar in character to Object’s equals method, except that it
    permits order comparisons in addition to simple equality comparisons, and it is generic. By implementing Comparable,
    a class indicates that its instances have a natural ordering.
    Sorting an array of objects that implement Comparable is as simple as this:
        Arrays.sort(a);

    It is similarly easy to search, compute extreme values, and maintain automatically sorted collections of Comparable
    objects.

!!!!
    By implementing Comparable, you allow your class to interoperate with all of the many generic algorithms and
    collection implementations that depend on this interface. You gain a tremendous amount of power for a small amount
    of effort. Virtually all of the value classes in the Java platform libraries, as well as all enum
    types (Item 34), implement Comparable. If you are writing a value class with an obvious natural ordering, such as
    alphabetical order, numerical order, or chronological order, you should implement the Comparable interface:
        public interface Comparable<T> {
            int compareTo(T t);
        }

    The general contract of the compareTo method is similar to that of equals:
    In the following description, the notation sgn(expression) designates the mathematical signum function, which is
    defined to return -1, 0, or 1, according to whether the value of expression is negative, zero, or positive.
        • The implementor must ensure that sgn(x.compareTo(y)) == -sgn(y.compareTo(x)) for all x and y. (This implies
            that x.compareTo(y) must throw an exception if and only if y.compareTo(x) throws an exception.)
        • The implementor must also ensure that the relation is transitive: (x.compareTo(y) > 0 && y.compareTo(z) > 0)
            implies x.compareTo(z) > 0.
        • Finally, the implementor must ensure that x.compareTo(y) == 0 implies that sgn(x.compareTo(z)) == sgn(y.compareTo(z)),
            for all z.
        • It is strongly recommended, but not required, that (x.compareTo(y) == 0) == (x.equals(y)). Generally speaking,
            any class that implements the Comparable interface and violates this condition should clearly indicate this
            fact. The recommended language is “Note: This class has a natural ordering that is inconsistent with equals.”

    Unlike the equals method, which imposes a global equivalence relation on all objects, compareTo
    doesn’t have to work across objects of different types: when confronted with objects of different types, compareTo
    is permitted to throw ClassCastException.
    Usually, that is exactly what it does. The contract does permit intertype comparisons, which are typically defined in
    an interface implemented by the objects being compared.

!!! One consequence of these three provisions is that the equality test imposed by a compareTo method must obey the
    same restrictions imposed by the equals contract: reflexivity, symmetry, and transitivity.
    Therefore, the same caveat applies: there is no way to extend an instantiable class with a new value component while
    preserving the compareTo contract, unless you are willing to forgo the benefits of object-oriented abstraction
    (Item 10). The same workaround applies, too. If you want to add a value component to a class that implements
    Comparable, don’t extend it; write an unrelated class containing an instance of the first class. Then
    provide a “view” method that returns the contained instance. This frees you to implement whatever compareTo method
    you like on the containing class, while allowing its client to view an instance of the containing class as an instance
    of the contained class when needed.

!!!
    The final paragraph of the compareTo contract, which is a strong suggestion rather than a true requirement, simply
    states that the equality test imposed by the  compareTo method should generally return the same results as the equals
    method. If this provision is obeyed, the ordering imposed by the compareTo method is said to be consistent with equals.
    If it’s violated, the ordering is said to be inconsistent with equals. A class whose compareTo method imposes an order
    that is inconsistent with equals will still work, but sorted collections containing elements of the class may not
    obey the general contract of the appropriate collection interfaces (Collection, Set, or Map). This is because the
    general contracts for these interfaces are defined in terms of the equals method, but sorted collections use the
    equality test imposed by compareTo in place of equals. It is not a catastrophe if this happens, but it’s something
    to be aware of.
        For example, consider the BigDecimal class, whose compareTo method is
        inconsistent with equals. If you create an empty HashSet instance and then add
        new BigDecimal("1.0") and new BigDecimal("1.00"), the set will contain two
        elements because the two BigDecimal instances added to the set are unequal
        when compared using the equals method. If, however, you perform the same
        procedure using a TreeSet instead of a HashSet, the set will contain only one
        element because the two BigDecimal instances are equal when compared using
        the compareTo method. (See the BigDecimal documentation for details.)

    In a compareTo method, fields are compared for order rather than equality. To compare object reference fields,
    invoke the compareTo method recursively. If a field does not implement Comparable or you need a nonstandard ordering,
    use a Comparator instead.
        // Single-field Comparable with object reference field
        public final class CaseInsensitiveString implements Comparable<CaseInsensitiveString> {
            public int compareTo(CaseInsensitiveString cis) {
                return String.CASE_INSENSITIVE_ORDER.compare(s, cis.s);
            }
            // Remainder omitted
        }

!!! Use of the relational operators < and > in compareTo methods is verbose and error-prone and no longer recommended.

!!!! If a class has multiple significant fields, the order in which you compare them is critical.
    Start with the most significant field and work your way down. If a comparison results in anything other than zero
    (which represents equality), you’re done; just return the result. If the most significant field is equal, compare
    the next most-significant field, and so on, until you find an unequal field or compare the least significant field.

    In Java 8, the Comparator interface was outfitted with a set of comparator
    construction methods, which enable fluent construction of comparators. These
    comparators can then be used to implement a compareTo method, as required by
    the Comparable interface. Many programmers prefer the conciseness of this
    approach, though it does come at a modest performance cost: sorting arrays of
    PhoneNumber instances is about 10% slower on my machine.

    // Comparable with comparator construction methods
    private static final Comparator<PhoneNumber> COMPARATOR = comparingInt((PhoneNumber pn) -> pn.areaCode)
        .thenComparingInt(pn -> pn.prefix)
        .thenComparingInt(pn -> pn.lineNum);

    public int compareTo(PhoneNumber pn) {
        return COMPARATOR.compare(this, pn);
    }

    There are also comparator construction methods for object reference types. The static method, named comparing, has
    two overloadings. One takes a key extractor and uses the keys’ natural order. The second takes both a key extractor
    and a comparator to be used on the extracted keys. There are three overloadings of the instance method, which is
    named thenComparing. One overloading takes only a comparator and uses it to provide a secondary order. A second
    overloading takes only a key extractor and uses the key’s natural order as a secondary order. The final overloading
    takes both a key extractor and a comparator to be used on the extracted keys.

    In summary, whenever you implement a "value class" that has a sensible ordering, you should have the class implement
    the Comparable interface so that its instances can be easily sorted, searched, and used in comparison-based
    collections. When comparing field values in the implementations of the compareTo methods, avoid the use of the
    < and > operators. Instead, use the static compare methods in the boxed primitive classes or the comparator
    construction methods in the Comparator interface


===============================================================================================================
===============================================================================================================
Chapter 4 - Classes and interfaces

Item 15 - Minimize the accessibility of classes and members

    The single most important factor that distinguishes a well-designed component
    from a poorly designed one is the degree to which the component hides its internal
    data and other implementation details from other components. A well-designed
    component hides all its implementation details, cleanly separating its API from its
    implementation. Components then communicate only through their APIs and are
    oblivious to each others’ inner workings. This concept, known as information
    hiding or encapsulation, is a fundamental tenet of software design.
!!!
    Information hiding is important for many reasons, most of which stem from
    the fact that it decouples the components that comprise a system, allowing them to
    be developed, tested, optimized, used, understood, and modified in isolation. This
    speeds up system development because components can be developed in parallel.
!!!
    The rule of thumb is simple: make each class or member as inaccessible as
    possible. In other words, use the lowest possible access level consistent with the
    proper functioning of the software that you are writing.

    If you declare a top-level class or interface with the public modifier, it will be public; otherwise, it will
    be package-private. If a top-level class or interface can be made package-private, it should be.
    By making it package-private, you make it part of the implementation rather than the exported API, and you can
    modify it, replace it, or eliminate it in a subsequent release without fear of harming existing clients. If you
    make it public, you are obligated to support it forever to maintain compatibility.

    If a package-private top-level class or interface is used by only one class, consider making the top-level class a
    private static nested class of the sole class that uses it (Item 24)

    For members (fields, methods, nested classes, and nested interfaces), there are four possible access levels,
    listed here in order of increasing accessibility:
    • private—The member is accessible only from the top-level class where it is declared.
    • package-private—The member is accessible from any class in the package where it is declared. Technically known
        as default access, this is the access level you get if no access modifier is specified (except for interface
        members, which are public by default).
    • protected—The member is accessible from subclasses of the class where it is declared (subject to a few
        restrictions [JLS, 6.6.2]) and from any class in the package where it is declared.
    • public—The member is accessible from anywhere.

    After carefully designing your class’s public API, your reflex should be to make all other members private.

    A protected member is part of the class’s exported API and must be supported forever. Also, a protected
    member of an exported class represents a public commitment to an implementation detail (Item 19). The need for
    protected members should be relatively rare
!!!!
    To facilitate testing your code, you may be tempted to make a class, interface, or member more accessible than
    otherwise necessary. This is fine up to a point. It is acceptable to make a private member of a public class
    package-private in order to test it, but it is not acceptable to raise the accessibility any higher. In other
    words, it is not acceptable to make a class, interface, or member a part of a package’s exported API to
    facilitate testing. Luckily, it isn’t necessary either because tests can be made to run as part of the package
    being tested, thus gaining access to its package-private elements.

!!!
    Instance fields of public classes should rarely be public (Item 16). If an instance field is nonfinal or is a
    reference to a mutable object, then by making it public, you give up the ability to limit the values that can be
    stored in the field.
    Even if a field is final and refers to an immutable object, by making it public you give up the flexibility
    to switch to a new internal data representation in which the field does not exist.
!!!
    The same advice applies to static fields, with one exception. You can expose constants via public static final
    fields, assuming the constants form an integral part of the abstraction provided by the class. By convention,
    such fields have names consisting of capital letters, with words separated by underscores (Item 68). It is
    critical that these fields contain either primitive values or references to immutable objects (Item 17). a field
    containing a reference to a mutable object has all the disadvantages of a nonfinal field. While the reference
    cannot be modified, the referenced object can be modified—with disastrous results.

    Note that a nonzero-length array is always mutable, so it is wrong for a class to have a public static final array
    field, or an accessor that returns such a field. If a class has such a field or accessor, clients will be able to
    modify the contents of the array. This is a frequent source of security holes:
        // Potential security hole!
        public static final Thing[] VALUES = { ... };
    You can make the public array private and add a public immutable list:
        private static final Thing[] PRIVATE_VALUES = { ... };
        public static final List<Thing> VALUES = Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES));

    As of Java 9, there are two additional, implicit access levels introduced as part of the module system. A module
    is a grouping of packages, like a package is a grouping of classes. A module may explicitly export some of its
    packages via export declarations in its module declaration (which is by convention contained in
    a source file named module-info.java). Public and protected members of unexported packages in a module are
    inaccessible outside the module;
    It is too early to say whether modules will achieve widespread use outside of the JDK itself. In the meantime, it
    seems best to avoid them unless you have a compelling need.

    To summarize, you should reduce accessibility of program elements as much
    as possible (within reason). After carefully designing a minimal public API, you
    should prevent any stray classes, interfaces, or members from becoming part of
    the API. With the exception of public static final fields, which serve as constants,
    public classes should have no public fields. Ensure that objects referenced by
    public static final fields are immutable.


Item 16 - In public classes use accessor methods not public fields

    Because the data fields of such classes are accessed directly, these classes do not offer the benefits of
    encapsulation (Item 15). You can’t change the representation without changing the API, you can’t enforce invariants,
    and you can’t take auxiliary action when a field is accessed.

    However, if a class is package-private or is a private nested class, there is nothing inherently wrong with exposing
    its data fields—assuming they do an adequate job of describing the abstraction provided by the class.

    In summary, public classes should never expose mutable fields. It is less
    harmful, though still questionable, for public classes to expose immutable fields.
    It is, however, sometimes desirable for package-private or private nested classes to
    expose fields, whether mutable or immutable.


Item 17 - Minimize mutability

    An immutable class is simply a class whose instances cannot be modified. All of
    the information contained in each instance is fixed for the lifetime of the object, so
    no changes can ever be observed. The Java platform libraries contain many
    immutable classes, including String, the boxed primitive classes...Immutable classes are easier to design,
    implement, and use than mutable classes. They are less prone to error and are more secure.

    To make a class immutable, follow these five rules:
        1. Don’t provide methods that modify the object’s state (known as mutators).
        2. Ensure that the class can’t be extended. This prevents careless or malicious
            subclasses from compromising the immutable behavior of the class by
            behaving as if the object’s state has changed. Preventing subclassing is
            generally accomplished by making the class final, but there is an alternative that we’ll discuss later.
        3. Make all fields final. This clearly expresses your intent in a manner that is enforced by the system.
            Also, it is necessary to ensure correct behavior if a reference to a newly created instance is passed from
            one thread to another without synchronization, as spelled out in the memory model.
        4. Make all fields private. This prevents clients from obtaining access to
            mutable objects referred to by fields and modifying these objects directly.
            While it is technically permissible for immutable classes to have public final
            fields containing primitive values or references to immutable objects, it is not
            recommended because it precludes changing the internal representation in a
            later release (Items 15 and 16).
        5. Ensure exclusive access to any mutable components. If your class has any
            fields that refer to mutable objects, ensure that clients of the class cannot obtain
            references to these objects. Never initialize such a field to a client-provided
            object reference or return the field from an accessor. Make defensive copies
            (Item 50) in constructors, accessors, and readObject methods (Item 88).

    Immutable objects are simple. An immutable object can be in exactly one state, the state in which it was
    created. If you make sure that all constructors establish class invariants, then it is
    guaranteed that these invariants will remain true for all time
!!!!!
    Immutable objects are inherently thread-safe; they require no synchronization. They cannot be corrupted by multiple
    threads accessing them concurrently. This is far and away the easiest approach to achieve thread safety. Since no
    thread can ever observe any effect of another thread on an immutable object, immutable objects can be shared freely.

    A consequence of the fact that immutable objects can be shared freely is that you never have to make defensive copies
    of them (Item 50). In fact, you never have to make any copies at all because the copies would be forever equivalent to
    the originals. Therefore, you need not and should not provide a clone method or copy constructor (Item 13) on an
    immutable class.

    immutable objects make great map keys and set elements: you don’t have to worry about their values changing once
    they’re in the map or set, which would destroy the map or set’s invariants.

    Immutable objects provide failure atomicity for free (Item 76). Their state never changes, so there is no possibility
    of a temporary inconsistency.
!!!!!
    The major disadvantage of immutable classes is that they require a separate object for each distinct value.
        Creating these objects can be costly, especially if they are large. For example, suppose that you have a million-bit
        BigInteger and you want to change its low-order bit:
            BigInteger moby = ...;
            moby = moby.flipBit(0);
        The flipBit method creates a new BigInteger instance, also a million bits long, that differs from the original in
        only one bit. The operation requires time and space proportional to the size of the BigInteger. Contrast this to
        java.util.BitSet. Like BigInteger, BitSet represents an arbitrarily long sequence of bits, but unlike BigInteger,
        BitSet is mutable. The BitSet class provides a method that allows you to change the state of a single bit of a
        millionbit instance in constant time:
            BitSet moby = ...;
            moby.flip(0);

    The package-private mutable companion class approach works fine if you can accurately predict which complex operations
    clients will want to perform on your immutable class. If not, then your best bet is to provide a public mutable
    companion class. The main example of this approach in the Java platform libraries
    is the String class, whose mutable companion is StringBuilder (and its obsolete predecessor, StringBuffer).

    Recall that to guarantee immutability, a class must not permit itself to be subclassed. This can
    be done by making the class final, but there is another, more flexible alternative.
    Instead of making an immutable class final, you can make all of its constructors private or package-private and add
    public static factories in place of the public constructors (Item 1).

        // Immutable class with static factories instead of constructors
        public class Complex {
            private final double re;
            private final double im;
            private Complex(double re, double im) {
                this.re = re;
                this.im = im;
            }
            public static Complex valueOf(double re, double im) {
                return new Complex(re, im);
            }
            ... // Remainder unchanged
        }

    This approach is often the best alternative. It is the most flexible because it allows the use of multiple
    package-private implementation classes. To its clients that reside outside its package, the immutable class is
    effectively final because it is impossible to extend a class that comes from another package and that lacks a
    public or protected constructor.

    If you write a class whose security depends on the immutability of a BigInteger or BigDecimal argument from an
    untrusted client, you must check to see that the argument is a “real” BigInteger or BigDecimal,
    rather than an instance of an untrusted subclass. If it is the latter, you must defensively copy it under the
    assumption that it might be mutable (Item 50):
        public static BigInteger safeInstance(BigInteger val) {
            return val.getClass() == BigInteger.class ? val : new BigInteger(val.toByteArray());
        }

    The list of rules for immutable classes at the beginning of this item says that no methods may modify the object and
    that all its fields must be final. In fact these rules are a bit stronger than necessary and can be relaxed to improve
    performance. In truth, no method may produce an externally visible change in the object’s state.
    However, some immutable classes have one or more nonfinal fields in which they cache the results of expensive
    computations the first time they are needed. If the same value is requested again, the cached value is returned,
    saving the cost of recalculation.

!!!!
    To summarize, resist the urge to write a setter for every getter. Classes should be immutable unless there’s a very
    good reason to make them mutable.
    Immutable classes provide many advantages, and their only disadvantage is the potential for performance problems
    under certain circumstances.
    There are some classes for which immutability is impractical. If a class cannot be made immutable, limit its mutability
    as much as possible. Reducing the number of states in which an object can exist makes it easier to reason about
    the object and reduces the likelihood of errors. Therefore, make every field final unless there is a compelling
    reason to make it nonfinal. Combining the advice of this item with that of Item 15, your natural inclination should
    be to declare every field private final unless there’s a good reason to do otherwise
    Constructors should create fully initialized objects with all of their invariants established. Don’t provide a public
    initialization method separate from the constructor or static factory unless there is a compelling reason to do so.
    Similarly, don’t provide a “reinitialize” method that enables an object to be reused as if it
    had been constructed with a different initial state.


Item 18 - Favor composition over inheritance

!!!
    Inheritance is a powerful way to achieve code reuse, but it is not always the best tool for the job. Used
    inappropriately, it leads to fragile software. It is safe to use inheritance within a package, where the subclass
    and the superclass implementations are under the control of the same programmers. It is also safe to use inheritance
    when extending classes specifically designed and documented for extension (Item 19).
!!!
    Inheriting from ordinary concrete classes across package boundaries, however, is dangerous.
    As a reminder, this book uses the word “inheritance” to mean implementation inheritance (when one class extends
    another). The problems discussed in this item do not apply to interface inheritance (when a class implements an
    interface or when one interface extends another).

    Unlike method invocation, inheritance violates encapsulation [Snyder86].
    In other words, a subclass depends on the implementation details of its superclass for its proper function.
    The superclass’s implementation may change from release to release, and if it does, the subclass may break, even
    though its code has not been touched. As a consequence, a subclass must evolve in tandem with its
    superclass, unless the superclass’s authors have designed and documented it specifically for the purpose of being
    extended.
!!!!
    Luckily, there is a way to avoid all of the problems described above. Instead of extending an existing class, give
    your new class a private field that references an instance of the existing class. This design is called composition
    because the existing class becomes a component of the new one. Each instance method in the new class invokes the
    corresponding method on the contained instance of the existing class and returns the results. This is known as
    forwarding, and the methods in the new class are known as forwarding methods. The resulting class will be rock
    solid, with no dependencies on the implementation details of the existing class.

    The InstrumentedSet  (see code examples in package item18) class is known as a wrapper class because each
    InstrumentedSet instance contains (“wraps”) another Set instance. This is also
    known as the Decorator pattern [Gamma95] because the InstrumentedSet class “decorates” a set by adding instrumentation.
    Sometimes the combination of composition and forwarding is loosely referred to as delegation. Technically it’s not
    delegation unless the wrapper object passes itself to the wrapped object [Lieberman86; Gamma95].

    The disadvantages of wrapper classes are few. One caveat is that wrapper classes are not suited for use in
    callback frameworks, wherein objects pass self references to other objects for subsequent invocations (“callbacks”).
    Because a wrapped object doesn’t know of its wrapper, it passes a reference to itself (this)
    and callbacks elude the wrapper. This is known as the SELF problem.

    a class B should extend a class A only if an “is-a” relationship exists between the two classes.
    If you are tempted to have a class B extend a class A, ask yourself the question: Is every B really an A? If you
    cannot truthfully answer yes to this question, B should not extend A. If the answer
    is no, it is often the case that B should contain a private instance of A and expose a
    different API: A is not an essential part of B, merely a detail of its implementation.
    There is one last set of questions you should ask yourself before deciding to
    use inheritance in place of composition. Does the class that you contemplate extending have any flaws in its API?
    If so, are you comfortable propagating those flaws into your class’s API? Inheritance propagates any flaws in the
    superclass’s API, while composition lets you design a new API that hides these flaws

    To summarize, inheritance is powerful, but it is problematic because it violates encapsulation.
    It is appropriate only when a genuine subtype relationship exists between the subclass and the superclass. Even then,
    inheritance may lead to fragility if the subclass is in a different package from the superclass and the
    superclass is not designed for inheritance. To avoid this fragility, use composition and forwarding instead of
    inheritance, especially if an appropriate interface to implement a wrapper class exists. Not only are wrapper classes
    more robust than subclasses, they are also more powerful.


Item 19 - Design and document for inheritance or else prohibit it

    Item 18 alerted you to the dangers of subclassing a “foreign” class that was not designed and documented for inheritance.
    So what does it mean for a class to be designed and documented for inheritance?

!!!
    First, the class must document precisely the effects of overriding any method.
    In other words, the class must document its self-use of overridable methods.
    For each public or protected method, the documentation must indicate which overridable methods the method invokes,
    in what sequence, and how the results of each invocation affect subsequent processing.
    (By overridable, we mean nonfinal and either public or protected.) More generally, a class must document any
    circumstances under which it might invoke an overridable method.
    For example, invocations might come from background threads or static initializers.

    A method that invokes overridable methods contains a description of these invocations at the end of its documentation
    comment. The description is in a special section of the specification, labeled “Implementation Requirements,”
    which is generated by the Javadoc tag @implSpec. This section describes the inner workings of the method. Here’s an
    example, copied from the specification for java.util.AbstractCollection:
        public boolean remove(Object o)

!!!
    But doesn’t this violate the dictum that good API documentation should describe what a given method does and not
    how it does it? Yes, it does! This is an unfortunate consequence of the fact that inheritance violates encapsulation.
    To document a class so that it can be safely subclassed, you must describe implementation details that should otherwise
    be left unspecified.

    The @implSpec tag was added in Java 8 and used heavily in Java 9. This tag should be enabled by default, but as of
    Java 9, the Javadoc utility still ignores it unless you pass the command line switch -tag "apiNote:a:API Note:".

    So how do you decide what protected members to expose when you design a class for inheritance? Unfortunately, there
    is no magic bullet. The best you can do is to think hard, take your best guess, and then test it by writing subclasses.
    You should expose as few protected members as possible because each one represents
    a commitment to an implementation detail. On the other hand, you must not expose too few because a missing protected
    member can render a class practically unusable for inheritance.
    The only way to test a class designed for inheritance is to write subclasses.

    Experience shows that three subclasses are usually sufficient to test an extendable class. One or more
    of these subclasses should be written by someone other than the superclass author.
    ...you are committing forever to the self-use patterns that you document
    and to the implementation decisions implicit in its protected methods and fields.
    These commitments can make it difficult or impossible to improve the performance or functionality of the class in a
    subsequent release. Therefore, you must test your class by writing subclasses before you release it.
!!!
    There are a few more restrictions that a class must obey to allow inheritance.
    Constructors must not invoke overridable methods, directly or indirectly. If you violate this rule, program failure
    will result. The superclass constructor runs before the subclass constructor, so the overriding method in the
    subclass will get invoked before the subclass constructor has run. If the overriding method depends
    on any initialization performed by the subclass constructor, the method will not behave as expected.

            (see code from package item19 to understand the scenario)

!!! Note that it is safe to invoke private methods, final methods, and static methods, none of which are overridable,
    from a constructor.

    The Cloneable and Serializable interfaces present special difficulties when designing for inheritance. It is generally
    not a good idea for a class designed for inheritance to implement either of these interfaces because they place a
    substantial burden on programmers who extend the class.
        (see book for more info on this)

    There are some situations where it (designing for inheritance) is clearly the right thing to do, such as abstract
    classes, including skeletal implementations of interfaces (Item 20). There are other situations where it is clearly
    the wrong thing to do, such as immutable classes (Item 17).
!!!!
    The best solution to this problem is to prohibit subclassing in classes that are not designed and documented to be
    safely subclassed. There are two ways to prohibit subclassing. The easier of the two is to declare the class final. The
    alternative is to make all the constructors private or package-private and to add public static factories in place
    of the constructors. This alternative, which provides the flexibility to use subclasses internally, is discussed in
    Item 17. Either approach is acceptable.

    This advice may be somewhat controversial because many programmers have grown accustomed to subclassing ordinary
    concrete classes to add facilities such as instrumentation, notification, and synchronization or to limit functionality.
    If a class implements some interface that captures its essence, such as Set, List, or Map, then you should feel no
    compunction about prohibiting subclassing. The wrapper class pattern, described in Item 18, provides a superior
    alternative to inheritance for augmenting the functionality.
!!!
    If a concrete class does not implement a standard interface, then you may inconvenience some programmers by prohibiting
    inheritance. If you feel that you must allow inheritance from such a class, one reasonable approach is to ensure
    that the class never invokes any of its overridable methods and to document this fact. In other words, eliminate the
    class’s self-use of overridable methods entirely. In doing so, you’ll create a class that is reasonably safe to
    subclass. Overriding a method will never affect the behavior of any other method.

    You can eliminate a class’s self-use of overridable methods mechanically,
    without changing its behavior. Move the body of each overridable method to a
    private “helper method” and have each overridable method invoke its private
    helper method. Then replace each self-use of an overridable method with a direct
    invocation of the overridable method’s private helper method.

    Unless you know there is a real need for subclasses, you are probably better off prohibiting inheritance by declaring
    your class final or ensuring that there are no accessible constructors. If you really need inheritance,
    you must document all of its self-use patterns, and once you’ve documented them, you must commit to
    them for the life of the class.


Item 20 - Prefer interfaces to abstract classes

    Java has two mechanisms to define a type that permits multiple implementations:
    interfaces and abstract classes. Since the introduction of default methods for interfaces in Java 8 [JLS 9.4.3], both
    mechanisms allow you to provide implementations for some instance methods. A major difference is that to implement
    the type defined by an abstract class, a class must be a subclass of the abstract class.
    Because Java permits only single inheritance, this restriction on abstract classes severely constrains their use as
    type definitions.

    + Existing classes can easily be retrofitted to implement a new interface. All
      you have to do is to add the required methods, if they don’t yet exist, and to add an
      implements clause to the class declaration. For example, many existing classes
      were retrofitted to implement the Comparable, Iterable, and Autocloseable
      interfaces when they were added to the platform. Existing classes cannot, in
      general, be retrofitted to extend a new abstract class. If you want to have two
      classes extend the same abstract class, you have to place it high up in the type
      hierarchy where it is an ancestor of both classes. Unfortunately, this can cause
      great collateral damage to the type hierarchy, forcing all descendants of the new
      abstract class to subclass it, whether or not it is appropriate.

    + Interfaces are ideal for defining mixins. Loosely speaking, a mixin is a type
      that a class can implement in addition to its “primary type,” to declare that it provides some optional behavior.
      For example, Comparable is a mixin interface that  allows a class to declare that its instances are ordered with
      respect to other mutually comparable objects. Such an interface is called a mixin because it allows the
      optional functionality to be “mixed in” to the type’s primary functionality

    + Interfaces allow for the construction of nonhierarchical type frameworks.
      Type hierarchies are great for organizing some things, but other things don’t fall
      neatly into a rigid hierarchy. For example, suppose we have an interface representing a singer and another representing
      a songwriter:
            public interface Singer {
                AudioClip sing(Song s);
            }

            public interface Songwriter {
                Song compose(int chartPosition);
            }

      In real life, some singers are also songwriters. Because we used interfaces rather than abstract classes to define
      these types, it is perfectly permissible for a single class to implement both Singer and Songwriter. In fact, we
      can define a third interface that extends both Singer and Songwriter and adds new methods that are appropriate to
      the combination:

            public interface SingerSongwriter extends Singer, Songwriter {
                AudioClip strum();
                void actSensitive();
            }
      You don’t always need this level of flexibility, but when you do, interfaces are a lifesaver. The alternative is a
      bloated class hierarchy containing a separate class for every supported combination of attributes. If there are n
      attributes in the type system, there are 2^n possible combinations that you might have to support. This is
      what’s known as a combinatorial explosion.

    + Interfaces enable safe, powerful functionality enhancements via the wrapper class idiom (Item 18). If you use
        abstract classes to define types, you leave the programmer who wants to add functionality with no alternative
        but inheritance. The resulting classes are less powerful and more fragile than wrapper classes.

    If you provide default methods, be sure to document them for inheritance using the @implSpec Javadoc tag (Item 19).

    You can, however, combine the advantages of interfaces and abstract classes by providing an abstract skeletal
    implementation class to go with an interface. The interface defines the type, perhaps providing some default methods,
    while the skeletal implementation class implements the remaining non-primitive interface methods atop the primitive
    interface methods. Extending a skeletal implementation takes most of the work out of implementing an interface.
    This is the Template Method pattern [Gamma95].
    By convention, skeletal implementation classes are called AbstractInterface, where Interface is the name of the
    interface they implement.
    For example, the Collections Framework provides a skeletal implementation to go along with each
    main collection interface: AbstractCollection, AbstractSet, AbstractList, and AbstractMap.

!!!
    The beauty of skeletal implementation classes is that they provide all of the implementation assistance of abstract
    classes without imposing the severe constraints that abstract classes impose when they serve as type definitions. For most
    implementors of an interface with a skeletal implementation class, extending this class is the obvious choice, but it
    is strictly optional. If a class cannot be made to extend the skeletal implementation, the class can always implement
    the interface directly. The class still benefits from any default methods present on the interface
    itself. Furthermore, the skeletal implementation can still aid the implementor’s task. The class implementing the
    interface can forward invocations of interface methods to a contained instance of a private inner class that extends
    the skeletal implementation. This technique, known as simulated multiple inheritance, is closely related to the wrapper
    class idiom discussed in Item 18. It provides many of the benefits of multiple inheritance, while avoiding the pitfalls.
        (see example of this in item20 ex2)

    Writing a skeletal implementation is a relatively simple, if somewhat tedious,
    process. First, study the interface and decide which methods are the primitives in
    terms of which the others can be implemented. These primitives will be the
    abstract methods in your skeletal implementation. Next, provide default methods
    in the interface for all of the methods that can be implemented directly atop the
    primitives, but recall that you may not provide default methods for Object
    methods such as equals and hashCode. If the primitives and default methods
    cover the interface, you’re done, and have no need for a skeletal implementation
    class. Otherwise, write a class declared to implement the interface, with
    implementations of all of the remaining interface methods. The class may contain
    any nonpublic fields ands methods appropriate to the task.

    Because skeletal implementations are designed for inheritance, you should
    follow all of the design and documentation guidelines in Item 19. For brevity’s
    sake, the documentation comments were omitted from the previous example, but
    good documentation is absolutely essential in a skeletal implementation,
    whether it consists of default methods on an interface or a separate abstract class.

    To summarize, an interface is generally the best way to define a type that permits multiple implementations. If you
    export a nontrivial interface, you should strongly consider providing a skeletal implementation to go with it. To
    the extent possible, you should provide the skeletal implementation via default methods on the interface so that
    all implementors of the interface can make use of it. That said, restrictions on interfaces typically mandate that
    a skeletal implementation take the form of an abstract class.


Item 21 - Design interfaces for posterity

    Prior to Java 8, it was impossible to add methods to interfaces without breaking
    existing implementations. If you added a new method to an interface, existing
    implementations would, in general, lack the method, resulting in a compile-time
    error. In Java 8, the default method construct was added [JLS 9.4], with the intent
    of allowing the addition of methods to existing interfaces. But adding new methods to existing interfaces is fraught
    with risk.

!!!
    The declaration for a default method includes a default implementation that is used by all classes that implement
    the interface but do not implement the default method. While the addition of default methods to Java makes it possible
    to add methods to an existing interface, there is no guarantee that these methods will work in all preexisting
    implementations. Default methods are “injected” into existing implementations without the knowledge or consent of
    their implementors. Before Java 8, these implementations were written with the tacit understanding that their interfaces
    would never acquire any new methods.

    Many new default methods were added to the core collection interfaces in Java 8, primarily to facilitate the use of
    lambdas (Chapter 6). The Java libraries’ default methods are high-quality general-purpose implementations, and in most
    cases, they work fine. But it is not always possible to write a default method that maintains all invariants of every
    conceivable implementation.

    (EXAMPLE OF problems that can occur because of default methods)
    This is the best general-purpose implementation one could possibly write for the removeIf method, but sadly, it fails
    on some real-world Collection implementations. For example, consider org.apache.commons.collections4.collection.SynchronizedCollection.
    The Apache version additionally provides the ability to use a client-supplied object for locking, in place of the
    collection. In other words, it is a wrapper class (Item 18), all of whose methods synchronize on a locking object
    before delegating to the wrapped collection.
    The Apache SynchronizedCollection class is still being actively maintained, but as of this writing, it does not override
    the removeIf method. If this class is used in conjunction with Java 8, it will therefore inherit the default
    implementation of removeIf, which does not, indeed cannot, maintain the class’s fundamental promise: to automatically
    synchronize around each method invocation. The default implementation knows nothing about synchronization and has no
    access to the field that contains the locking object. If a client calls the removeIf method on a SynchronizedCollection
    instance in the presence of concurrent modification of the collection by another thread, a ConcurrentModificationException or
    other unspecified behavior may result.

    In the presence of default methods, existing implementations of an interface may compile without error or warning but
    fail at runtime. While not terribly common, this problem is not an isolated incident either. A handful of the
    methods added to the collections interfaces in Java 8 are known to be susceptible, and a handful of existing
    implementations are known to be affected.
!!!
    Using default methods to add new methods to existing interfaces should be
    avoided unless the need is critical, in which case you should think long and hard
    about whether an existing interface implementation might be broken by your
    default method implementation.
    It is also worth noting that default methods were not designed to support
    removing methods from interfaces or changing the signatures of existing methods.
    Neither of these interface changes is possible without breaking existing clients.

    Even though default methods are now a part of the Java platform, it is still of the utmost importance to design
    interfaces with great care.

    Therefore, it is critically important to test each new interface before you release it. Multiple programmers should
    implement each interface in different ways. At a minimum, you should aim for three diverse implementations. Equally
    important is to write multiple client programs that use instances of each new interface to perform various tasks.
    This will go a long way toward ensuring that each interface satisfies all of its intended uses. These steps will
    allow you to discover flaws in interfaces before they are released, when you can still correct them easily. While
    it may be possible to correct some interface flaws after an interface is released, you cannot count on it.


Item 22 - Use interfaces only to define types

    When a class implements an interface, the interface serves as a type that can be used to refer to instances of the
    class. That a class implements an interface should therefore say something about what a client can do with instances
    of the class. It is inappropriate to define an interface for any other purpose.

    One kind of interface that fails this test is the so-called constant interface. Such an interface contains no methods;
    it consists solely of static final fields, each exporting a constant.

    There are several constant interfaces in the Java platform libraries, such as
    java.io.ObjectStreamConstants. These interfaces should be regarded as anomalies and should not be emulated

    If the constants are best viewed as members of an enumerated type, you should export them with an enum type (Item 34).
    Otherwise, you should export the constants with a noninstantiable utility class (Item 4).

    In summary, interfaces should be used only to define types. They should not be used merely to export constants


Item 23 - Prefer class hierarchies to tagged classes

    Occasionally you may run across a class whose instances come in two or more flavors and contain a tag field
    indicating the flavor of the instance. For example, consider this class, which is capable of representing a circle
    or a rectangle
        (basically a class that can represent either a cirecle or a rectangle and has code for both, and a field that
        is used to determine what geometric form the instance is)

    Such tagged classes have numerous shortcomings. They are cluttered with boilerplate, including enum declarations,
    tag fields, and switch statements. Readability is further harmed because multiple implementations are jumbled together
    in a single class. Memory footprint is increased because instances are burdened with irrelevant fields belonging to
    other flavors. Fields can’t be made final unless constructors initialize irrelevant fields, resulting in more
    boilerplate. Constructors must set the tag field and initialize the right data fields with no help from the compiler:
    if you initialize the wrong fields, the program will fail at runtime. You can’t add a flavor to a tagged class unless
    you can modify its source file. If you do add a flavor, you must remember to add a case to every switch statement,
    or the class will fail at runtime. Finally, the data type of an instance gives no clue as to its
    flavor. In short, tagged classes are verbose, error-prone, and inefficient.

    A tagged class is just a pallid imitation of a class hierarchy

    In summary, tagged classes are seldom appropriate. If you’re tempted to write a class with an explicit tag field,
    think about whether the tag could be eliminated and the class replaced by a hierarchy. When you encounter an existing
    class with a tag field, consider refactoring it into a hierarchy


Item 24 - Favor static member classes over nonstatic

!!!
    A nested class is a class defined within another class. A nested class should exist only to serve its enclosing
    class. If a nested class would be useful in some other context, then it should be a top-level class. There are four
    kinds of nested classes: static member classes, nonstatic member classes, anonymous classes, and local
    classes. All but the first kind are known as inner classes. This item tells you when to use which kind of nested
    class and why.

    A static member class is best thought of as an ordinary class that happens to be declared inside another class and has
    access to all of the enclosing class’s members, even those declared private. A static member class is a static member
    of its enclosing class and obeys the same accessibility rules as other static members. If it is declared private, it
    is accessible only within the enclosing class, and so forth.

    For example, consider an enum describing the operations supported by a calculator (Item 34). The Operation enum should
    be a public static member class of the Calculator class. Clients of Calculator could then refer to operations using
    names like Calculator.Operation.PLUS and Calculator.Operation.MINUS.

    Syntactically, the only difference between static and nonstatic member classes is that static member classes have the
    modifier static in their declarations.
!!! Despite the syntactic similarity, these two kinds of nested classes are very different. Each instance of a nonstatic
    member class is implicitly associated with an enclosing instance of its containing class. Within instance methods of
    a nonstatic member class, you can invoke methods on the enclosing instance or obtain a reference to the enclosing
    instance using the qualified "this" construct. If an instance of a nested class can exist in isolation from an
    instance of its enclosing class, then the nested class must be a static member class: it is impossible to create
    an instance of a nonstatic member class without an enclosing instance.

    One common use of a nonstatic member class is to define an Adapter that allows an instance of the outer class to be
    viewed as an instance of some unrelated class. Example:
    implementations of the collection interfaces, such as Set and List, typically use nonstatic member classes to implement
    their iterators:
        // Typical use of a nonstatic member class
        public class MySet<E> extends AbstractSet<E> {
            ... // Bulk of the class omitted
            @Override public Iterator<E> iterator() {
                return new MyIterator();
            }

            private class MyIterator implements Iterator<E> {
                ...
            }
        }
!!!!
    If you declare a member class that does not require access to an enclosing instance, always put the "static" modifier
    in its declaration, making it a static rather than a nonstatic member class.
    If you omit this modifier, each instance will have a hidden extraneous reference to its enclosing instance. As
    previously mentioned, storing this reference takes time and space. More seriously, it can result in
    the enclosing instance being retained when it would otherwise be eligible for garbage collection (Item 7). The
    resulting memory leak can be catastrophic. It is often difficult to detect because the reference is invisible.

    A common use of private static member classes is to represent components of the object represented by their enclosing
    class. For example, consider a Map instance, which associates keys with values. Many Map implementations have an
    internal Entry object for each key-value pair in the map. While each entry is associated with a map, the methods on
    an entry (getKey, getValue, and setValue) do not need access to the map. Therefore, it would be wasteful to use a
    nonstatic member class to represent entries: a private static member class is best. If you
    accidentally omit the static modifier in the entry declaration, the map will still work, but each entry will contain
    a superfluous reference to the map, which wastes space and time.

!!!
    An anonymous class has no name. It is not a member of its enclosing class. Rather than being declared along with
    other members, it is simultaneously declared and instantiated at the point of use. Anonymous classes
    are permitted at any point in the code where an expression is legal. Anonymous classes have enclosing instances if
    and only if they occur in a nonstatic context.
    But even if they occur in a static context, they cannot have any static members other than constant variables, which
    are final primitive or string fields initialized to constant expressions

    There are many limitations on the applicability of anonymous classes. You can’t instantiate them except at the point
    they’re declared. You can’t perform instanceof tests or do anything else that requires you to name the class. You
    can’t declare an anonymous class to implement multiple interfaces or to extend a class and implement an interface
    at the same time. Clients of an anonymous class can’t invoke any members except those it inherits from its supertype.
    Because anonymous classes occur in the midst of expressions, they must be kept short—about ten lines or fewer—or
    readability will suffer.
!!!  Before lambdas were added to Java (Chapter 6), anonymous classes were the preferred means of creating small function
    objects and process objects on the fly, but lambdas are now preferred (Item 42). Another common use of anonymous
    classes is in the implementation of static factory methods

    Local classes are the least frequently used of the four kinds of nested classes. A
    local class can be declared practically anywhere a local variable can be declared and
    obeys the same scoping rules. Local classes have attributes in common with each of
    the other kinds of nested classes. Like member classes, they have names and can be
    used repeatedly. Like anonymous classes, they have enclosing instances only if they
    are defined in a nonstatic context, and they cannot contain static members. And like
    anonymous classes, they should be kept short so as not to harm readability.

!!!
    To recap, there are four different kinds of nested classes, and each has its
    place. If a nested class needs to be visible outside of a single method or is too long
    to fit comfortably inside a method, use a member class. If each instance of a member class needs a reference to its
    enclosing instance, make it nonstatic; otherwise,
    make it static. Assuming the class belongs inside a method, if you need to create
    instances from only one location and there is a preexisting type that characterizes
    the class, make it an anonymous class; otherwise, make it a local class.


Item 25 - Limit source files to a single top level class

    While the Java compiler lets you define multiple top-level classes in a single source
    file, there are no benefits associated with doing so, and there are significant risks.
    The risks stem from the fact that defining multiple top-level classes in a source file
    makes it possible to provide multiple definitions for a class. Which definition gets
    used is affected by the order in which the source files are passed to the compiler.

        (example provided in the book)

    If you are tempted to put multiple top-level classes into a single source file, consider using static
    member classes (Item 24) as an alternative to splitting the classes into separate source files.

    The lesson is clear: Never put multiple top-level classes or interfaces in a single source file. Following this rule
    guarantees that you can’t have multiple definitions for a single class at compile time. This in turn guarantees that
    the class files generated by compilation, and the behavior of the resulting program, are independent of the order in
    which the source files are passed to the compiler.


===============================================================================================================
===============================================================================================================
Chapter 5 - Generics

    SINCE Java 5, generics have been a part of the language. Before generics, you had
    to cast every object you read from a collection. If someone accidentally inserted an
    object of the wrong type, casts could fail at runtime. With generics, you tell the
    compiler what types of objects are permitted in each collection. The compiler
    inserts casts for you automatically and tells you at compile time if you try to insert
    an object of the wrong type. This results in programs that are both safer and clearer,
    but these benefits, which are not limited to collections, come at a price.


Item 26 - Don't use raw types

!!! A class or interface whose declaration has one or more type parameters is a generic class or interface.
    For example, the List interface has a single type parameter, E, representing its element type. The
    full name of the interface is List<E> (read “list of E”), but people often call it List
    for short. Generic classes and interfaces are collectively known as generic types.

    Each generic type defines a set of parameterized types, which consist of the class or interface name followed
    by an angle-bracketed list of actual type parameters corresponding to the generic type’s formal type parameters.
    For example, List<String> (read “list of string”) is a parameterized type representing a list whose elements are of
    type String. (String is the actual type parameter corresponding to the formal type parameter E.)
!!!
    Finally, each generic type defines a raw type, which is the name of the generic type used without any accompanying
    type parameters. For example, the raw type corresponding to List<E> is List. Raw types behave as if all of the
    generic type information were erased from the type declaration. They exist primarily for compatibility with pre-generics code.

    Before generics were added to Java, this would have been an exemplary collection declaration. As of Java 9, it is
    still legal, but far from exemplary:
        // Raw collection type - don't do this!
        // My stamp collection. Contains only Stamp instances.
        private final Collection stamps = ... ;
    If you use this declaration today and then accidentally put a coin into your stamp collection, the erroneous insertion
    compiles and runs without error (though the compiler does emit a vague warning):
        // Erroneous insertion of coin into stamp collection
        stamps.add(new Coin( ... )); // Emits "unchecked call" warning
    You don’t get an error until you try to retrieve the coin from the stamp collection:
        // Raw iterator type - don't do this!
        for (Iterator i = stamps.iterator(); i.hasNext(); )
        Stamp stamp = (Stamp) i.next(); // Throws ClassCastException
        stamp.cancel();

    As mentioned throughout this book, it pays to discover errors as soon as possible after they are made, ideally at
    compile time. In this case, you don’t discover the error until runtime.

    With generics, the type declaration contains the information, not the comment:
        // Parameterized collection type - typesafe
        private final Collection<Stamp> stamps = ... ;

    From this declaration, the compiler knows that stamps should contain only Stamp instances and guarantees it to be true,
    assuming your entire codebase compiles without emitting (or suppressing; see Item 27) any warnings. When stamps is
    declared with a parameterized type declaration, the erroneous insertion generates a compile-time error message that
    tells you exactly what is wrong:
        Test.java:9: error: incompatible types: Coin cannot be converted
        to Stamp
        c.add(new Coin());

     For example, it is easy to imagine putting a BigInteger into a collection that is supposed to contain only BigDecimal instances.


!!!!As noted earlier, it is legal to use raw types (generic types without their type parameters), but you should never
    do it. If you use raw types, you lose all the  safety and expressiveness benefits of generics.

    Given that you shouldn’t use them, why did the language designers permit raw types in the first place? For
    compatibility. Java was about to enter its second decade when generics were added, and there was an enormous amount
    of code in existence that did not use generics. It was deemed critical that all of this code remain legal and interoperate
    with newer code that does use generics. It had to be legal to pass instances of parameterized types to methods that
    were designed for use with raw types, and vice versa.

!!!
    While you shouldn’t use raw types such as List, it is fine to use types that are parameterized to allow insertion of
    arbitrary objects, such as List<Object>. Just what is the difference between the raw type List and the parameterized type
    List<Object>?
    Loosely speaking, the former has opted out of the generic type system, while the latter has explicitly told the compiler
    that it is capable of holding objects of any type. While you can pass a List<String> to a parameter of
    type List, you can’t pass it to a parameter of type List<Object>. There are subtyping rules for generics, and List<String>
    is a subtype of the raw type List, but not of the parameterized type List<Object> (Item 28).
!!! As a consequence, you lose type safety if you use a raw type such as List, but not if you use a parameterized type
    such as List<Object>.


    You might be tempted to use a raw type for a collection whose element type is unknown and doesn’t matter. For example,
    suppose you want to write a method that takes two sets and returns the number of elements they have in common.
    Here’s how you might write such a method if you were new to generics:
        // Use of raw type for unknown element type - don't do this!
        static int numElementsInCommon(Set s1, Set s2) {
            int result = 0;
            for (Object o1 : s1)
                if (s2.contains(o1))
                    result++;
            return result;
        }

!!! This method works but it uses raw types, which are dangerous. The safe alternative is to use "unbounded wildcard types".
    If you want to use a generic type but you don’t know or care what the actual type parameter is, you can use a question
    mark instead. For example, the unbounded wildcard type for the generic type Set<E> is Set<?> (read “set of some type”).
    It is the most general parameterized Set type, capable of holding any set.

        // Uses unbounded wildcard type - typesafe and flexible
        static int numElementsInCommon(Set<?> s1, Set<?> s2) { ... }

    What is the difference between the unbounded wildcard type Set<?> and the raw type Set? Does the question mark really
    buy you anything? Not to belabor the point, but the wildcard type is safe and the raw type isn’t. You can put any element
    into a collection with a raw type, easily corrupting the collection’s type invariant (as demonstrated by the unsafeAdd
    method on page 119); you can’t put any element (other than null) into a Collection<?>

        (see example in class UnboundedWildcardType)

    Not only can’t you put any element (other than null) into a Collection<?>, but you can’t assume anything about the type
    of the objects that you get out. If these restrictions are unacceptable, you can use generic methods (Item 30) or
    bounded wildcard types (Item 31).

    There are a few minor exceptions to the rule that you should not use rawtypes.
        1. You must use raw types in class literals. The specification does not permit the use of parameterized types
        (though it does permit array types and primitive types). In other words, List.class, String[].class, and
        int.class are all legal, but List<String>.class and List<?>.class are not.

        2. A second exception to the rule concerns the instanceof operator. Because generic type information is erased at
            runtime, it is illegal to use the instanceof operator on parameterized types other than unbounded wildcard
            types. The use of unbounded wildcard types in place of raw types does not affect the behavior of the
            instanceof operator in any way. In this case, the angle brackets and question marks are just noise. This is
            the preferred way to use the instanceof operator with generic types:

               // Legitimate use of raw type - instanceof operator
               if (o instanceof Set) { // Raw type
                   Set<?> s = (Set<?>) o; // Wildcard type
                   ...
               }

    In summary, using raw types can lead to exceptions at runtime, so don’t use them. They are provided only for compatibility
    and interoperability with legacy code that predates the introduction of generics. As a quick review, Set<Object> is
    a parameterized type representing a set that can contain objects of any type, Set<?> is a wildcard type representing
    a set that can contain only objects of some unknown type, and Set is a raw type, which opts out of the generic type system.
    The first two are safe, and the last is not.

!!!!
    Term                            Example                             Item
    Parameterized type              List<String>                        26
    Actual type parameter           String                              26
    Generic type                    List<E>                             26, 29
    Formal type parameter           E                                   26
    Unbounded wildcard type         List<?>                             26
    Raw type                        List                                26
    Bounded type parameter          <E extends Number>                  29
    Recursive type bound            <T extends Comparable<T>>           30
    Bounded wildcard type           List<? extends Number>              31
    Generic method static           <E> List<E> asList(E[] a)           30
    Type token                      String.class                        33


Item 27 - Eliminate unchecked warnings

    When you program with generics, you will see many compiler warnings:
    unchecked cast warnings, unchecked method invocation warnings, unchecked parameterized vararg type warnings, and
    unchecked conversion warnings. The more experience you acquire with generics, the fewer warnings you’ll get, but
    don’t expect newly written code to compile cleanly.

!!!!!!
    Some warnings will be much more difficult to eliminate. This chapter is filled with examples of such warnings. When
    you get warnings that require some thought, persevere! Eliminate every unchecked warning that you can. If you
    eliminate all warnings, you are assured that your code is typesafe, which is a very good thing. It means that you
    won’t get a ClassCastException at runtime, and it increases your confidence that your program will behave as you intended.
    If you can’t eliminate a warning, but you can prove that the code that provoked the warning is typesafe, then
    (and only then) suppress the warning with an @SuppressWarnings("unchecked") annotation

!!!
    Always use the SuppressWarnings annotation on the smallest scope possible. Typically this will be a variable
    declaration or a very short method or constructor. Never use SuppressWarnings on an entire class. Doing so could
    mask critical warnings.

    It is illegal to put a SuppressWarnings annotation on the return statement, because it isn’t a declaration .
    You might be tempted to put the annotation on the entire method, but don’t. Instead, declare a local variable to hold the
    return value and annotate its declaration.

    Every time you use a @SuppressWarnings("unchecked") annotation, add a comment saying why it is safe to do so. This
    will help others understand the code, and more importantly, it will decrease the odds that someone will modify
    the code so as to make the computation unsafe. If you find it hard to write such a comment, keep thinking.
    You may end up figuring out that the unchecked operation isn’t safe after all.

    In summary, unchecked warnings are important. Don’t ignore them. Every unchecked warning represents the potential
    for a ClassCastException at runtime. Do your best to eliminate these warnings. If you can’t eliminate an
    unchecked warning and you can prove that the code that provoked it is typesafe, suppress the warning with a
    @SuppressWarnings("unchecked") annotation in the narrowest possible scope. Record the rationale for your decision
    to suppress the warning in a comment.


Item 28 - Prefer lists to arrays

!!!
    Arrays differ from generic types in two important ways. First, arrays are covariant. This scary-sounding word means
    simply that if Sub is a subtype of Super, then the array type Sub[] is a subtype of the array type Super[]. Generics, by
    contrast, are invariant: for any two distinct types Type1 and Type2, List<Type1> is neither a subtype nor a supertype
    of List<Type2>. You might think this means that generics are deficient, but arguably it is arrays that are deficient

        This code fragment is legal:
                // Fails at runtime!
                Object[] objectArray = new Long[1];
                objectArray[0] = "I don't fit in"; // Throws ArrayStoreException
        but this one is not:
                // Won't compile!
                List<Object> ol = new ArrayList<Long>(); // Incompatible types
                ol.add("I don't fit in");

    The second major difference between arrays and generics is that arrays are reified. This means that arrays know and
    enforce their element type at runtime. As noted earlier, if you try to put a String into an array of Long, you’ll
    get an ArrayStoreException. Generics, by contrast, are implemented by erasure. This means that they enforce their
    type constraints only at compile time and discard (or erase) their element type information at runtime. Erasure is
    what allowed generic types to interoperate freely with legacy code that didn’t use generics (Item 26), ensuring a
    smooth transition to generics in Java 5.

    Why is it illegal to create a generic array? Because it isn’t typesafe. If it were legal, casts generated by the
    compiler in an otherwise correct program could fail at runtime with a ClassCastException. This would violate the
    fundamental guarantee provided by the generic type system

        (example in the book with why it is illegal to create a generic array )
!!
    Types such as E, List<E>, and List<String> are technically known as nonreifiable types. Intuitively speaking, a
    non-reifiable type is one whose runtime representation contains less information than its compile-time
    representation. Because of erasure, the only parameterized types that are reifiable are unbounded wildcard types
    such as List<?> and Map<?,?> (Item 26). It is legal, though rarely useful, to create arrays of unbounded wildcard
    types.    (erasure meaning "Type erasure can be explained as the process of enforcing type constraints only at
                compile time and discarding the element type information at runtime." )


    In summary, arrays and generics have very different type rules. Arrays are covariant and reified; generics are
    invariant and erased. As a consequence, arrays provide runtime type safety but not compile-time type safety, and
    vice versa for generics. As a rule, arrays and generics don’t mix well. If you find yourself
    mixing them and getting compile-time errors or warnings, your first impulse should be to replace the arrays with lists


Item 29 - Favor generic types

!!!
    It is generally not too difficult to parameterize your declarations and make use of the generic types and methods
    provided by the JDK. Writing your own generic types is a bit more difficult, but it’s worth the effort to learn how

    The first step in generifying a class is to add one or more type parameters to its declaration.

    The next step is to replace all the uses of the type Object with the appropriate type parameter and then try to
    compile the resulting program

    Thus, the first (one used in GenericStack in the constructor, to cast the array) technique is preferable and more
    commonly used in practice. It does, however, cause heap pollution (Item 32): the runtime type of the array does not
    match its compile-time type (unless E happens to be Object). This makes some programmers sufficiently queasy that
    they opt for the second technique, though the heap pollution is harmless in this situation

!!!
    The foregoing (from package item29) example may appear to contradict Item 28, which encourages
    the use of lists in preference to arrays. It is not always possible or desirable to use
    lists inside your generic types. Java doesn’t support lists natively, so some generic
    types, such as ArrayList, must be implemented atop arrays. Other generic types,
    such as HashMap, are implemented atop arrays for performance.

    The great majority of generic types are like our Stack example in that their type parameters have no restrictions:
    you can create a Stack<Object>, Stack<int[]>, Stack<List<String>>, or Stack of any other object reference
    type. Note that you can’t create a Stack of a primitive type: trying to create a Stack<int> or Stack<double> will
    result in a compile-time error. This is a fundamental limitation of Java’s generic type system. You can work around this
    restriction by using boxed primitive types (Item 61).

        class DelayQueue<E extends Delayed> implements BlockingQueue<E>

    The type parameter list (<E extends Delayed>) requires that the actual type parameter E be a subtype of
    java.util.concurrent.Delayed. This allows the DelayQueue implementation and its clients to take advantage of Delayed
    methods on the elements of a DelayQueue, without the need for explicit casting or the risk of a ClassCastException.
    The type parameter E is known as a bounded type parameter. Note that the subtype relation is defined so that every
    type is a subtype of itself, so it is legal to create a DelayQueue<Delayed>.

    In summary, generic types are safer and easier to use than types that require
    casts in client code. When you design new types, make sure that they can be used
    without such casts. This will often mean making the types generic. If you have any
    existing types that should be generic but aren’t, generify them. This will make life
    easier for new users of these types without breaking existing clients (Item 26).


Item 30 - Favor generic methods

    Just as classes can be generic, so can methods. Static utility methods that operate
    on parameterized types are usually generic. All of the “algorithm” methods in
    Collections (such as binarySearch and sort) are generic.
    Writing generic methods is similar to writing generic types.

    The type parameter list, which declares the type parameters, goes between a method’s modifiers and its return type.

    You can make the method more flexible by using bounded wildcard types (Item 31)

    On occasion, you will need to create an object that is immutable but
    applicable to many different types. Because generics are implemented by erasure
    (Item 28), you can use a single object for all required type parameterizations, but
    you need to write a static factory method to repeatedly dole out the object for each
    requested type parameterization. This pattern, called the generic singleton factory,
    is used for function objects (Item 42) such as Collections.reverseOrder, and
    occasionally for collections such as Collections.emptySet.

    Suppose that you want to write an identity function dispenser. (The libraries provide Function.identity, so there’s no
    reason to write your own (Item 59), but it is instructive..for example purposes.)
    It would be wasteful to create a new identity function object time one is requested, because it’s stateless.
    If Java’s generics were reified, you would need one identity function per type, but since they’re erased a generic
    singleton will suffice. Here’s how it looks:

        // Generic singleton factory pattern
        private static UnaryOperator<Object> IDENTITY_FN = (t) -> t;

        @SuppressWarnings("unchecked")
        public static <T> UnaryOperator<T> identityFunction() {
            return (UnaryOperator<T>) IDENTITY_FN;
        }
!!! The cast of IDENTITY_FN to (UnaryFunction<T>) generates an unchecked cast warning, as UnaryOperator<Object> is not a
    UnaryOperator<T> for every T. But the identity function is special: it returns its argument unmodified, so we
    know that it is typesafe to use it as a UnaryFunction<T>, whatever the value of T.

    Therefore, we can confidently suppress the unchecked cast warning generated by
    this cast. Once we’ve done this, the code compiles without error or warning.

!!! It is permissible, though relatively rare, for a type parameter to be bounded by
    some expression involving that type parameter itself. This is what’s known as a
    recursive type bound. A common use of recursive type bounds is in connection
    with the Comparable interface, which defines a type’s natural ordering (Item 14).

        This interface is shown here:
            public interface Comparable<T> {
                int compareTo(T o);
            }
!!!
    The type parameter T defines the type to which elements of the type implementing  Comparable<T> can be compared.
    In practice, nearly all types can be compared only to elements of their own type. So, for example, String
    implements Comparable<String>, Integer implements Comparable<Integer>, and so on.
    Many methods take a collection of elements implementing Comparable to sort it, search within it, calculate its
    minimum or maximum, and the like. To do these things, it is required that every element in the collection be
    comparable to every other element in it, in other words, that the elements of the list be mutually
    comparable. Here is how to express that constraint:

        // Using a recursive type bound to express mutual comparability
        public static <E extends Comparable<E>> E max(Collection<E> c);

    The type bound <E extends Comparable<E>> may be read as “any type E that can be compared to itself,” which
    corresponds more or less precisely to the notion of mutual comparability.

    In summary, generic methods, like generic types, are safer and easier to use than methods requiring their clients
    to put explicit casts on input parameters and return values. Like types, you should make sure that your methods can
    be used without casts, which often means making them generic. And like types, you should generify existing methods
    whose use requires casts. This makes life easier for new users without breaking existing clients (Item 26).


Item 31 - Use bounded wildcards to increase API flexibility

!!!
    parameterized types are invariant. In other words, for any two distinct types Type1 and Type2, List<Type1> is
    neither a subtype nor a supertype of List<Type2>. Although it is counterintuitive that List<String> is
    not a subtype of List<Object>, it really does make sense. You can put any object
    into a List<Object>, but you can put only strings into a List<String>. Since a
    List<String> can’t do everything a List<Object> can, it isn’t a subtype (by the Liskov substitution principal, Item 10).

    Sometimes you need more flexibility than invariant typing can provide. Consider the Stack class from Item 29.
    To refresh your memory, here is its public API:
        public class Stack<E> {
            public Stack();
            public void push(E e);
            public E pop();
            public boolean isEmpty();
        }

    Suppose we want to add a method that takes a sequence of elements and pushes them all onto the stack. Here’s a
    first attempt:
        // pushAll method without wildcard type - deficient!
        public void pushAll(Iterable<E> src) {
            for (E e : src)
                push(e);
        }

    This method compiles cleanly, but it isn’t entirely satisfactory. If the element type of the Iterable src exactly
    matches that of the stack, it works fine. But suppose you have a Stack<Number> and you invoke push(intVal), where
    intVal is of type Integer. This works because Integer is a subtype of Number. So logically, it seems that this
    should work, too:
        Stack<Number> numberStack = new Stack<>();
        Iterable<Integer> integers = ... ;
        numberStack.pushAll(integers)
    If you try it, however, you’ll get this error message because parameterized types are invariant:
        StackTest.java:7: error: incompatible types: Iterable<Integer> cannot be converted to Iterable<Number>
        numberStack.pushAll(integers);

!!!!
    Luckily, there’s a way out. The language provides a special kind of parameterized type call a bounded wildcard type
    to deal with situations like this. The type of the input parameter to pushAll should not be “Iterable of E” but
    “Iterable of some subtype of E,” and there is a wildcard type that means precisely that: Iterable<? extends E>.
    (The use of the keyword extends is slightly misleading: recall from Item 29 that subtype is defined so that every
    type is a subtype of itself, even though it does not extend itself.) Let’s modify pushAll to use this type:
        // Wildcard type for a parameter that serves as an E producer
        public void pushAll(Iterable<? extends E> src) {
            for (E e : src)
                push(e);
        }

    Now suppose you want to write a popAll method to go with pushAll. The popAll method pops each element off the stack
    and adds the elements to the given collection. Here’s how a first attempt at writing the popAll method might look:
        // popAll method without wildcard type - deficient!
        public void popAll(Collection<E> dst) {
            while (!isEmpty())
                dst.add(pop());
        }

    Again, this compiles cleanly and works fine if the element type of the destination collection exactly matches that
    of the stack. But again, it isn’t entirely satisfactory. Suppose you have a Stack<Number> and variable of type Object.
        Stack<Number> numberStack = new Stack<Number>();
        Collection<Object> objects = ... ;
        numberStack.popAll(objects);
    If you try to compile this client code against the version of popAll shown earlier, you’ll get an error very similar
    to the one that we got with our first version of pushAll: Collection<Object> is not a subtype of Collection<Number>.

    The type of the input parameter to popAll should not be “collection of E” but “collection of some supertype of E”
    (where supertype is defined such that E is a supertype of itself). Again, there is a wildcard type that means
    precisely that: Collection<? super E>.
    Let’s modify popAll to use it:
        // Wildcard type for parameter that serves as an E consumer
        public void popAll(Collection<? super E> dst) {
            while (!isEmpty())
                dst.add(pop());
        }

!!!!
    The lesson is clear. For maximum flexibility, use wildcard types on input parameters that represent producers or
    consumers. If an input parameter is both a producer and a consumer, then wildcard types will do you no good: you
    need an exact type match, which is what you get without any wildcards. Here is a mnemonic to help you remember which
    wildcard type to use:
!!!!       PECS stands for producer-extends, consumer-super.

    In our Stack example, pushAll’s src parameter produces E instances for use by the Stack, so the appropriate type
    for src is Iterable<? extends E>; popAll’s dst parameter consumes E instances from the Stack, so the appropriate
    type for dst is Collection<? super E>

    let’s take a look at some method and constructor declarations from previous items in this chapter.
        (I did that in the item31 code examples : Chooser)

!!!!
    Note that the return type is still Set<E>. Do not use bounded wildcard types as return types. Rather than providing
    additional flexibility for your users, it would force them to use wildcard types in client code.
    Properly used, wildcard types are nearly invisible to the users of a class. They cause methods to accept the
    parameters they should accept and reject those they should reject.
    If the user of a class has to think about wildcard types, there is probably something wrong with its API.

    There is one more wildcard-related topic that bears discussing. There is a duality between type parameters and
    wildcards, and many methods can be declared using one or the other. For example, here are two possible declarations
    for a static method to swap two indexed items in a list. The first uses an unbounded type parameter (Item 30) and
    the second an unbounded wildcard:

        // Two possible declarations for the swap method
        public static <E> void swap(List<E> list, int i, int j);
        public static void swap(List<?> list, int i, int j);

!!!!
    Which of these two declarations is preferable, and why? In a public API, the second is better because it’s simpler.
    You pass in a list—any list—and the method swaps the indexed elements. There is no type parameter to worry about.
    As a rule, if a type parameter appears only once in a method declaration, replace it with a wildcard. If it’s an
    unbounded type parameter, replace it with an unbounded wildcard; if it’s a bounded type parameter, replace it with
    a bounded wildcard.

!!!
    In summary, using wildcard types in your APIs, while tricky, makes the APIs
    far more flexible. If you write a library that will be widely used, the proper use of
    wildcard types should be considered mandatory. Remember the basic rule:
    producer-extends, consumer-super (PECS). Also remember that all comparables
    and comparators are consumers.


Item 32 - Combine generics and varargs judiciously

    Varargs methods (Item 53) and generics were both added to the platform in Java 5,
    so you might expect them to interact gracefully; sadly, they do not. The purpose of
    varargs is to allow clients to pass a variable number of arguments to a method, but
    it is a leaky abstraction: when you invoke a varargs method, an array is created to
    hold the varargs parameters; that array, which should be an implementation detail,
    is visible. As a consequence, you get confusing compiler warnings when varargs
    parameters have generic or parameterized types.

    Recall from Item 28 that a non-reifiable type is one whose runtime representation has less information than its
    compile-time representation, and that nearly all generic and parameterized types are non-reifiable. If a method
    declares its varargs parameter to be of a non-reifiable type, the compiler generates a warning on the
    declaration. If the method is invoked on varargs parameters whose inferred type is non-reifiable, the compiler
    generates a warning on the invocation too. The warnings look something like this:
        warning: [unchecked] Possible heap pollution from parameterized vararg type List<String>

    Heap pollution occurs when a variable of a parameterized type refers to an object that is not of that type. It can
    cause the compiler’s automatically generated casts to fail, violating the fundamental guarantee of the generic type system.

        // Mixing generics and varargs can violate type safety!
        static void dangerous(List<String>... stringLists) {
             List<Integer> intList = List.of(42);
             Object[] objects = stringLists;
             objects[0] = intList;              // Heap pollution
             String s = stringLists[0].get(0); // ClassCastException
        }
    Its last line has an invisible cast that is generated by the compiler. This cast fails, demonstrating that type
    safety has been compromised, and it is unsafe to store a value in a generic varargs array parameter.

    This example raises an interesting question: Why is it even legal to declare a method with a generic varargs parameter,
    when it is illegal to create a generic array explicitly?

    The answer is that methods with varargs parameters of generic or parameterized types can be very useful in practice,
    so the language designers opted to live with this inconsistency. In fact, the Java libraries export several such
    methods, including
        Arrays.asList(T... a),
        Collections.addAll(Collection<? super T> c, T... elements),
        EnumSet.of(E first, E... rest).
    Unlike the dangerous method shown earlier, these library methods are typesafe.

!!!!
    In Java 7, the SafeVarargs annotation was added to the platform, to allow the author of a method with a generic
    varargs parameter to suppress client warnings automatically. In essence, the SafeVarargs annotation constitutes a
    promise by the author of a method that it is typesafe. In exchange for this promise, the compiler agrees not to
    warn the users of the method that calls may be unsafe.

    It is critical that you do not annotate a method with @SafeVarargs unless it
    actually is safe. So what does it take to ensure this? Recall that a generic array is
    created when the method is invoked, to hold the varargs parameters. If the method
    doesn’t store anything into the array (which would overwrite the parameters) and
    doesn’t allow a reference to the array to escape (which would enable untrusted
    code to access the array), then it’s safe. In other words, if the varargs parameter
    array is used only to transmit a variable number of arguments from the caller to
    the method—which is, after all, the purpose of varargs—then the method is safe.

    This example (Dan : from the book I did not put it here because this is so rare IMO that it doesn't make sense for me
    right now) is meant to drive home the point that it is unsafe to give another method access to a generic varargs
    parameter array, with two exceptions: it is safe to pass the array to another varargs method that is correctly
    annotated with @SafeVarargs, and it is safe to pass the array to a non-varargs method that merely computes some
    function of the contents of the array.

    As a reminder, a generic varargs methods is safe if:
    1. it doesn’t store anything in the varargs parameter array, and
    2. it doesn’t make the array (or a clone) visible to untrusted code.

!!!
    In summary, varargs and generics do not interact well because the varargs facility is a leaky abstraction built atop
    arrays, and arrays have different type rules from generics. Though generic varargs parameters are not typesafe, they
    are legal.
    If you choose to write a method with a generic (or parameterized) varargs parameter, first ensure that the method is
    typesafe, and then annotate it with @SafeVarargs so it is not unpleasant to use.


Item 33 - Consider typesafe heterogeneous containers

    Common uses of generics include collections, such as Set<E> and Map<K,V>, and
    single-element containers, such as ThreadLocal<T> and AtomicReference<T>.
    In all of these uses, it is the container that is parameterized. This limits you to a
    fixed number of type parameters per container. Normally that is exactly what you
    want. A Set has a single type parameter, representing its element type; a Map has
    two, representing its key and value types; and so forth.

    When a class literal is passed among methods to communicate both compile-time and runtime type information, it is
    called a type token. (For example, String.class is of type Class<String>, and  Integer.class is of type Class<Integer>)

    The type tokens used by Favorites (see code example from package item33) are unbounded: getFavorite and putFavorite
    accept any Class object. Sometimes you may need to limit the types that can be passed to a method. This can be
    achieved with a bounded type token, which is simply a type token that places a bound on what type can be represented,
    using a bounded type parameter (Item 30) or a bounded wildcard (Item 31)

    In summary, the normal use of generics, exemplified by the collections APIs,
    restricts you to a fixed number of type parameters per container. You can get
    around this restriction by placing the type parameter on the key rather than the
    container. You can use Class objects as keys for such typesafe heterogeneous
    containers. A Class object used in this fashion is called a type token. You can also
    use a custom key type. For example, you could have a DatabaseRow type representing a database row (the container),
    and a generic type Column<T> as its key.
    (from what I understand, in this database example, the DatabaseRow would
    correspond to our Favorites class ...and inside we would have a map, where the key would be Column<T>..meaning the type
    of the column...however...I don't understand how this would work if one had 2 columns with the same type...what would be
    the usefulness?)


===============================================================================================================
===============================================================================================================
Chapter 6 - Enums and Annotations

JAVA supports two special-purpose families of reference types: a kind of class called an enum type, and a kind of
interface called an annotation type. This chapter discusses best practices for using these type families.


Item 34 - Use enums instead of int constants

    An enumerated type is a type whose legal values consist of a fixed set of
    constants, such as the seasons of the year, the planets in the solar system, or the
    suits in a deck of playing cards.

    Before enums, devs had to do the following:
        // The int enum pattern - severely deficient!
        public static final int APPLE_FUJI = 0;
        public static final int APPLE_PIPPIN = 1;
        public static final int APPLE_GRANNY_SMITH = 2;

        public static final int ORANGE_NAVEL = 0;
        public static final int ORANGE_TEMPLE = 1;
        public static final int ORANGE_BLOOD = 2;
!!!
    This technique, known as the int enum pattern, has many shortcomings. It provides nothing in the way of type safety
    and little in the way of expressive power. The compiler won’t complain if you pass an apple to a method that expects
    an orange, compare apples to oranges with the == operator

    There is no easy way to translate int enum constants into printable strings. If you print such a constant or display
    it from a debugger, all you see is a number, which isn’t very helpful. There is no reliable way to iterate over all
    the int enum constants in a group, or even to obtain the size of an int enum group.

    Java’s enum types are full-fledged classes, far more powerful than their counterparts in these other languages,
    where enums are essentially int values.
!!  The basic idea behind Java’s enum types is simple: they are classes that export one instance for each enumeration
    constant via a public static final field. Enum types are effectively final, by virtue of having no accessible
    constructors. Because clients can neither create instances of an enum type nor extend it, there can be no
    instances but the declared enum constants. In other words, enum types are instance-controlled (page 6). They are a
    generalization of singletons (Item 3), which are essentially single-element enums.

!!!
    Enums provide compile-time type safety. If you declare a parameter to be of type Apple, you are guaranteed that
    any non-null object reference passed to the parameter is one of the three valid Apple values.

    Enum types with identically named constants coexist peacefully because each type has its own namespace.
    Finally, you can translate enums into printable strings by calling their toString method.

    Enums provide high-quality implementations of all the Object methods (Chapter 3), they implement Comparable
    (Item 14) and Serializable (Chapter 12), and their serialized form is designed to withstand most changes to the
    enum type.

    So why would you want to add methods or fields to an enum type? For starters, you might want to associate data with
    its constants. Our Apple and Orange types, for example, might benefit from a method that returns the color of the fruit,
    or one that returns an image of it. You can augment an enum type with any method that seems appropriate.

!!!
    It is easy to write a rich enum type such as Planet (see code examples). To associate data with
    enum constants, declare instance fields and write a constructor that takes the
    data and stores it in the fields. Enums are by their nature immutable, so all fields
    should be final (Item 17). Fields can be public, but it is better to make them private
    and provide public accessors (Item 16).

    Just as with other classes, unless you have a compelling reason to expose an enum method to its clients, declare it
    private or, if need be, package-private (Item 15).
    If an enum is generally useful, it should be a top-level class; if its use is tied to a specific top-level class,
    it should be a member class of that top-level class (Item 24).

!!!
    There is a better way to associate a different behavior with each enum constant: declare an abstract apply method
    in the enum type, and override it with a concrete method for each constant in a constant-specific class body.
    Such methods are known as constant-specific method implementations
        (see example in class Operation from item34 package)

!!!
    Switches on enums are good for augmenting enum types with constant-specific behavior. For example, suppose the
    Operation enum is not under your control and you wish it had an instance method to return the inverse of each
    operation. You could simulate the effect with the following static method:
        // Switch on an enum to simulate a missing method
        public static Operation inverse(Operation op) {
            switch(op) {
                case PLUS: return Operation.MINUS;
                case MINUS: return Operation.PLUS;
                case TIMES: return Operation.DIVIDE;
                case DIVIDE: return Operation.TIMES;
                default: throw new AssertionError("Unknown op: " + op);
            }
        }

    So when should you use enums? Use enums any time you need a set of constants whose members are known at compile time.
    It is not necessary that the set of constants in an enum type stay fixed for all time. The enum feature was specifically
    designed to allow for binary compatible evolution of enum types.

    In summary, the advantages of enum types over int constants are compelling.
    Enums are more readable, safer, and more powerful. Many enums require no
    explicit constructors or members, but others benefit from associating data with
    each constant and providing methods whose behavior is affected by this data.
    Fewer enums benefit from associating multiple behaviors with a single method. In
    this relatively rare case, prefer constant-specific methods to enums that switch on
    their own values. Consider the strategy enum pattern if some, but not all, enum
    constants share common behaviors.


Item 35 - Use instance fields instead of ordinals

    Many enums are naturally associated with a single int value. All enums have an
    ordinal method, which returns the numerical position of each enum constant in
    its type. You may be tempted to derive an associated int value from the ordinal:

        // Abuse of ordinal to derive an associated value - DON'T DO THIS
        public enum Ensemble {
            SOLO, DUET, TRIO, QUARTET, QUINTET, SEXTET, SEPTET, OCTET, NONET, DECTET;
            public int numberOfMusicians() { return ordinal() + 1; }
        }

    While this enum works, it is a maintenance nightmare. If the constants are reordered, the numberOfMusicians method
    will break. If you want to add a second enum constant associated with an int value that you’ve already used, you’re
    out of luck. For example, it might be nice to add a constant for double quartet, which, like an octet, consists of
    eight musicians, but there is no way to do it.

    Also, you can’t add a constant for an int value without adding constants for all intervening int values. For example,
    suppose you want to add a constant representing a triple quartet, which consists of twelve musicians. There is no standard
    term for an ensemble consisting of eleven musicians, so you are forced to add a dummy constant for the unused int
    value (11). At best, this is ugly. If many int values are unused, it’s impractical.

    Luckily, there is a simple solution to these problems. Never derive a value associated with an enum from its
    ordinal; store it in an instance field instead:

        public enum Ensemble {
            SOLO(1), DUET(2), TRIO(3), QUARTET(4), QUINTET(5),
            SEXTET(6), SEPTET(7), OCTET(8), DOUBLE_QUARTET(8),
            NONET(9), DECTET(10), TRIPLE_QUARTET(12);
            private final int numberOfMusicians;
            Ensemble(int size) { this.numberOfMusicians = size; }
            public int numberOfMusicians() { return numberOfMusicians; }
        }
!!!
    The Enum specification has this to say about ordinal: “Most programmers will have no use for this method. It is
    designed for use by general-purpose enumbased data structures such as EnumSet and EnumMap.” Unless you are writing code
    with this character, you are best off avoiding the ordinal method entirely.


Item 36 - Use EnumSet instead of bit fields

    But bit fields have all the disadvantages of int enum constants and more. It is even harder to interpret a bit
    field than a simple int enum constant when it is printed as a number

    Some programmers who use enums in preference to int constants still cling to the use of bit fields when they need
    to pass around sets of constants. There is no reason to do this, because a better alternative exists. The java.util
    package provides the EnumSet class to efficiently represent sets of values drawn from a single enum type. This class
    implements the Set interface, providing all of the richness, type safety, and interoperability you get with any other
    Set implementation. But internally, each EnumSet is represented as a bit vector

    But you are insulated from the ugliness and error-proneness of manual bit twiddling: the EnumSet does
    the hard work for you.

    In summary, just because an enumerated type will be used in sets, there is no reason to represent it with bit fields.
    The EnumSet class combines the conciseness and performance of bit fields with all the many advantages of enum types
    described in Item 34. The one real disadvantage of EnumSet is that it is not, as of Java 9, possible to create an
    immutable EnumSet, but this will likely be remedied in an upcoming release. In the meantime, you can wrap an EnumSet with
    Collections.unmodifiableSet, but conciseness and performance will suffer.


Item 37 - Use EnumMap instead of ordinal indexing

    Occasionally you may see code that uses the ordinal method (Item 35) to index  into an array or list.
        (example is in the book...basically using the ordinal of an enum value as index in an array or list..is BAD)

    But the most serious problem with this technique is that when you access an array that is indexed by an enum’s ordinal,
    it is your responsibility to use the correct int value; ints do not provide the type safety of enums. If you use the
    wrong value, the program will silently do the wrong thing or—if you’re lucky—throw an ArrayIndexOutOfBoundsException.

!!!
    More specifically, there is a very fast Map implementation designed for use with enum keys, known as java.util.EnumMap.
    Here is how the program looks when it is rewritten to use EnumMap

    In summary, it is rarely appropriate to use ordinals to index into arrays: use EnumMap instead. If the relationship
    you are representing is multidimensional, use EnumMap<..., EnumMap<...>>. This is a special case of the general principle
    that application programmers should rarely, if ever, use Enum.ordinal (Item 35)


Item 38 - Emulate extensible enums with interfaces

    For the most part, extensibility of enums turns out to be a bad idea.
    That said, there is at least one compelling use case for extensible enumerated types, which is operation codes, also
    known as opcodes. An opcode is an enumerated type whose elements represent operations on some machine, such as the
    Operation type in Item 34, which represents the functions on a simple calculator.
    Sometimes it is desirable to let the users of an API provide their own operations, effectively extending the set of
    operations provided by the API.

!!!!
    Luckily, there is a nice way to achieve this effect using enum types. The basic idea is to take advantage of the fact
    that enum types can implement arbitrary interfaces by defining an interface for the opcode type and an enum that is
    the standard implementation of the interface
            (see code examples)

    You can now use your new operations anywhere you could use the basic operations, provided that APIs are written to
    take the interface type (Operation), not the implementation (BasicOperation).

    A minor disadvantage of the use of interfaces to emulate extensible enums is that implementations cannot be inherited
    from one enum type to another. If the implementation code does not rely on any state, it can be placed in the interface,
    using default implementations (Item 20). In the case of our Operation example, the logic to store and retrieve the
    symbol associated with an operation must be duplicated in BasicOperation and ExtendedOperation. In this case it doesn’t
    matter because very little code is duplicated. If there were a larger amount of shared functionality, you could
    encapsulate it in a helper class or a static helper method to eliminate the code duplication.

    In summary, while you cannot write an extensible enum type, you can
    emulate it by writing an interface to accompany a basic enum type that
    implements the interface. This allows clients to write their own enums (or other
    types) that implement the interface. Instances of these types can then be used
    wherever instances of the basic enum type can be used, assuming APIs are written
    in terms of the interface.


Item 39 - Prefer annotations to naming patterns

    Historically, it was common to use naming patterns to indicate that some program
    elements demanded special treatment by a tool or framework. For example, prior
    to release 4, the JUnit testing framework required its users to designate test methods by beginning their names with
    the characters "test"
    This technique works, but it has several big disadvantages. First, typographical errors result in
    silent failures. For example, suppose you accidentally named a test method tsetSafetyOverride instead of
    testSafetyOverride. JUnit 3 wouldn’t complain, but it wouldn’t execute the test either, leading to a false sense of
    security.

    Annotations solve all of these problems nicely, and JUnit adopted them starting with release 4.

!!!
    There is simply no reason to use naming patterns when you can use annotations instead.
    That said, with the exception of toolsmiths, most programmers will have no need to define annotation types.
    But all programmers should use the predefined annotation types that Java provides (Items 40, 27).
    Also, consider using the annotations provided by your IDE or static analysis tools. Such annotations can
    improve the quality of the diagnostic information provided by these tools. Note,
    however, that these annotations have yet to be standardized, so you may have
    some work to do if you switch tools or if a standard emerges.


Item 40 - Consistently use the Override annotation

    The Java libraries contain several annotation types. For the typical programmer,
    the most important of these is @Override. This annotation can be used only on
    method declarations, and it indicates that the annotated method declaration overrides a declaration in a supertype.
    If you consistently use this annotation, it will protect you from a large class of nefarious bugs

    Clearly, the author of the Bigram class (example in the book with the type of errors that can occur because of the lack
    of usage for @Override) intended to override the equals method (Item 10) and even remembered to
    override hashCode in tandem (Item 11). Unfortunately, our hapless programmer failed to override equals, overloading
    it instead (Item 52). To override Object.equals, you must define an equals method whose parameter is of type Object,
    but the parameter of Bigram’s equals method is not of type Object, so Bigram inherits the equals method from Object

    Luckily, the compiler can help you find this error, but only if you help it by telling it that you intend to override
    Object.equals. To do this, annotate Bigram.equals with @Override, as shown here:
        @Override public boolean equals(Bigram b) {
            return b.first == first && b.second == second;
        }

    If you insert this annotation and try to recompile the program, the compiler will generate an error message like this:
        Bigram.java:10: method does not override or implement a method
        from a supertype
        @Override public boolean equals(Bigram b) {

    You will immediately realize what you did wrong, slap yourself on the forehead, and replace the broken equals
    implementation with a correct one (Item 10):
        @Override
        public boolean equals(Object o) {
            if (!(o instanceof Bigram))
                return false;
            Bigram b = (Bigram) o;
            return b.first == first && b.second == second;
        }

!!!
    Therefore, you should use the Override annotation on every method declaration that you believe to override a superclass
    declaration. There is one minor exception to this rule. If you are writing a class that is not labeled abstract and you
    believe that it overrides an abstract method in its superclass, you needn’t bother
    putting the Override annotation on that method. In a class that is not declared
    abstract, the compiler will emit an error message if you fail to override an abstract superclass method.

    The Override annotation may be used on method declarations that override
    declarations from interfaces as well as classes. With the advent of default methods, it is good practice to use Override
    on concrete implementations of interface methods to ensure that the signature is correct.

!!!!
    In an abstract class or an interface, however, it is worth annotating all methods
    that you believe to override superclass or superinterface methods, whether concrete or abstract. For example, the Set
    interface adds no new methods to the Collection interface, so it should include Override annotations on all of its
    method declarations to ensure that it does not accidentally add any new methods to the Collection interface

    In summary, the compiler can protect you from a great many errors if you use
    the Override annotation on every method declaration that you believe to override
    a supertype declaration, with one exception. In concrete classes, you need not
    annotate methods that you believe to override abstract method declarations
    (though it is not harmful to do so).


Item 41 - Use marker interfaces to define types

    A marker interface is an interface that contains no method declarations but merely
    designates (or “marks”) a class that implements the interface as having some
    property. For example, consider the Serializable interface (Chapter 12). By
    implementing this interface, a class indicates that its instances can be written to an ObjectOutputStream (or “serialized”).

!!!
    You may hear it said that marker annotations (Item 39) make marker interfaces obsolete. This assertion is incorrect.
    Marker interfaces have two advantages over marker annotations. First and foremost, marker interfaces define a type
    that is implemented by instances of the marked class; marker annotations do not. The existence of a marker interface
    type allows you to catch errors at compile time that you couldn’t catch until runtime if you used a marker annotation
    Compile-time error detection is the intent of marker interfaces (unfortunately Serializable is not a good example
    because the writers of the API did not take advantage of this when they wrote the code for ObjectOutputStream.write,
    whose parameter should have been a Serializable, not an Object, and thus it would have detected if an object that
    is not a Serializable is passed to that method at compile time not at run time as it happens now:/ )


    Another advantage of marker interfaces over marker annotations is that they can be targeted more precisely. If an
    annotation type is declared with target ElementType.TYPE, it can be applied to any class or interface. Suppose you have
    a marker that is applicable only to implementations of a particular interface. If you define it as a marker interface,
    you can have it extend the sole interface to which it is applicable, guaranteeing that all marked types are also
    subtypes of the sole interface to which it is applicable.

    The chief advantage of marker annotations over marker interfaces is that they are part of the larger annotation
    facility. Therefore, marker annotations allow for consistency in annotation-based frameworks.

!!!!
    So when should you use a marker annotation and when should you use a marker interface? Clearly you must use an
    annotation if the marker applies to any program element other than a class or interface, because only classes and
    interfaces can be made to implement or extend an interface. If the marker applies only to classes and interfaces,
    ask yourself the question “Might I want to write one or more methods that accept only objects that have this
    marking?” If so, you should use a marker interface in preference to an annotation. This will make it possible
    for you to use the interface as a parameter type for the methods in question, which will result in the benefit of
    compile-time type checking. If you can convince yourself that you’ll never want to write a method that accepts only
    objects with the marking, then you’re probably better off using a marker annotation. If, additionally, the marking
    is part of a framework that makes heavy use of annotations, then a marker annotation is the clear choice.

    In summary, marker interfaces and marker annotations both have their uses. If you want to define a type that does
    not have any new methods associated with it, a marker interface is the way to go. If you want to mark program elements other
    than classes and interfaces or to fit the marker into a framework that already makes heavy use of annotation types,
    then a marker annotation is the correct choice. If you find yourself writing a marker annotation type whose target is
    ElementType.TYPE, take the time to figure out whether it really should be an annotation type or whether a marker
    interface would be more appropriate.
    In a sense, this item is the inverse of Item 22, which says, “If you don’t want to define a type, don’t use an
    interface.” To a first approximation, this item says, “If you do want to define a type, do use an interface.”


===============================================================================================================
===============================================================================================================
Chapter 7 - Lambdas and Streams

In Java 8, functional interfaces, lambdas, and method references were added to make it easier to create function objects.
The streams API was added in tandem with these language changes to provide library support for processing sequences of
data elements.


Item 42 - Prefer lambdas to anonymous classes

    Historically, interfaces (or, rarely, abstract classes) with a single abstract method
    were used as function types. Their instances, known as function objects, represent
    functions or actions. Since JDK 1.1 was released in 1997, the primary means of
    creating a function object was the anonymous class (Item 24).

    Example of sorting of strings by length using an anonymous class ...(that is now obsolete because of lambdas)

    // Anonymous class instance as a function object - obsolete!
    Collections.sort(words, new Comparator<String>() {
        public int compare(String s1, String s2) {
            return Integer.compare(s1.length(), s2.length());
        }
    });

    Anonymous classes were adequate for the classic objected-oriented design patterns requiring function objects, notably
    the Strategy pattern [Gamma95]. The Comparator interface represents an abstract strategy for sorting; the anonymous
    class above is a concrete strategy for sorting strings. The verbosity of anonymous classes, however, made functional
    programming in Java an unappealing prospect.

!!!
    In Java 8, the language formalized the notion that interfaces with a single abstract method are special and deserve
    special treatment. These interfaces are now known as functional interfaces, and the language allows you to create
    instances of these interfaces using lambda expressions, or lambdas for short.

    Lambdas are similar in function to anonymous classes, but far more concise. Here’s how the code snippet above looks
    with the anonymous class replaced by a lambda. The boilerplate is gone, and the behavior is clearly evident:

    // Lambda expression as function object (replaces anonymous class)
    Collections.sort(words, (s1, s2) -> Integer.compare(s1.length(), s2.length()));

    Note that the types of the lambda (Comparator<String>), of its parameters (s1 and s2, both String), and of its return
    value (int) are not present in the code. The compiler deduces these types from context, using a process known as type
    inference. In some cases, the compiler won’t be able to determine the types, and you’ll have to specify them.
!!!
    Omit the types of all lambda parameters unless their presence makes your program clearer.
    If the compiler generates an error telling you it can’t infer the type of a lambda parameter, then specify it
!!!!
    Item 26 tells you not to use raw types, Item 29 tells you to favor generic types, and Item 30 tells you to
    favor generic methods. This advice is doubly important when you’re using lambdas, because the compiler obtains most
    of the type information that allows it to perform type inference from generics. If you don’t provide this information, the
    compiler will be unable to do type inference, and you’ll have to specify types manually in your lambdas, which will
    greatly increase their verbosity. By way of example, the code snippet above won’t compile if the variable words is
    declared to be of the raw type List instead of the parameterized type List<String>.

    Incidentally, the comparator in the snippet can be made even more succinct if
    a comparator construction method is used in place of a lambda (Items 14. 43):
    Collections.sort(words, comparingInt(String::length));

!!!
    Unlike methods and classes, lambdas lack names and documentation; if a computation isn’t self-explanatory, or
    exceeds a few lines, don’t put it in a lambda
!!!! One line is ideal for a lambda, and three lines is a reasonable maximum.
    If you violate this rule, it can cause serious harm to the readability of your programs. If a lambda is long or
    difficult to read, either find a way to simplify it or refactor your program to eliminate it.

    Also, the arguments passed to enum constructors are evaluated in a static context. Thus, lambdas in enum constructors
    can’t access instance members of the enum.
    Constant-specific class bodies (like in item34 -> Operation) are still the way to go if an enum type has
    constant-specific behavior that is difficult to understand, that can’t be implemented in a few lines, or that requires
    access to instance fields or methods.

!!!
    Likewise, you might think that anonymous classes are obsolete in the era of lambdas. This is closer to the truth,
    but there are a few things you can do with anonymous classes that you can’t do with lambdas. Lambdas are limited to
    functional interfaces. If you want to create an instance of an abstract class, you can do it with an anonymous class,
    but not a lambda. Similarly, you can use anonymous classes to create instances of interfaces with multiple abstract
    methods. Finally, a lambda cannot obtain a reference to itself. In a lambda, the this keyword refers to
    the enclosing instance, which is typically what you want. In an anonymous class, the this keyword refers to the
    anonymous class instance. If you need access to the function object from within its body, then you must use an
    anonymous class.

    In summary, as of Java 8, lambdas are by far the best way to represent small function objects. Don’t use anonymous
    classes for function objects unless you have to create instances of types that aren’t functional interfaces. Also,
    remember that lambdas make it so easy to represent small function objects that it opens the door to functional
    programming techniques that were not previously practical in Java.


Item 43- Prefer method references to lambdas

    The primary advantage of lambdas over anonymous classes is that they are more succinct. Java provides a way to
    generate function objects even more succinct than lambdas: method references

        map.merge(key, 1, (count, incr) -> count + incr);

    As of Java 8, Integer (and all the other boxed numerical primitive types) provides a static method sum that does
    exactly the same thing. We can simply pass a reference to this method and get the same result with less visual clutter:

        map.merge(key, 1, Integer::sum);

!!  In some lambdas, however, the parameter names you choose provide useful documentation, making the lambda more
    readable and maintainable than a method reference, even if the lambda is longer.

!!!!
    That said, method references usually result in shorter, clearer code. They also give you an out if a lambda gets too
    long or complex: You can extract the code from the lambda into a new method and replace the lambda with a reference
    to that method. You can give the method a good name and document it to your heart’s content

    Occasionally, a lambda will be more succinct than a method reference. This happens most often when the method is in
    the same class as the lambda. For example, consider this snippet, which is presumed to occur in a class
    named GoshThisClassNameIsHumongous:

        service.execute(GoshThisClassNameIsHumongous::action);

    The lambda equivalent looks like this:
        service.execute(() -> action());

    Along similar lines, the Function interface provides a generic static factory method to return the identity function,
    Function.identity(). It’s typically shorter and cleaner not to use this method but to code the equivalent lambda
    inline: x -> x.

    Many method references refer to static methods, but there are four kinds that do not. Two of them are bound and
    unbound instance method references. In bound references, the receiving object is specified in the method reference. Bound
    references are similar in nature to static references: the function object takes the same arguments as the referenced
    method. In unbound references, the receiving object is specified when the function object is applied, via an
    additional parameter before the method’s declared parameters. Unbound references are often used as
    mapping and filter functions in stream pipelines (Item 45). Finally, there are two kinds of constructor references,
    for classes and arrays. Constructor references serve as factory objects. All five kinds of method references are
    summarized in the table below

        Method Ref Type                 Example                                     Lambda Equivalent
        Static                          Integer::parseInt                           str -> Integer.parseInt(str)
        Bound                           Instant.now()::isAfter                      Instant then = Instant.now();
                                                                                    t -> then.isAfter(t)
        Unbound                         String::toLowerCase                         str -> str.toLowerCase()
        Class Constructor               TreeMap<K,V>::new                           () -> new TreeMap<K,V>
        Array Constructor               int[]::new                                  len -> new int[len]

    In summary, method references often provide a more succinct alternative to lambdas. Where method references are
    shorter and clearer, use them; where they aren’t, stick with lambdas.


Item 44 - Favor the use of standard functional interfaces

    Now that Java has lambdas, best practices for writing APIs have changed considerably.
    For example, the Template Method pattern [Gamma95], wherein a subclass overrides a primitive method to specialize
    the behavior of its superclass, is far less attractive.
    The modern alternative is to provide a static factory or constructor that accepts a function object to achieve the
    same effect. More generally, you’ll be writing more constructors and methods that take function objects as parameters.
    Choosing the right functional parameter type demands care.

    The java.util.function package provides a large collection of standard functional interfaces for your use.

!!! If one of the standard functional interfaces does the job, you should generally use it in preference to a purpose-built
    functional interface. This will make your API easier to learn, by reducing its conceptual surface area, and will provide
    significant interoperability benefits, as many of the standard functional interfaces provide useful default methods.

!!!!!!
    There are forty-three interfaces in java.util.Function. You can’t be expected to remember them all, but if you
    remember six basic interfaces, you can derive the rest when you need them. The basic interfaces operate on object
    reference types.
        1. The Operator interfaces represent functions whose result and argument types are the same
        2. The Predicate interface represents a function that takes an argument and returns a boolean.
        3. The Function interface represents a function whose argument and return types differ
        4. The Supplier interface represents a function that takes no arguments and returns (or “supplies”) a value
        5. Finally, Consumer represents a function that takes an argument and returns nothing, essentially consuming its argument

    Interface               Function Signature                          Example
    UnaryOperator<T>        T apply(T t)                                String::toLowerCase
    BinaryOperator<T>       T apply(T t1, T t2)                         BigInteger::add
    Predicate<T>            boolean test(T t)                           Collection::isEmpty
    Function<T,R>           R apply(T t)                                Arrays::asList
    Supplier<T>             T get()                                     Instant::now
    Consumer<T>             void accept(T t)                            System.out::println

!!!
    Most of the standard functional interfaces exist only to provide support for primitive types. Don’t be tempted to
    use basic functional interfaces with boxed primitives instead of primitive functional interfaces. While it works,
    it violates the advice of Item 61, “prefer primitive types to boxed primitives.” The performance consequences of
    using boxed primitives for bulk operations can be deadly

    Of course you need to write your own if none of the standard ones does what you need, for example if you require a
    predicate that takes three parameters, or one that throws a checked exception

    You should seriously consider writing a purpose-built functional interface in preference to using a standard one if
    you need a functional interface that shares one or more of the following characteristics with Comparator:
    • It will be commonly used and could benefit from a descriptive name.
    • It has a strong contract associated with it.
    • It would benefit from custom default methods

!!!
    Always annotate your functional interfaces with the @FunctionalInterface annotation.
    This annotation type is similar in spirit to @Override. It is a statement of programmer intent that serves three
    purposes: it tells readers of the class and its documentation that the interface was designed to enable lambdas; it
    keeps you honest because the interface won’t compile unless it has exactly one abstract method; and it prevents
    maintainers from accidentally adding abstract methods to the interface as it evolves

    In summary, now that Java has lambdas, it is imperative that you design your APIs with lambdas in mind. Accept
    functional interface types on input and return them on output. It is generally best to use the standard interfaces
    provided in java.util.function.Function, but keep your eyes open for the relatively rare cases where you would be
    better off writing your own functional interface.


Item 45 - Use streams judiciously

    The streams API was added in Java 8 to ease the task of performing bulk operations, sequentially or in parallel.
!!!! This API provides two key abstractions: the stream, which represents a finite or infinite sequence of data elements,
    and the stream pipeline, which represents a multistage computation on these elements.
    The elements in a stream can come from anywhere. Common sources include collections, arrays, files, regular expression
    pattern matchers, pseudorandom number generators, and other streams.
    The data elements in a stream can be object references or primitive values.
    Three primitive types are supported: int, long, and double.

    A stream pipeline consists of a source stream followed by zero or more intermediate operations and one terminal
    operation. Each intermediate operation transforms the stream in some way, such as mapping each element to a function of
    that element or filtering out all elements that do not satisfy some condition.

    he terminal operation performs a final computation on the stream resulting from the last intermediate
    operation, such as storing its elements into a collection, returning a certain element, or printing all of its elements.
!!!!
    Stream pipelines are evaluated lazily: evaluation doesn’t start until the terminal operation is invoked, and data
    elements that aren’t required in order to complete the terminal operation are never computed

    The streams API is fluent: it is designed to allow all of the calls that comprise a pipeline to be chained into a
    single expression. In fact, multiple pipelines can be chained together into a single expression

    By default, stream pipelines run sequentially. Making a pipeline execute in parallel is as simple as invoking the
    parallel method on any stream in the pipeline, but it is seldom appropriate to do so (Item 48).

!!!
    The streams API is sufficiently versatile that practically any computation can be performed using streams, but just
    because you can doesn’t mean you should. When used appropriately, streams can make programs shorter and clearer; when
    used inappropriately, they can make programs difficult to read and maintain.

!!! Overusing streams makes programs hard to read and maintain.

    In the absence of explicit types, careful naming of lambda parameters is essential to the readability of stream pipelines.
    Using helper methods is even more important for readability in stream pipelines than in iterative code
    because pipelines lack explicit type information and named temporary variables.

    When you start using streams, you may feel the urge to convert all your loops into streams, but resist the urge.
    While it may be possible, it will likely harm the readability and maintainability of your code base
!!! So refactor existing code to use streams and use them in new code only where it makes sense to do so.

    There are some things you can do from code blocks that you can’t do from function objects:
        • From a code block, you can read or modify any local variable in scope; from a lambda, you can only read final
        or effectively final variables, and you can’t modify any local variables.
        • From a code block, you can return from the enclosing method, break or continue an enclosing loop, or throw any
         checked exception that this method is declared to throw; from a lambda you can do none of these things.

    Conversely, streams make it very easy to do some things:
        • Uniformly transform sequences of elements
        • Filter sequences of elements
        • Combine sequences of elements using a single operation (for example to add them, concatenate them, or compute
        their minimum)
        • Accumulate sequences of elements into a collection, perhaps grouping them by some common attribute
        • Search a sequence of elements for an element satisfying some criterion

    In summary, some tasks are best accomplished with streams, and others with
    iteration. Many tasks are best accomplished by combining the two approaches.
    In many cases, it will be clear which approach to
    use; in some cases, it won’t. If you’re not sure whether a task is better served
    by streams or iteration, try both and see which works better.


Item 46 - Prefer side-effect-free functions in streams

    If you’re new to streams, it can be difficult to get the hang of them. Merely expressing your computation as a stream
    pipeline can be hard.
    Streams isn’t just an API, it’s a paradigm based on functional programming. In order to obtain the
    expressiveness, speed, and in some cases parallelizability that streams have to offer, you have to adopt the paradigm
    as well as the API.

!!!!
    The most important part of the streams paradigm is to structure your computation as a sequence of transformations where
    the result of each stage is as close as possible to a pure function of the result of the previous stage.
    A pure function is one whose result depends only on its input: it does not depend on any mutable state, nor does it
    update any state. In order to achieve this, any function objects that you pass into stream operations, both intermediate
    and terminal, should be free of side-effects.

    Occasionally, you may see streams code that looks like this snippet, which builds a frequency table of the words in a
    text file:

        // Uses the streams API but not the paradigm--Don't do this!
        Map<String, Long> freq = new HashMap<>();
        try (Stream<String> words = new Scanner(file).tokens()) {
            words.forEach(word -> {
            freq.merge(word.toLowerCase(), 1L, Long::sum);
        });
        }

    What’s wrong with this code? After all, it uses streams, lambdas, and method references, and gets the right answer.
    Simply put, it’s not streams code at all; it’s iterative code masquerading as streams code. It derives no benefits
    from the streams API, and it’s (a bit) longer, harder to read, and less maintainable than the
!!!  corresponding iterative code. The problem stems from the fact that this code is doing all its work in a terminal
    forEach operation, using a lambda that mutates external state (the frequency table).
!!!  A forEach operation that does  anything more than present the result of the computation performed by a stream is a
    “bad smell in code,” as is a lambda that mutates state. So how should this code look?

        // Proper use of streams to initialize a frequency table
        Map<String, Long> freq;
        try (Stream<String> words = new Scanner(file).tokens()) {
            freq = words.collect(groupingBy(String::toLowerCase, counting()));
        }

    This snippet does the same thing as the previous one but makes proper use of the streams API. It’s shorter and clearer.
    So why would anyone write it the other way? Because it uses tools they’re already familiar with. Java programmers know
    how to use for-each loops, and the forEach terminal operation is similar. B

!!! The forEach operation should be used only to report the result of a stream computation, not to perform the computation.
    Occasionally, it makes sense to use forEach for some other purpose, such as adding the results of a
    stream computation to a preexisting collection

!!! The Collectors API is intimidating: it has 39 methods, some of which have as many as five type parameters. The good
    news is that you can derive most of the benefit from this API without delving into its full complexity. For starters,
    you can ignore the Collector interface and think of a collector as an opaque object that encapsulates a reduction
    strategy. In this context, reduction means combining the elements of a stream into a single object.
    The object produced by a collector is typically a collection (which accounts for the name collector).

    The collectors for gathering the elements of a stream into a true Collection are straightforward. There are three
    such collectors: toList(), toSet(), and toCollection(collectionFactory). They return, respectively, a set, a list, and
    a programmer-specified collection type
!!!
    It is customary and wise to statically import all members of Collectors because it makes stream pipelines more readable.

    So what about the other thirty-six methods in Collectors? Most of them exist to let you collect streams into maps,
    which is far more complicated than collecting them into true collections. Each stream element is associated with a key
    and a value, and multiple stream elements can be associated with the same key

    The simplest map collector is toMap(keyMapper, valueMapper), which takes two functions, one of which maps a stream
    element to a key, the other, to a value.

        // Using a toMap collector to make a map from string to enum
        private static final Map<String, Operation> stringToEnum = Stream.of(values()).collect(toMap(Object::toString, e -> e));

!!!!
    This simple form of toMap is perfect if each element in the stream maps to a unique key. If multiple stream elements
    map to the same key, the pipeline will terminate with an IllegalStateException
!!!
    The more complicated forms of toMap, as well as the groupingBy method, give you various ways to provide strategies
    for dealing with such collisions. One way is to provide the toMap method with a merge function in addition to its key
    and value mappers. The merge function is a BinaryOperator<V>, where V is the value type of the map. Any additional
    values associated with a key are combined with the existing value using the merge function, so, for example, if the merge
    function is multiplication, you end up with a value that is the product of all the values associated with the key
    by the value mapper.

    Another use of the three-argument form of toMap is to produce a collector that imposes a last-write-wins policy when
    there are collisions. For many streams, the results will be nondeterministic, but if all the values that may be
    associated with a key by the mapping functions are identical, or if they are all acceptable, this collector’s s behavior
    may be just what you want:
        // Collector to impose last-write-wins policy
        toMap(keyMapper, valueMapper, (v1, v2) -> v2)

    The third and final version of toMap takes a fourth argument, which is a map factory, for use when you want to
    specify a particular map implementation such as an EnumMap or a TreeMap.

    In addition to the toMap method, the Collectors API provides the groupingBy method, which returns collectors to produce
    maps that group elements into categories based on a classifier function. The classifier function takes an element
    and returns the category into which it falls. This category serves as the element’s map key. The simplest version of
    the groupingBy method takes only a classifier and returns a map whose values are lists of all the elements in each
    category. This is the collector that we used in the Anagram program in Item 45 to generate a map from
    alphabetized word to a list of the words sharing the alphabetization:

        words.collect(groupingBy(word -> alphabetize(word)))

    Another simple use of the two-argument form of groupingBy is to pass counting() as the downstream collector. This
    results in a map that associates each category with the number of elements in the category, rather than a collection
    containing the elements. That’s what you saw in the frequency table example at the beginning of this item:

        Map<String, Long> freq = words.collect(groupingBy(String::toLowerCase, counting()));

    The final Collectors method is joining, which operates only on streams of CharSequence instances such as strings.
    In its parameterless form, it returns a collector that simply concatenates the elements. Its one argument form takes a single
    CharSequence parameter named delimiter and returns a collector that joins the stream elements, inserting the delimiter
    between adjacent elements. If you pass in a comma as the delimiter, the collector returns a comma-separated values string
    (but beware that the string will be ambiguous if any of the elements in the stream contain commas). The three argument
    form takes a prefix and suffix in addition to the delimiter. The resulting collector generates strings like the ones
    that you get when you print a collection, for example [came, saw, conquered].

!!!
    In summary, the essence of programming stream pipelines is side-effect-free function objects. This applies to all of
    the many function objects passed to streams and related objects. The terminal operation forEach should only be used
    to report the result of a computation performed by a stream, not to perform the computation. In order to use streams
    properly, you have to know about collectors. The most important collector factories are toList, toSet, toMap,
    groupingBy, and joining.


Item 47 - Prefer Collection to Stream as a return type

    Many methods return sequences of elements. Prior to Java 8, the obvious return types for such methods were the
    collection interfaces Collection, Set, and List; Iterable; and the array types. Usually, it was easy to decide which
    of these types to return. The norm was a collection interface. If the method existed solely to enable for-each loops
    or the returned sequence couldn’t be made to implement some Collection method (typically, contains(Object)), the
    Iterable interface was used. If the returned elements were primitive values or there were stringent performance
    requirements, arrays were used. In Java 8, streams were added to the platform, substantially complicating the task
    of choosing the appropriate return type for a sequence-returning method

        (Adapters class is intended to be use to switch from a Iterable to a Stream and backwards...the java API does
        not include such a useful method unfortunately)

    If you’re writing a method that returns a sequence of objects and you know that it will only be used in a stream
    pipeline, then of course you should feel free to return a stream. Similarly, a method returning a sequence that will
    only be used for iteration should return an Iterable. But if you’re writing a public API that
    returns a sequence, you should provide for users who want to write stream pipelines as well as those who want to
    write for-each statements, unless you have a good reason to believe that most of your users will want to use the same
    mechanism

!!! The Collection interface is a subtype of Iterable and has a stream method, so it provides for both iteration and stream
    access. Therefore, Collection or an appropriate subtype is generally the best return type for a public, sequence returning
    method. Arrays also provide for easy iteration and stream access with the Arrays.asList and Stream.of methods.

!!! If the sequence you’re returning is small enough to fit easily in memory, you’re probably best off returning one of the
    standard collection implementations, such as ArrayList or HashSet. But do not store a large sequence in memory just
    to return it as a collection.

    If the sequence you’re returning is large but can be represented concisely, consider implementing a special-purpose
    collection. For example, suppose you want to return the power set of a given set, which consists of all of its subsets. The
    power set of {a, b, c} is {{}, {a}, {b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c}}. If a
    set has n elements, its power set has 2^n . Therefore, you shouldn’t even consider storing the power set in a standard
    collection implementation. It is, however, easy to implement a custom collection for the job with the help of AbstractList.

        (in the book he presents a solution on how to implement such a collection)

    In summary, when writing a method that returns a sequence of elements, remember that some of your users may want to
    process them as a stream while others may want to iterate over them. Try to accommodate both groups. If it’s feasible
    to return a collection, do so. If you already have the elements in a collection or the number of elements in the
    sequence is small enough to justify creating a new one, return a standard collection such as ArrayList. Otherwise, consider
    implementing a custom collection as we did for the power set. If it isn’t feasible to return a collection, return a
    stream or iterable, whichever seems more natural. If, in a future Java release, the Stream interface declaration is
    modified to extend Iterable, then you should feel free to return streams because they will allow for both stream
    processing and iteration.


Item 48 - Use caution when making streams parallel

    Java 7 introduced the fork-join package, a highperformance framework for parallel decomposition. Java 8 introduced streams,
    which can be parallelized with a single call to the parallel method. Writing concurrent programs in Java keeps getting
    easier, but writing concurrent programs that are correct and fast is as difficult as it ever was

    Safety and liveness violations are a fact of life in concurrent programming, and parallel stream pipelines are no
    exception.

    (example of a program where using parallel stream causes performance issues )

    // Stream-based program to generate the first 20 Mersenne primes
    public static void main(String[] args) {
        primes().map(p -> TWO.pow(p.intValueExact()).subtract(ONE))
            .filter(mersenne -> mersenne.isProbablePrime(50))
            .limit(20)
            .forEach(System.out::println);
    }
    static Stream<BigInteger> primes() {
        return Stream.iterate(TWO, BigInteger::nextProbablePrime);
    }

!!! What’s going on here? Simply put, the streams library has no idea how to parallelize this pipeline and the heuristics
    fail. Even under the best of circumstances, parallelizing a pipeline is unlikely to increase its performance if the
    source is from Stream.iterate, or the intermediate operation limit is used.

!!!!
    The moral of this story is simple: Do not parallelize stream pipelines indiscriminately. The performance consequences
    may be disastrous.
    As a rule, performance gains from parallelism are best on streams over ArrayList, HashMap, HashSet, and ConcurrentHashMap
    instances; arrays; int ranges; and long ranges.
    What these data structures have in common is that they can all be accurately and cheaply split into subranges of any
    desired sizes, which makes it easy to divide work among parallel threads.

    Another important factor that all of these data structures have in common is that they provide good-to-excellent
    locality of reference when processed sequentially: sequential element references are stored together in memory. The objects
    referred to by those references may not be close to one another in memory, which reduces locality-of-reference.
    Locality-of-reference turns out to be critically important for parallelizing bulk operations: without it, threads
    spend much of their time idle, waiting for data to be transferred from memory into the processor’s
    cache. The data structures with the best locality of reference are primitive arrays because the data itself is stored
    contiguously in memory

!!! The nature of a stream pipeline’s terminal operation also affects the effectiveness of parallel execution. If a
    significant amount of work is done in the terminal operation compared to the overall work of the pipeline and that
    operation is inherently sequential, then parallelizing the pipeline will have limited effectiveness.
    The best terminal operations for parallelism are reductions, where all of the elements emerging from the pipeline
    are combined using one of Stream’s reduce methods, or prepackaged reductions such as min, max, count, and sum.
    The shortcircuiting operations anyMatch, allMatch, and noneMatch are also amenable to parallelism. The operations
    performed by Stream’s collect method, which are known as mutable reductions, are not good candidates for parallelism
    because the overhead of combining collections is costly.

!!   Not only can parallelizing a stream lead to poor performance, including liveness failures; it can lead to incorrect
    results and unpredictable behavior (safety failures). Safety failures may result from parallelizing a pipeline that uses
    mappers, filters, and other programmer-supplied function objects that fail to adhere to their specifications. The
    Stream specification places stringent requirements on these function objects. For example, the accumulator and combiner
    functions passed to Stream’s reduce operation must be associative, non-interfering, and stateless. If you violate
    these requirements (some of which are discussed in Item 46) but run your pipeline sequentially, it will likely yield
    correct results; if you parallelize it, it will likely fail, perhaps catastrophically

!!! won’t get a good speedup from parallelization unless the pipeline is doing enough
    real work to offset the costs associated with parallelism. As a very rough estimate,
    the number of elements in the stream times the number of lines of code executed
    per element should be at least a hundred thousand

    If it sounds like the odds are stacked against you when parallelizing stream pipelines, it’s because they are. An
    acquaintance who maintains a multimillionline codebase that makes heavy use of streams found only a handful of places
    where parallel streams were effective. This does not mean that you should refrain
    from parallelizing streams. Under the right circumstances, it is possible to
    achieve near-linear speedup in the number of processor cores simply by adding a parallel call to a stream pipeline.

    In summary, do not even attempt to parallelize a stream pipeline unless you
    have good reason to believe that it will preserve the correctness of the computation
    and increase its speed. The cost of inappropriately parallelizing a stream can be a
    program failure or performance disaster. If you believe that parallelism may be
    justified, ensure that your code remains correct when run in parallel, and do careful
    performance measurements under realistic conditions. If your code remains correct
    and these experiments bear out your suspicion of increased performance, then and
    only then parallelize the stream in production code.


===============================================================================================================
===============================================================================================================
Chapter 8 - Methods

THIS chapter discusses several aspects of method design: how to treat parameters and return values, how to design method
signatures, and how to document methods. Much of the material in this chapter applies to constructors as
well as to methods. Like Chapter 4, this chapter focuses on usability, robustness, and flexibility


Item 49 - Check parameters for validity

    Most methods and constructors have some restrictions on what values may be passed into their parameters. For example,
    it is not uncommon that index values must be non-negative and object references must be non-null. You should clearly
    document all such restrictions and enforce them with checks at the beginning of the method body. This is a special
    case of the general principle that you should attempt to detect errors as soon as possible after they occur. Failing
    to do so makes it less likely that an error will be detected and makes it harder to determine the source of an error
    once it has been detected.

!!! If an invalid parameter value is passed to a method and the method checks its parameters before execution, it will
    fail quickly and cleanly with an appropriate exception.

!!! If the method fails to check its parameters, several things could happen. The method could fail with a confusing
    exception in the midst of processing. Worse, the method could return normally but silently compute the wrong result.
    Worst of all, the method could return normally but leave some object in a compromised state, causing an error at
    some unrelated point in the code at some undetermined time in the future. In other words, failure to validate parameters,
    can result in a violation of failure atomicity (Item 76).

!!!!For public and protected methods, use the Javadoc @throws tag to document the exception that will be thrown if a
    restriction on parameter values is violated (Item 74). Typically, the resulting exception will be IllegalArgumentException,
    IndexOutOfBoundsException, or NullPointerException (Item 72).

!!!
    The Objects.requireNonNull method, added in Java 7, is flexible and convenient, so there’s no reason to perform null
    checks manually anymore. You can specify your own exception detail message if you wish
!!!
    For an unexported method, you, as the package author, control the circumstances under which the method is called, so
    you can and should ensure that only valid parameter values are ever passed in. Therefore, nonpublic methods
    can check their parameters using assertions, as shown (in the code examples)

        assert keyword is used
!!!
    In essence, these assertions are claims that the asserted condition will be true, regardless of how the enclosing
    package is used by its clients. Unlike normal validity checks, assertions throw AssertionError if they fail. And
    unlike normal validity checks, they have no effect and essentially no cost unless you enable
    them, which you do by passing the -ea (or -enableassertions) flag to the java command.
    https://stackoverflow.com/questions/18168257/where-to-add-compiler-options-like-ea-in-intellij-idea
        ON HOW to enable asserts in InteliJ

    It is particularly important to check the validity of parameters that are not used
    by a method, but stored for later use. (for example if you store a null now, but that value gets retrieved later on,
    it will be more difficult to investigate/find out the issue)

!!!
    Constructors represent a special case of the principle that you should check the validity of parameters that are to
    be stored away for later use. It is critical to check the validity of constructor parameters to prevent the
    construction of an object that violates its class invariants.

    There are exceptions to the rule that you should explicitly check a method’s parameters before performing its
    computation. An important exception is the case in which the validity check would be expensive or impractical and
    the check is performed implicitly in the process of doing the computation. For example, consider a method that sorts
    a list of objects, such as Collections.sort(List).
    All of the objects in the list must be mutually comparable. In the process of sorting the list, every object in the
    list will be compared to some other object in the list. If the objects aren’t mutually comparable, one of these
    comparisons will throw a ClassCastException, which is exactly what the sort method should do.
    Therefore, there would be little point in checking ahead of time that the elements in the list were mutually comparable

!!!!
    Do not infer from this item that arbitrary restrictions on parameters are a good thing. On the contrary, you should
    design methods to be as general as it is practical to make them. The fewer restrictions that you place on parameters, the
    better, assuming the method can do something reasonable wih all of the parameter values that it accepts. Often,
    however, some restrictions are intrinsic to the abstraction being implemented.
    To summarize, each time you write a method or constructor, you should think about what restrictions exist on its
    parameters. You should document these restrictions and enforce them with explicit checks at the beginning of the method
!!! body. It is important to get into the habit of doing this. The modest work that it entails will be paid back with
    interest the first time a validity check fails


Item 50 - Make defensive copies when needed

!!!
    You must program defensively, with the assumption that clients of your class will do their best to destroy its
    invariants. This is increasingly true as people try harder to break the security of systems, but more
    commonly, your class will have to cope with unexpected behavior resulting from the honest mistakes of
    well-intentioned programmers. Either way, it is worth taking the time to write classes that are robust in the face
    of ill-behaved clients.

        see code example for a problematic "immutable" (at least in intention immutable class) and its fixes

!!!!
    As of Java 8, the obvious way to fix this problem is to use Instant (or LocalDateTime or ZonedDateTime) in place of
    a Date because Instant (and the other java.time classes) are immutable (Item 17).
    Date is obsolete and should no longer be used in new code.

!!!
    To protect the internals of a Period instance from this sort of attack, it is essential to make a defensive copy of
    each mutable parameter to the constructor and to use the copies as components of the Period instance in place of the
    originals

!!!!
    Note that defensive copies are made before checking the validity of the parameters (Item 49), and the validity check
    is performed on the copies rather than on the originals. While this may seem unnatural, it is
    necessary. It protects the class against changes to the parameters from another thread during the window of
    vulnerability between the time the parameters are checked and the time they are copied. In the computer security
    community, this is known as a time-of-check/time-of-use or TOCTOU attack.

    do not use the clone method to make a defensive copy of a parameter whose type is subclassable by untrusted parties.
        (explanation in the book...clone can be used with classes that are not final and that can thus be extended by
        attackers)

    Defensive copying of parameters is not just for immutable classes. Any time you write a method or constructor that
    stores a reference to a client-provided object in an internal data structure, think about whether the client-provided
    object is potentially mutable. If it is, think about whether your class could tolerate a
    change in the object after it was entered into the data structure. If the answer is no, you must defensively copy the
    object and enter the copy into the data structure in place of the original.
    The same is true for defensive copying of internal components prior to returning them to clients. Whether or not
    your class is immutable, you should think twice before returning a reference to an internal component that is mutable.
    Chances are, you should return a defensive copy.

!!!
    There may be a performance penalty associated with defensive copying and it isn’t always justified.
    If a class trusts its caller not to modify an internal component, perhaps because the class and its client are both
    part of the same package, then it may be appropriate to dispense with defensive copying. Under
    these circumstances, the class documentation should make it clear that the caller must not modify the affected
    parameters or return values
    Even across package boundaries, it is not always appropriate to make a defensive copy of a mutable parameter before
    integrating it into an object. There are some methods and constructors whose invocation indicates an explicit handoff
    of the object referenced by a parameter. When invoking such a method, the client promises that it will no longer
    modify the object directly.

    Classes containing methods or constructors whose invocation indicates a transfer of control (over the objects from
    inside the class) cannot defend themselves against malicious clients. Such classes are acceptable only when there
    is mutual trust between a class and its client or when damage to the class’s invariants would harm no one but the
    client.

    In summary, if a class has mutable components that it gets from or returns to its clients, the class must
    defensively copy these components. If the cost of the copy would be prohibitive and the class trusts its clients not
    to modify the components inappropriately, then the defensive copy may be replaced by documentation outlining the
    client’s responsibility not to modify the affected components.


Item 51 - Design method signatures carefully

    Taken together, they’ll (tips from below) help make your API easier to learn and use and less prone to errors:

    Choose method names carefully. Names should always obey the standard naming conventions (Item 68). Your primary
    goal should be to choose names that are understandable and consistent with other names in the same package. Your
    secondary goal should be to choose names consistent with the broader consensus, where it exists. Avoid long method
    names.

!!! Don’t go overboard in providing convenience methods. Every method should “pull its weight.” Too many methods make
    a class difficult to learn, use, document, test, and maintain. This is doubly true for interfaces, where too many
    methods complicate life for implementors as well as users. For each action supported by your class or interface,
    provide a fully functional method. Consider providing a “shorthand” only if it will be used often. When in doubt,
    leave it out.

    Avoid long parameter lists. Aim for four parameters or fewer. Most programmers can’t remember longer parameter
    lists. If many of your methods  exceed this limit, your API won’t be usable without constant reference to its
    documentation. Modern IDEs help, but you are still much better off with short parameter lists. Long sequences of
    identically typed parameters are especially harmful.

    A second technique for shortening long parameter lists is to create helper classes to hold groups of parameters.
    Typically these helper classes are static member classes (Item 24). This technique is recommended if a frequently
    occurring sequence of parameters is seen to represent some distinct entity. For example, suppose you are writing a
    class representing a card game, and you find yourself constantly passing a sequence of two parameters representing
    a card’s rank and its suit. Your API, as well as the internals of your class, would probably benefit if you
    added a helper class to represent a card and replaced every occurrence of the parameter sequence with a single
    parameter of the helper class.
!!! A third technique that combines aspects of the first two is to adapt the Builder pattern (Item 2) from object
    construction to method invocation. Once the desired parameters have been set, the client invokes the object’s
    “execute” method, which does any final validity checks on the parameters and performs the actual computation

    For parameter types, favor interfaces over classes (Item 64). If there is an appropriate interface to define a
    parameter, use it in favor of a class that implements the interface. For example, there is no reason to ever write
    a method that takes HashMap on input—use Map instead.

!!! Prefer two-element enum types to boolean parameters, unless the meaning of the boolean is clear from the method name.
    Enums make your code easier to read and to write. Also, they make it easy to add more options later. For example,
    you might have a Thermometer type with a static factory that takes this enum:
        public enum TemperatureScale { FAHRENHEIT, CELSIUS }
    Not only does Thermometer.newInstance(TemperatureScale.CELSIUS) make a lot more sense than
    Thermometer.newInstance(true), but you can add KELVIN to TemperatureScale in a future release without having to add
    a new static factory to Thermometer.


Item 52 - Use overloading judiciously

    (see code from CollectionClassifier and ask yourself...what that program prints ?)

!!!!
    It prints Unknown Collection three times. Why does this happen?
    Because the classify method is overloaded, and the choice of which overloading to invoke is made at compile time.
    For all three iterations of the loop, the compile-time type of the parameter is the same: Collection<?>. The
    runtime type is different in each iteration, but this does not affect the choice of overloading. Because the
    compile-time type of the parameter is Collection<?>, the only applicable overloading is the third one,
    classify(Collection<?>), and this overloading is invoked in each iteration of the loop.

!!!!
    The behavior of this program is counterintuitive because selection among overloaded methods is static, while
    selection among overridden methods is dynamic.
    The correct version of an overridden method is chosen at runtime, based on the runtime type of the object on which
    the method is invoked

    The compile-time type of an object has no effect on which method is executed when an overridden method is invoked;
    the “most specific” overriding method always gets executed.
    Compare this to overloading, where the runtime type of an object has no effect on which overloading is executed;
    the selection is made at compile time, based entirely on the compile-time types of the parameters.

!!!!!
    Because overriding is the norm and overloading is the exception, overriding sets people’s expectations for the
    behavior of method invocation. As demonstrated by the CollectionClassifier example, overloading can easily confound
    these expectations. It is bad practice to write code whose behavior is likely to confuse programmers. This is
    especially true for APIs. If the typical user of an API does not know which of several method overloadings will get
    invoked for a given set of parameters, use of the API is likely to result in errors. These errors will likely
    manifest themselves as erratic behavior at runtime, and many programmers will have a hard time diagnosing them.
    Therefore you should avoid confusing uses of overloading.

!!  A safe, conservative policy is never to export two overloadings with the same number of parameters. If a method
    uses varargs, a conservative policy is not to overload it at all, except as described in Item 53. If you adhere to
    these restrictions, programmers will never be in doubt as to which overloading applies
    to any set of actual parameters. These restrictions are not terribly onerous because
    you can always give methods different names instead of overloading them.

    For constructors, you don’t have the option of using different names: multiple constructors for a class are always
    overloaded. You do, in many cases, have the option of exporting static factories instead of constructors (Item 1).

!!!
    Therefore, do not overload methods to take different functional interfaces in the same argument position

    To summarize, just because you can overload methods doesn’t mean you should. It is generally best to refrain from
    overloading methods with multiple signatures that have the same number of parameters. In some cases, especially
    where constructors are involved, it may be impossible to follow this advice. In these cases, you should at least
    avoid situations where the same set of parameters can be passed to different overloadings by the addition of casts.
    If this cannot be avoided, for example, because you are retrofitting an existing class to implement a
    new interface, you should ensure that all overloadings behave identically when passed the same parameters. If
    you fail to do this, programmers will be hard pressed to make effective use of the overloaded method or constructor,
    and they won’t understand why it doesn’t work.


Item 53 - Use varargs judiciously

    Varargs methods, formally known as variable arity methods, accept zero or more arguments of a specified type. The
    varargs facility works by first creating an array whose size is the number of arguments passed at the call site,
    then putting the argument values into the array, and finally passing the array to the method.

    Every invocation of a varargs method causes an array allocation and initialization.

    In summary, varargs are invaluable when you need to define methods with a variable number of arguments. Precede
    the varargs parameter with any required parameters, and be aware of the performance consequences of using varargs.


Item 54 - Return empty collections or arrays, not nulls

    Doing so  (returning a null instead of empty collection) requires extra code in the client to handle the possibly null
    return value, for example:

        List<Cheese> cheeses = shop.getCheeses();
        if (cheeses != null && cheeses.contains(Cheese.STILTON))
            System.out.println("Jolly good, just the thing.");

    It is sometimes argued that a null return value is preferable to an empty collection or array because it avoids the
    expense of allocating the empty container.
    This argument fails on two counts. First, it is inadvisable to worry about performance at this level unless
    measurements have shown that the allocation in question is a real contributor to performance problems (Item 67).
    Second, it is possible to return empty collections and arrays without allocating them

        //The right way to return a possibly empty collection
        public List<Cheese> getCheeses() {
            return new ArrayList<>(cheesesInStock);
        }

    In the unlikely event that you have evidence suggesting that allocating empty collections is harming performance,
    you can avoid the allocations by returning the same immutable empty collection repeatedly, as immutable objects may
    be shared freely (Item 17). Here is the code to do it, using the Collections.emptyList method.

!!! If you were returning a set, you’d use Collections.emptySet; if you were returning a map, you’d use Collections.emptyMap.

        // Optimization - avoids allocating empty collections
        public List<Cheese> getCheeses() {
            return cheesesInStock.isEmpty() ? Collections.emptyList() : new ArrayList<>(cheesesInStock);
        }

    The situation for arrays is identical to that for collections. Never return null instead of a zero-length array.

    In summary, never return null in place of an empty array or collection. It makes your API more difficult to use and
    more prone to error, and it has no performance advantages.


Item 55 - Return optionals judiciously

    Prior to Java 8, there were two approaches you could take when writing a method that was unable to return a value
    under certain circumstances. Either you could throw an exception, or you could return null (assuming the return type
    was an object reference type). Neither of these approaches is perfect. Exceptions should be reserved for exceptional
    conditions (Item 69)
    If a method returns null, clients must contain special-case code to deal with the possibility of
    a null return, unless the programmer can prove that a null return is impossible. If a
    client neglects to check for a null return and stores a null return value away in
    some data structure, a NullPointerException may result at some arbitrary time
    in the future, at some place in the code that has nothing to do with the problem.

    In Java 8, there is a third approach to writing methods that may not be able to return a value. The Optional<T>
    class represents an immutable container that can hold either a single non-null T reference or nothing at all. An
    optional that contains nothing is said to be empty. A value is said to be present in an optional that is not empty.

    A method that conceptually returns a T but may be unable to do so under certain circumstances can instead be declared
    to return an Optional<T>. This allows the method to return an empty result to indicate that it couldn’t return a
    valid result. An Optional-returning method is more flexible and easier to use than one that throws an exception, and
    it is less error-prone than one that returns null.


    As you can see (see code examples), it is straightforward to return an optional. All you have to do
    is to create the optional with the appropriate static factory. In this program, we use
    two: Optional.empty() returns an empty optional, and Optional.of(value) returns an optional containing the given
    non-null value.

!!!!
    Never return a null value from an Optional-returning method: it defeats the entire purpose of the facility

!!  Optionals are similar in spirit to checked exceptions (Item 71), in that they force the user of an API to confront
    the fact that there may be no value returned. Throwing an unchecked exception or returning a null allows
    the user to ignore this eventuality, with potentially dire consequences. However, throwing a checked exception
    requires additional boilerplate code in the client.

    If a method returns an optional, the client gets to choose what action to take if the method can’t return a value.
    You can specify a default value:

        // Using an optional to provide a chosen default value
        String lastWordInLexicon = max(words).orElse("No words...");

        // Using an optional to throw a chosen exception
        Toy myToy = max(toys).orElseThrow(TemperTantrumException::new);

        // Using optional when you know there’s a return value
        Element lastNobleGas = max(Elements.NOBLE_GASES).get();

    Many uses of isPresent can profitably be replaced by one of the methods mentioned above. The resulting code will
    typically be shorter, clearer, and more  idiomatic.  (so using this should be like a last option)

!!!!
    Container types, including collections, maps, streams, arrays, and optionals should not be wrapped in optionals.
    Rather than returning an empty Optional<List<T>>, you should simply return an empty List<T> (Item 54).

    So when should you declare a method to return Optional<T> rather than T?
    As a rule, you should declare a method to return Optional<T> if it might not be able to return a result and clients
    will have to perform special processing if no result is returned. That said, returning an Optional<T> is not without
    cost.
    An Optional is an object that has to be allocated and initialized, and reading the value out of the optional
    requires an extra indirection. This makes optionals inappropriate for use in some performance-critical situations.
    Whether a particular method falls into this category can only be determined by careful measurement (Item 67)

!!!!!
    Returning an optional that contains a boxed primitive type is prohibitively expensive compared to returning a
    primitive type because the optional has two levels of boxing instead of zero
    Therefore, the library designers saw fit to provide analogues of Optional<T> for the primitive types
    int, long, and double. These optional types are OptionalInt, OptionalLong, and OptionalDouble. They
    contain most, but not all, of the methods on Optional<T>.
    Therefore, you should never return an optional of a boxed primitive type, with the possible exception
    of the “minor primitive types,” Boolean, Byte, Character, Short, and Float.

!!
    For example, you should never use optionals as map values. If you do, you have two ways of expressing a key’s
    logical absence from the map: either the key can be absent from the map, or it can be present and
    map to an empty optional. This represents needless complexity with great potential for confusion and errors. More
    generally, it is almost never appropriate to use an optional as a key, value, or element in a collection or array

    This leaves a big question unanswered. Is it ever appropriate to store an optional in an instance field? Often
    it’s a “bad smell”: it suggests that perhaps you should have a subclass containing the optional fields. But sometimes
    it may be justified.
    Consider the case of our NutritionFacts class in Item 2.
    A NutritionFacts instance contains many fields that are not required. You can’t
    have a subclass for every possible combination of these fields. Also, the fields
    have primitive types, which make it awkward to express absence directly.
    The best API for NutritionFacts would return an optional from the getter for each
    optional field, so it makes good sense to simply store those optionals as fields in
    the object.

    In summary, if you find yourself writing a method that can’t always return a value and you believe it is important
    that users of the method consider this possibility every time they call it, then you should probably return an optional.
    You should, however, be aware that there are real performance consequences associated with returning optionals; for
    performance-critical methods, it may be better to return a null or throw an exception. Finally, you should rarely
    use an optional in any other capacity than as a return value.


Item 56 - Write doc comments for all exposed API elements

    If an API is to be usable, it must be documented. Traditionally, API documentation
    was generated manually, and keeping it in sync with code was a chore. The Java
    programming environment eases this task with the Javadoc utility. Javadoc
    generates API documentation automatically from source code with specially
    formatted documentation comments, more commonly known as doc comments.

    While the doc comment conventions are not officially part of the language, they constitute a de facto API that
    every Java programmer should know. These conventions are described in the "How to Write Doc Comments web page".

!!  To document your API properly, you must precede every exported class, interface, constructor, method, and field
    declaration with a doc comment. If a class is serializable, you should also document its serialized form (Item 87).

    To write maintainable code, you should also write doc comments for most unexported classes, interfaces, constructors,
    methods, and fields, though these comments needn’t be as thorough as those for exported API elements.

!!!!
    The doc comment for a method should describe succinctly the contract between the method and its client. With the
    exception of methods in classes designed for inheritance (Item 19), the contract should say what the method does
    rather than how it does its job. The doc comment should enumerate all of the method’s preconditions, which are the
    things that have to be true in order for a client to invoke it, and its postconditions, which are the things that
    will be true after the invocation has completed successfully. Typically, preconditions are described implicitly by
    the @throws tags for unchecked exceptions; each unchecked exception corresponds to a precondition violation. Also,
    preconditions can be specified along with the affected parameters in their @param tags.

    In addition to preconditions and postconditions, methods should document any side effects (like starting a background
    thread)

!!!
    To describe a method’s contract fully, the doc comment should have an @param tag for every parameter, an @return
    tag unless the method has a void return type, and an @throws tag for every exception thrown by the method,
    whether checked or unchecked (Item 74).

    The text following an @throws tag should consist of the word “if,” followed by a clause describing the conditions
    under which the exception is thrown. By convention, the phrase or clause following an @param, @return, or
    @throws tag is not terminated by a period.

    Example:

    /**
    * Returns the element at the specified position in this list.
    *
    * <p>This method is <i>not</i> guaranteed to run in constant
    * time. In some implementations it may run in time proportional
    * to the element position.
    *
    * @param index index of element to return; must be
    *       non-negative and less than the size of this list
    * @return the element at the specified position in this list
    * @throws IndexOutOfBoundsException if the index is out of range
    *           ({@code index < 0 || index >= this.size()})
    */
    E get(int index);

    Notice the use of HTML tags in this doc comment (<p> and <i>). The Javadoc utility translates doc comments into
    HTML, and arbitrary HTML elements in doc comments end up in the resulting HTML document.

    Also notice the use of the Javadoc {@code} tag around the code fragment in the @throws clause. This tag serves two
    purposes: it causes the code fragment to be rendered in code font, and it suppresses processing of HTML markup and
    nested Javadoc tags in the code fragment. The latter property is what allows us to use the
    less-than sign (<) in the code fragment even though it’s an HTML metacharacter.

    Finally, notice the use of the words “this list” in the doc comment. By convention, the word “this” refers to the
    object on which a method is invoked when it is used in the doc comment for an instance method.

    As mentioned in Item 15, when you design a class for inheritance, you must
    document its self-use patterns, so programmers know the semantics of overriding
    its methods. These self-use patterns should be documented using the @implSpec
    tag, added in Java 8. Recall that ordinary doc comments describe the contract
    between a method and its client; @implSpec comments, by contrast, describe the
    contract between a method and its subclass, allowing subclasses to rely on
    implementation behavior if they inherit the method or call it via super

    Don’t forget that you must take special action to generate documentation that contains HTML metacharacters, such as
    the less-than sign (<), the greater-than sign (>), and the ampersand (&). The best way to get these characters into
    documentation is to surround them with the {@literal} tag, which suppress processing of HTML markup and nested
    Javadoc tags. It is like the {@code} tag, except that it doesn’t render the text in code font. For example, this
    Javadoc fragment:
        * A geometric series converges if {@literal |r| < 1}.

!!!!
    This illustrates the general principle that doc comments should be readable both in the source code and in
    the generated documentation. If you can’t achieve both, the readability of the
    generated documentation trumps that of the source code.

!!! To avoid confusion, no two members or constructors in a class or interface should have the
    same summary description. Pay particular attention to overloadings, for which it
    is often natural to use the same first sentence (but unacceptable in doc comments)

    For methods and constructors, the summary description should be a verb phrase (including any object) describing the
    action performed by the method. For example:
    • ArrayList(int initialCapacity)—Constructs an empty list with the specified initial capacity.
    • Collection.size()—Returns the number of elements in this collection.

    For classes, interfaces, and fields, the summary description should be a noun phrase describing the thing represented
    by an instance of the class or interface or by the field itself. For example:
    • Instant—An instantaneous point on the time-line.
    • Math.PI—The double value that is closer than any other to pi, the ratio of the circumference of a circle to its
                diameter.

    Occasionally you may wish to index additional terms that are important to your API. The {@index} tag
    was added for this purpose. Indexing a term that appears in a doc comment is as
    simple as wrapping it in this tag, as shown in this fragment:
        * This method complies with the {@index IEEE 754} standard.

    Generics, enums, and annotations require special care in doc comments.
    When documenting a generic type or method, be sure to document all type parameters:
            /**
             * An object that maps keys to values. A map cannot contain
             * duplicate keys; each key can map to at most one value.
             *
             * (Remainder omitted)
             *
            * @param <K> the type of keys maintained by this map
             * @param <V> the type of mapped values
             */
            public interface Map<K, V> { ... }

    When documenting an enum type, be sure to document the constants as
    well as the type and any public methods. Note that you can put an entire doc
    comment on one line if it’s short:
            /**
             * An instrument section of a symphony orchestra.
             */
            public enum OrchestraSection {
             /** Woodwinds, such as flute, clarinet, and oboe. */
             WOODWIND,
             /** Brass instruments, such as french horn and trumpet. */
             BRASS,
             /** Percussion instruments, such as timpani and cymbals. */
             PERCUSSION,
             /** Stringed instruments, such as violin and cello. */
             STRING;
            }

    When documenting an annotation type, be sure to document any members as well as the type itself. Document members
    with noun phrases, as if they were fields. For the summary description of the type, use a verb phrase that says
    what it means when a program element has an annotation of this type:
            /**
             * Indicates that the annotated method is a test method that
             * must throw the designated exception to pass.
             */
            @Retention(RetentionPolicy.RUNTIME)
            @Target(ElementType.METHOD)
            public @interface ExceptionTest {
             /**
             * The exception that the annotated test method must throw
             * in order to pass. (The test is permitted to throw any
             * subtype of the type described by this class object.)
             */
             Class<? extends Throwable> value();
            }

    Two aspects of APIs that are often neglected in documentation are threadsafety and serializability. Whether or not
    a class or static method is threadsafe, you should document its thread-safety level, as described in Item 82. If a
    class is serializable, you should document its serialized form, as described in Item 87

    This means, among other things, that classes can reuse doc comments from
    interfaces they implement, rather than copying these comments. This facility has
    the potential to reduce the burden of maintaining multiple sets of nearly identical
    doc comments, but it is tricky to use and has some limitations. The details are
    beyond the scope of this book.

!!!
    One caveat should be added concerning documentation comments. While it is necessary to provide documentation
    comments for all exported API elements, it is not always sufficient. For complex APIs consisting of multiple
    interrelated classes, it is often necessary to supplement the documentation comments with an
    external document describing the overall architecture of the API. If such a document exists, the relevant class or
    package documentation comments should include a link to it

    When validating generated HTML, keep in mind that as of Java 9, Javadoc is capable of generating HTML5 as well as
    HTML 4.01, though it still generates HTML 4.01 by default. Use the -html5 command line switch if you want Javadoc
    to generate HTML5.

    To summarize, documentation comments are the best, most effective way to document your API. Their use should be
    considered mandatory for all exported  API elements. Adopt a consistent style that adheres to standard conventions.
    Remember that arbitrary HTML is permissible in documentation comments and that HTML metacharacters must be escaped.


===============================================================================================================
===============================================================================================================
Chapter 9 - General Programming

THIS chapter is devoted to the nuts and bolts of the language. It discusses local
variables, control structures, libraries, data types, and two extralinguistic facilities:
reflection and native methods. Finally, it discusses optimization and naming
conventions.

Item 57 - Minimize the scope of local variables

    This item is similar in nature to Item 15, “Minimize the accessibility of classes and members.” By minimizing the
    scope of local variables, you increase the readability and maintainability of your code and reduce the likelihood of
    error

    Java lets you declare variables anywhere a statement is legal

    The most powerful technique for minimizing the scope of a local variable is to declare it where it is first used.
    If a variable is declared before it is used, it’s just clutter—one more thing to distract the reader who is trying
    to figure out what the program does. By the time the variable is used, the reader might not remember the variable’s
    type or initial value.

    Declaring a local variable prematurely can cause its scope not only to begin too early but also to end too late.
    The scope of a local variable extends from the point where it is declared to the end of the enclosing block. If a
    variable is declared outside of the block in which it is used, it remains visible after the program exits that block.
!!!
    Nearly every local variable declaration should contain an initializer. If you don’t yet have enough information to
    initialize a variable sensibly, you should postpone the declaration until you do. One exception to this rule concerns
    try catch statements.

    Loops present a special opportunity to minimize the scope of variables. The for loop, in both its traditional and
    for-each forms, allows you to declare loop variables, limiting their scope to the exact region where they’re needed
    Therefore, prefer for loops to while loops, assuming the contents of the loop variable aren’t needed after the loop
    terminates.

        // Preferred idiom for iterating over a collection or array
        for (Element e : c) {
        ... // Do Something with e
        }

        // Idiom for iterating when you need the iterator
        for (Iterator<Element> i = c.iterator(); i.hasNext(); ) {
            Element e = i.next();
            ... // Do something with e and i
        }

    Moreover, if you use a for loop, it’s much less likely that you’ll make the copy-and-paste error because there’s no
    incentive to use different variable names  in the two loops. The loops are completely independent, so there’s no harm in
    reusing the element (or iterator) variable name. In fact, it’s often stylish to do so.

    As a rule, you should use this idiom if the loop test involves a method invocation (expensiveComputation) that is
    guaranteed to return the same result on each iteration.
        for (int i = 0, n = expensiveComputation(); i < n; i++) {
        ... // Do something with i;
        }

!!!
    A final technique to minimize the scope of local variables is to keep methods small and focused. If you combine two
    activities in the same method, local variables relevant to one activity may be in the scope of the code performing the
    other activity. To prevent this from happening, simply separate the method into two: one for each activity.


Item 58 - Prefer for-each loops to traditional for loops

    As discussed in Item 45, some tasks are best accomplished with streams, others with iteration.

        // Not the best way to iterate over a collection!
        for (Iterator<Element> i = c.iterator(); i.hasNext(); ) {
        Element e = i.next();
        ... // Do something with e
        }

    and here is a traditional for loop to iterate over an array:

        // Not the best way to iterate over an array!
        for (int i = 0; i < a.length; i++) {
        ... // Do something with a[i]
        }

    The iterator and the index variables are both just clutter—all you need are the elements.
    Furthermore, they represent opportunities for error. The iterator occurs three times in each loop and the index
    variable four, which gives you many chances to use the wrong variable. If you do, there is no guarantee that the
    compiler will catch the problem. Finally, the two loops are quite different, drawing unnecessary attention
    to the type of the container and adding a (minor) hassle to changing that type.

    The for-each loop (officially known as the “enhanced for statement”) solves all of these problems. It gets rid of the
    clutter and the opportunity for error by hiding the iterator or index variable. The resulting idiom applies equally to
    collections and arrays, easing the process of switching the implementation type of a container from one to the other:

        // The preferred idiom for iterating over collections and arrays
        for (Element e : elements) {
        ... // Do something with e
        }

    Unfortunately, there are three common situations where you can’t use for-each:
    • Destructive filtering—If you need to traverse a collection removing selected elements, then you need to use an
    explicit iterator so that you can call its remove method. You can often avoid explicit traversal by using Collection’s
    removeIf method, added in Java 8.
    • Transforming—If you need to traverse a list or array and replace some or all of the values of its elements, then you
    need the list iterator or array index in order to replace the value of an element.
    • Parallel iteration—If you need to traverse multiple collections in parallel, then you need explicit control over the
    iterator or index variable so that all iterators or index variables can be advanced in lockstep (as demonstrated
    unintentionally in the buggy card and dice examples above).

    It is a bit tricky to implement Iterable if you have to write your own Iterator implementation from scratch, but if
    you are writing a type that represents a group of elements, you should strongly consider having it implement Iterable,
    even if you choose not to have it implement Collection. This will allow your users to iterate over your type using
    the for-each loop, and they will be forever grateful.

!!! In summary, the for-each loop provides compelling advantages over the traditional for loop in clarity, flexibility,
    and bug prevention, with no performance penalty. Use for-each loops in preference to for loops wherever you can.


Item 59 - Know and use the libraries

    A senior engineer with a background in algorithms spent a good deal of time designing, implementing, and testing this
    method and then showed it to several experts in the field to make sure it was right.
    Then the library was beta tested, released, and used extensively by millions of programmers for almost two decades.
    No flaws have yet been found in the method, but if a flaw were to be discovered, it would be fixed in the next release.
    By using a standard library, you take advantage of the knowledge of the experts who wrote it and the experience of
    those who used it before you.

    A second advantage of using the libraries is that you don’t have to waste your time writing ad hoc solutions to
    problems that are only marginally related to your work. If you are like most programmers, you’d rather spend your
    time working on your application than on the underlying plumbing.

    A third advantage of using standard libraries is that their performance tends to improve over time, with no effort
    on your part. Because many people use them and because they’re used in industry-standard benchmarks, the organizations that
    supply these libraries have a strong incentive to make them run faster. Many of the Java platform libraries have been
    rewritten over the years, sometimes repeatedly, resulting in dramatic performance improvements

    A fourth advantage of using libraries is that they tend to gain functionality over time. If a library is missing
    something, the developer community will make it known, and the missing functionality may get added in a subsequent release.

    A final advantage of using the standard libraries is that you place your code in the mainstream. Such code is more
    easily readable, maintainable, and reusable by the multitude of developers.

!!!
    As of Java 7, you should no longer use Random. For most uses, the random number generator of choice is now
    ThreadLocalRandom. It produces higher quality random numbers, and it’s very fast. On my machine, it is 3.6 times faster
    than Random. For fork join pools and parallel streams, use SplittableRandom.

!!! Given all these advantages, it seems only logical to use library facilities in preference to ad hoc implementations,
    yet many programmers don’t. Why not?
    Perhaps they don’t know the library facilities exist. Numerous features are added to the libraries in every major
    release, and it pays to keep abreast of these additions. Each time there is a major release of the Java platform, a web
    page is published describing its new features. These pages are well worth reading [Java8-feat, Java9-feat].

!!!
    The libraries are too big to study all the documentation [Java9-api], but every programmer should be familiar with
    the basics of java.lang, java.util, and java.io, and their subpackages.
    Several libraries bear special mention. The collections framework and the streams library (Items 45–48) should be
    part of every programmer’s basic toolkit, as should parts of the concurrency utilities in java.util.concurrent. This
    package contains both high-level utilities to simplify the task of multithreaded programming and low-level primitives
    to allow experts to write their own higherlevel concurrent abstractions.

    If you can’t find what you need in Java platform libraries, your next choice should be to look in high-quality
    third-party libraries, such as Google’s excellent, open source Guava library [Guava]. If you can’t find the
    functionality that you need in any appropriate library, you may have no choice but to implement it yourself.

!!!!
    To summarize, don’t reinvent the wheel. If you need to do something that seems like it should be reasonably common,
    there may already be a facility in the libraries that does what you want. If there is, use it; if you don’t know, check.
    Generally speaking, library code is likely to be better than code that you’d write yourself and is likely to improve
    over time. This is no reflection on your abilities as a programmer. Economies of scale dictate that library code
    receives far more attention than most developers could afford to devote to the same functionality.


Item 60 - Avoid float and double if exact answers are required

    The float and double types are designed primarily for scientific and engineering calculations. They perform binary
    floating-point arithmetic, which was carefully designed to furnish accurate approximations quickly over a broad range of
    magnitudes.

!!! They do not, however, provide exact results and should not be used where exact results are required. The float and
    double types are particularly ill-suited for monetary calculations because it is impossible to represent 0.1 (or
    any other negative power of ten) as a float or double exactly

    For example, suppose you have $1.03 in your pocket, and you spend 42¢. How much money do you have left? Here’s a
    naive program fragment that attempts to answer this question:

        System.out.println(1.03 - 0.42);

    Unfortunately, it prints out 0.6100000000000001. This is not an isolated case
    Suppose you have a dollar in your pocket, and you buy nine washers priced at ten cents each. How much change do you get?

        System.out.println(1.00 - 9 * 0.10);

    According to this program fragment, you get $0.09999999999999998.

!!!!!
    The right way to solve this problem is to use BigDecimal, int, or long for monetary calculations
        (see code example with the problematic way of doing it, with double, and the correct way with BigDecimal)

    There are, however, two disadvantages to using BigDecimal: it’s a lot less
    convenient than using a primitive arithmetic type, and it’s a lot slower. The latter
    disadvantage is irrelevant if you’re solving a single short problem, but the former may annoy you

    Or you could use int or long and do all calculations in cents (see code example)

!!!!
    In summary, don’t use float or double for any calculations that require an exact answer. Use BigDecimal if you want
    the system to keep track of the decimal point and you don’t mind the inconvenience and cost of not using a primitive type.
    Using BigDecimal has the added advantage that it gives you full control over rounding, letting you select from eight
    rounding modes whenever an operation that entails rounding is performed. This comes in handy if you’re performing
    business calculations with legally mandated rounding behavior. If performance is of the essence, you don’t mind
    keeping track of the decimal point yourself, and the quantities aren’t too big, use int or long. If the quantities
    don’t exceed nine decimal digits, you can use int; if they don’t exceed eighteen digits, you can use long. If the
    quantities might exceed eighteen digits, use BigDecimal.


Item 61 - Prefer primitive types to boxed primitives

!!
    Java has a two-part type system, consisting of primitives, such as int, double, and boolean, and reference types,
    such as String and List. Every primitive type has a corresponding reference type, called a boxed primitive. The
    boxed primitives corresponding to int, double, and boolean are Integer, Double, and Boolean

    As mentioned in Item 6, autoboxing and auto-unboxing blur but do not erase the distinction between the primitive
    and boxed primitive types. There are real differences between the two, and it’s important that you remain aware of
    which you are using and that you choose carefully between them.

    There are three major differences between primitives and boxed primitives:
        First, primitives have only their values, whereas boxed primitives have identities
        distinct from their values. In other words, two boxed primitive instances can have
        the same value and different identities

        Second, primitive types have only fully functional values, whereas each boxed primitive type has one nonfunctional
        value, which is null, in addition to all the functional values of the corresponding primitive type

        Last, primitives are more time- and space-efficient than boxed primitives.
        All three of these differences can get you into real trouble if you aren’t careful.

    In nearly every case when you mix primitives and boxed primitives in an operation, the boxed primitive is auto-unboxed.
    If a null object reference is auto-unboxed, you get a NullPointerException  (see code example in class Unbelievable)

        // Hideously slow program! Can you spot the object creation?
        public static void main(String[] args) {
            Long sum = 0L;
            for (long i = 0; i < Integer.MAX_VALUE; i++) {
                sum += i;
            }
            System.out.println(sum);
        }
    This program is much slower than it should be because it accidentally declares a
    local variable (sum) to be of the boxed primitive type Long instead of the primitive
    type long. The program compiles without error or warning, and the variable is
    repeatedly boxed and unboxed, causing the observed performance degradation.

!!!!
    So when should you use boxed primitives? They have several legitimate uses.
    The first is as elements, keys, and values in collections. You can’t put primitives in collections, so you’re forced
    to use boxed primitives. This is a special case of a more general one. You must use boxed primitives as type parameters in
    parameterized types and methods (Chapter 5), because the language does not permit you to use primitives. For example,
    you cannot declare a variable to be of type ThreadLocal<int>, so you must use ThreadLocal<Integer> instead.
    Finally, you must use boxed primitives when making reflective method invocations (Item 65).

    In summary, use primitives in preference to boxed primitives whenever you have the choice. Primitive types are simpler
    and faster. If you must use boxed primitives, be careful! Autoboxing reduces the verbosity, but not the danger, of
    using boxed primitives. When your program compares two boxed primitives with the == operator, it does an identity
    comparison, which is almost certainly not what you want. When your program does mixed-type computations involving
    boxed and unboxed primitives, it does unboxing, and when your program does unboxing, it can throw a NullPointerException.
    Finally, when your program boxes primitive values, it can result in costly and unnecessary object creations


Item 62 - Avoid strings where other types are more appropriate

    Strings are designed to represent text, and they do a fine job of it. Because strings are so common and so well
    supported by the language, there is a natural tendency to use strings for purposes other than those for which they
    were designed. This item discusses a few things that you shouldn’t do with strings
!!!
    Strings are poor substitutes for other value types. When a piece of data comes into a program from a file, from the
    network, or from keyboard input, it is often in string form. There is a natural tendency to leave it that way, but
    this tendency is justified only if the data really is textual in nature. If it’s numeric, it
    should be translated into the appropriate numeric type, such as int, float, or BigInteger. If it’s the answer to a
    yes-or-no question, it should be translated into an appropriate enum type or a boolean. More generally, if there’s an
    appropriate value type, whether primitive or object reference, you should use it; if there isn’t,
    you should write one. While this advice may seem obvious, it is often violated.

    Strings are poor substitutes for enum types. As discussed in Item 34, enums make far better enumerated type constants
    than strings.

    Strings are poor substitutes for aggregate types. If an entity has multiple components, it is usually a bad idea to
    represent it as a single string. For example, here’s a line of code that comes from a real system—identifier names have been
    changed to protect the guilty:

        // Inappropriate use of string as aggregate type
        String compoundKey = className + "#" + i.next();

    This approach has many disadvantages. If the character used to separate fields occurs in one of the fields, chaos
    may result. To access individual fields, you have to parse the string, which is slow, tedious, and error-prone.
    You can’t provide equals, toString, or compareTo methods but are forced to accept the behavior
    that String provides. A better approach is simply to write a class to represent the aggregate, often a private
    static member class (Item 24)

    To summarize, avoid the natural tendency to represent objects as strings when better data types exist or can be
    written. Used inappropriately, strings are more cumbersome, less flexible, slower, and more error-prone than other
    types. Types for which strings are commonly misused include primitive types, enums, and aggregate types.


Item 63 - Beware the performance of string concatenation

    The string concatenation operator (+) is a convenient way to combine a few strings into one. It is fine for generating
    a single line of output or constructing the string representation of a small, fixed-size object, but it does not scale.
    Using the string concatenation operator repeatedly to concatenate n strings requires time quadratic in n. This is an
    unfortunate consequence of the fact that strings are immutable (Item 17). When two strings are concatenated, the
    contents of both are copied.

    For example, consider this method, which constructs the string representation of a billing statement by repeatedly
    concatenating a line for each item:
        // Inappropriate use of string concatenation - Performs poorly!
        public String statement() {
            String result = "";
            for (int i = 0; i < numItems(); i++)
                result += lineForItem(i); // String concatenation
            return result;
        }
    The method performs abysmally if the number of items is large. To achieve acceptable performance, use a StringBuilder
    in place of a String to store the statement under construction:
        public String statement() {
            StringBuilder b = new StringBuilder(numItems() * LINE_WIDTH);
            for (int i = 0; i < numItems(); i++)
                b.append(lineForItem(i));
            return b.toString();
        }

!!!!The moral is simple: Don’t use the string concatenation operator to combine more than a few strings unless performance
    is irrelevant. Use StringBuilder’s append method instead. Alternatively, use a character array, or
    process the strings one at a time instead of combining them.


Item 64 - Refer to objects by their interfaces

    Item 51 says that you should use interfaces rather than classes as parameter types.
    More generally, you should favor the use of interfaces over classes to refer to objects. If appropriate interface
    types exist, then parameters, return values, variables, and fields should all be declared using interface types. The only
    time you really need to refer to an object’s class is when you’re creating it with a constructor

        // Good - uses interface as type
        Set<Son> sonSet = new LinkedHashSet<>();

        not this:

        // Bad - uses class as type!
        LinkedHashSet<Son> sonSet = new LinkedHashSet<>();
!!!
    If you get into the habit of using interfaces as types, your program will be much more flexible. If you decide that
    you want to switch implementations, all you have to do is change the class name in the constructor (or use a different
    static factory).

    There is one caveat: if the original implementation offered some special functionality not required by the general
    contract of the interface and the code depended on that functionality, then it is critical that the new implementation
    provide the same functionality. For example, if the code surrounding the first declaration depended on
    LinkedHashSet’s ordering policy, then it would be incorrect to substitute HashSet for LinkedHashSet in the
    declaration, because HashSet makes no guarantee concerning iteration order

!!!
    It is entirely appropriate to refer to an object by a class rather than an interface if no appropriate interface
    exists. For example, consider value classes, such as String and BigInteger. Value classes are rarely written with
    multiple implementations in mind. They are often final and rarely have corresponding interfaces. It is perfectly
    appropriate to use such a value class as a parameter, variable, field, or return type
!!!
    A second case in which there is no appropriate interface type is that of objects belonging to a framework whose
    fundamental types are classes rather than interfaces. If an object belongs to such a class-based framework, it is
    preferable to refer to it by the relevant base class, which is often abstract, rather than by its implementation class.
    Many java.io classes such as OutputStream fall into this category.
!!!
    A final case in which there is no appropriate interface type is that of classes that implement an interface but also
    provide extra methods not found in the interface—for example, PriorityQueue has a comparator method that is not
    present on the Queue interface. Such a class should be used to refer to its instances only if the program relies on
    the extra methods, and this should be very rare

    Summary : If it does, your program will be more flexible and stylish if you use the interface to refer to the object.
    If there is no appropriate interface, just use the least specific class in the class hierarchy that provides the
    required functionality.


Item 65 - Prefer interfaces to reflection

    The core reflection facility, java.lang.reflect, offers programmatic access to arbitrary classes. Given a Class
    object, you can obtain Constructor, Method, and Field instances representing the constructors, methods, and fields
    of the class represented by the Class instance. These objects provide programmatic access to the class’s member names,
    field types, method signatures, and so on

    Moreover, Constructor, Method, and Field instances let you manipulate their underlying counterparts reflectively: you
    can construct instances, invoke methods, and access fields of the underlying class by invoking methods on the
    Constructor, Method, and Field instances. For example, Method.invoke lets you invoke any method on any object of any
    class (subject to the usual security constraints). Reflection allows one class to use another, even if the latter class did
    not exist when the former was compiled. This power, however, comes at a price:

        • You lose all the benefits of compile-time type checking, including exception checking. If a program attempts to
        invoke a nonexistent or inaccessible method reflectively, it will fail at runtime unless you’ve taken special precautions.
        • The code required to perform reflective access is clumsy and verbose. It is tedious to write and difficult to read.
        • Performance suffers. Reflective method invocation is much slower than normal method invocation. Exactly how much
        slower is hard to say, as there are many factors at work. On my machine, invoking a method with no input
        parameters and an int return was eleven times slower when done reflectively.

    There are a few sophisticated applications that require reflection. Examples include code analysis tools and
    dependency injection frameworks. Even such tools have been moving away from reflection of late, as its disadvantages become
    clearer. If you have any doubts as to whether your application requires reflection, it probably doesn’t.

!!!
    You can obtain many of the benefits of reflection while incurring few of its costs by using it only in a very
    limited form. For many programs that must use a class that is unavailable at compile time, there exists at compile time an
    appropriate interface or superclass by which to refer to the class (Item 64). If this is the case, you can create
    instances reflectively and access them normally via their interface or superclass.

    In summary, reflection is a powerful facility that is required for certain sophisticated system programming tasks,
    but it has many disadvantages. If you are writing a program that has to work with classes unknown at compile time, you
    should, if at all possible, use reflection only to instantiate objects, and access the objects using some interface
    or superclass that is known at compile time


Item 66 - Use native methods judiciously

    The Java Native Interface (JNI) allows Java programs to call native methods, which are methods written in native
    programming languages such as C or C++. Historically, native methods have had three main uses.
    They provide access to platform-specific facilities such as registries.
    They provide access to existing libraries of native code, including legacy libraries that provide access to legacy data.
    Finally, native methods are used to write performance-critical parts of applications in native languages for improved
    performance.

!!!
    It is rarely advisable to use native methods for improved performance. In early releases (prior to Java 3), it was
    often necessary, but JVMs have gotten much faster since then. For most tasks, it is now possible to obtain comparable
    performance in Java. For example, when java.math was added in release 1.1, BigInteger relied on a then-fast
    multiprecision arithmetic library written in C. In Java 3, BigInteger was reimplemented in Java, and carefully tuned
    to the point where it ran faster than the original native implementation.

    The use of native methods has serious disadvantages. Because native languages are not "safe" (Item 50), applications
    using native methods are no longer immune to memory corruption errors. Because native languages are more platform-dependent
    than Java, programs using native methods are less portable. They are also harder to debug. If you aren’t careful,
    native methods can decrease performance because the garbage collector can’t automate, or even track, native memory
    usage (Item 8), and there is a cost associated with going into and out of native code. Finally, native
    methods require “glue code” that is difficult to read and tedious to write.

!!!!
    In summary, think twice before using native methods. It is rare that you need to use them for improved performance.
    If you must use native methods to access low-level resources or native libraries, use as little native code as possible
    and test it thoroughly. A single bug in the native code can corrupt your entire application.


Item 67 - Optimize judiciously

    There are three aphorisms concerning optimization that everyone should know:

        More computing sins are committed in the name of efficiency (without necessarily achieving it) than for any other
        single reason—including blind stupidity.  — William A. Wulf

        We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.
        —Donald E. Knuth

        We follow two rules in the matter of optimization:
            Rule 1. Don’t do it.
            Rule 2 (for experts only). Don’t do it yet—that is, not until you have a perfectly clear and unoptimized solution.
        —M. A. Jackson

    All of these aphorisms predate the Java programming language by two
    decades. They tell a deep truth about optimization: it is easy to do more harm than
    good, especially if you optimize prematurely. In the process, you may produce
    software that is neither fast nor correct and cannot easily be fixed.

!!!
    Don’t sacrifice sound architectural principles for performance. Strive to write good programs rather than fast ones.
    If a good program is not fast enough, its architecture will allow it to be optimized.
    This does not mean that you can ignore performance concerns until your program is complete. Implementation problems can
    be fixed by later optimization, but pervasive architectural flaws that limit performance can be impossible to fix
    without rewriting the system

    Strive to avoid design decisions that limit performance. The components of a design that are most difficult to
    change after the fact are those specifying interactions between components and with the outside world. Chief among these
    design components are APIs, wire-level protocols, and persistent data formats.

    Consider the performance consequences of your API design decisions.
    Making a public type mutable may require a lot of needless defensive copying (Item 50). Similarly, using inheritance
    in a public class where composition would have been appropriate ties the class forever to its superclass, which can place
    artificial limits on the performance of the subclass (Item 18). As a final example, using an implementation type
    rather than an interface in an API ties you to a specific implementation, even though faster implementations may be
    written in the future (Item 64)
!!
    Once you’ve carefully designed your program and produced a clear, concise, and well-structured implementation, then
    it may be time to consider optimization,  assuming you’re not already satisfied with the performance of the program.

    Recall that Jackson’s two rules of optimization were “Don’t do it,” and “(for experts only). Don’t do it yet.” He
    could have added one more: measure performance before and after each attempted optimization. You may be surprised by
    what you find. Often, attempted optimizations have no measurable effect on performance; sometimes, they make it worse

!!!!
    Common wisdom says that programs spend 90 percent of their time in 10 percent of their code.

    Profiling tools can help you decide where to focus your optimization efforts.
    These tools give you runtime information, such as roughly how much time each method is consuming and how many times
    it is invoked.

    The more code in the system, the more important it is to use a profiler.
    It’s like looking for a needle in a haystack: the bigger the haystack, the more useful
    it is to have a metal detector. Another tool that deserves special mention is jmh,
    which is not a profiler but a microbenchmarking framework that provides
    unparalleled visibility into the detailed performance of Java code [JMH].    (see Security github project where i used this)

    If you will be running your program on multiple implementations or
    multiple hardware platforms, it is important that you measure the effects of your
    optimization on each. Occasionally you may be forced to make trade-offs between
    performance on different implementations or hardware platforms.

    To summarize, do not strive to write fast programs—strive to write good ones; speed will follow. But do think about
    performance while you’re designing systems, especially while you’re designing APIs, wire-level protocols, and
    persistent data formats. When you’ve finished building the system, measure its performance. If it’s fast enough,
    you’re done. If not, locate the source of the problem with the aid of a profiler and go to work optimizing the
    relevant parts of the system. The first step is to examine your choice of algorithms: no amount of low-level
    optimization can make up for a poor choice of algorithm. Repeat this process as necessary, measuring the performance
    after every change, until you’re satisfied


Item 68 - Adhere to generally accepted naming conventions

    The Java platform has a well-established set of naming conventions, many of which are contained in The Java
    Language Specification. Loosely speaking, naming conventions fall into two categories: typographical and grammatical.

    There are only a handful of typographical naming conventions, covering packages, classes, interfaces, methods, fields,
    and type variables. You should rarely violate them and never without a very good reason. If an API violates these
    conventions, it may be difficult to use.

!!!
    Package and module names should be hierarchical with the components separated by periods. Components should consist
    of lowercase alphabetic characters and, rarely, digits. The name of any package that will be used outside
    your organization should begin with your organization’s Internet domain name with the components reversed, for example,
    edu.cmu, com.google, org.eff. The standard libraries and optional packages, whose names begin with java and
    javax, are exceptions to this rule. Users must not create packages or modules whose names begin with java or javax

!!!
    The remainder of a package name should consist of one or more components describing the package. Components should
    be short, generally eight or fewer characters. Meaningful abbreviations are encouraged, for example, util rather
    than utilities. Acronyms are acceptable, for example, awt. Components should generally consist of a single word or
    abbreviation.
            Dan : This and other github projects are for practice only..hence the longer package names, with camelcase

    Class and interface names, including enum and annotation type names, should consist of one or more words, with the
    first letter of each word capitalized, for example, List or FutureTask. Abbreviations are to be avoided, except for
    acronyms and certain common abbreviations like max and min

    Method and field names follow the same typographical conventions as class and interface names, except that the first
    letter of a method or field name should be lowercase, for example, "remove" or "ensureCapacity". If an acronym occurs as
    the first word of a method or field name, it should be lowercase
    The sole exception to the previous rule concerns “constant fields,” whose names should consist of one or more
    uppercase words separated by the underscore character, for example, VALUES or NEGATIVE_INFINITY. A constant field is
    a static final field whose value is immutable. If a static final field has a primitive type or an immutable reference
    type (Item 17), then it is a constant field. For example, enum constants are constant fields. If a static final field
    has a mutable reference type, it can still be a constant field if the referenced object is immutable. Note that
    constant fields constitute the only recommended use of underscores.

    Local variable names have similar typographical naming conventions to member names, except that abbreviations are
    permitted, as are individual characters and short sequences of characters whose meaning depends on the context in which
    they occur, for example, i, denom, houseNum.
!!   Input parameters are a special kind of local variable. They should be  named much more carefully than ordinary local
    variables, as their names are an integral part of their method’s documentation.

!!!
    Type parameter names usually consist of a single letter. Most commonly it is one of these five: T for an arbitrary
    type, E for the element type of a collection, K and V for the key and value types of a map, and X for an exception.
    The return type of a function is usually R. A sequence of arbitrary types can be T, U, V or T1, T2, T3.

    Grammatical naming conventions are more flexible and more controversial than typographical conventions.

    Instantiable classes, including enum types, are generally named with a singular noun or noun phrase, such as Thread,
    PriorityQueue, or ChessPiece. Non-instantiable utility classes (Item 4) are often named with a plural noun, such as
    Collectors or Collections. Interfaces are named like classes, for example, Collection or Comparator, or with an
    adjective ending in "able" or "ible", for example, Runnable, Iterable, or Accessible. Because annotation types have
    so many uses, no part of speech predominates. Nouns, verbs, prepositions, and adjectives are all common, for example,
    BindingAnnotation, Inject, ImplementedBy, or Singleton.

    Methods that perform some action are generally named with a verb or verb phrase (including object), for example,
    append or drawImage. Methods that return a boolean value usually have names that begin with the word "is" or, less
    commonly, "has", followed by a noun, noun phrase, or any word or phrase that functions
    as an adjective, for example, isDigit, isProbablePrime, isEmpty, isEnabled, or hasSiblings.

    There is also a strong precedent for following this naming convention if a class contains both a setter and a getter
    for the same attribute. In this case, the two methods are typically named getAttribute and setAttribute.

    A few method names deserve special mention. Instance methods that convert the type of an object, returning an independent
    object of a different type, are often called toType, for example, toString or toArray. Methods that return a view
    (Item 6) whose type differs from that of the receiving object are often called asType, for example, asList. Methods that
    return a primitive with the same value as the object on which they’re invoked are often called typeValue, for example,
    intValue. Common names for static factories include from, of, valueOf, instance, getInstance, newInstance, getType,
    and newType (Item 1, page 9).

    To summarize, internalize the standard naming conventions and learn to use them as second nature.
    The typographical conventions are straightforward and largely unambiguous; the grammatical conventions are more
    complex and looser.
    To quote from The Java Language Specification, “These conventions should not be followed slavishly if long-held
    conventional usage dictates otherwise.” Use common sense.


===============================================================================================================
===============================================================================================================
Chapter 10 - Exceptions

WHEN used to best advantage, exceptions can improve a program’s readability, reliability, and maintainability.
When used improperly, they can have the opposite effect. This chapter provides guidelines for using exceptions effectively


Item 69 - Use exceptions only for exceptional conditions

    // Horrible abuse of exceptions. Don't ever do this!
    try {
        int i = 0;
        while(true)
            range[i++].climb();
    } catch (ArrayIndexOutOfBoundsException e) {
    }

    What does this code do? It’s not at all obvious from inspection, and that’s reason enough not to use it (Item 67).
    It turns out to be a horribly ill-conceived idiom for looping through the elements of an array. The infinite loop
    terminates by throwing, catching, and ignoring an ArrayIndexOutOfBoundsException when it
    attempts to access the first array element outside the bounds of the array.

!!
    Because exceptions are designed for exceptional circumstances, there is little incentive for JVM implementors to
    make them as fast as explicit tests.

    Placing code inside a try-catch block inhibits certain optimizations that JVM implementations might otherwise perform.

    If there is a bug in the loop, the use of exceptions for flow control can mask the bug, greatly complicating the
    debugging process.

!!! The moral of this story is simple: Exceptions are, as their name implies, to be used only for exceptional conditions;
    they should never be used for ordinary control flow.

    This principle also has implications for API design. A well-designed API must not force its clients to use exceptions
    for ordinary control flow.

    A class with a “state-dependent” method that can be invoked only under certain unpredictable conditions should generally
    have a separate “state-testing” method indicating whether it is appropriate to invoke the state-dependent method
    (for ex Iterator with hasNext method)

    In summary, exceptions are designed for exceptional conditions. Don’t use
    them for ordinary control flow, and don’t write APIs that force others to do so


Item 70 - Use checked exceptions for recoverable conditions and runtime exceptions for programming errors

    Java provides three kinds of throwables: checked exceptions, runtime exceptions, and
    errors. There is some confusion among programmers as to when it is appropriate to
    use each kind of throwable. While the decision is not always clear-cut, there are some
    general rules that provide strong guidance.

!!!!
    The cardinal rule in deciding whether to use a checked or an unchecked exception is this: use checked exceptions for
    conditions from which the caller can reasonably be expected to recover. By throwing a checked exception, you
    force the caller to handle the exception in a catch clause or to propagate it outward. Each checked exception that a
    method is declared to throw is therefore a potent indication to the API user that the associated condition is a possible
    outcome of invoking the method.

    By confronting the user with a checked exception, the API designer presents a mandate to recover from the condition.
    The user can disregard the mandate by Fcatching the exception and ignoring it, but this is usually a bad idea (Item 77).
!!
    There are two kinds of unchecked throwables: runtime exceptions and errors.
    They are identical in their behavior: both are throwables that needn’t, and generally shouldn’t, be caught. If a program
    throws an unchecked exception or an error, it is generally the case that recovery is impossible and continued execution
    would do more harm than good. If a program does not catch such a throwable, it will cause the current thread to halt
    with an appropriate error message.
!!!!
    Use runtime exceptions to indicate programming errors. The great majority of runtime exceptions indicate precondition
    violations. A precondition violation is simply a failure by the client of an API to adhere to the contract established
    by the API specification. For example, the contract for array access specifies that the array index must be between zero
    and the array length minus one, inclusive. ArrayIndexOutOfBoundsException indicates that this precondition was violated.

    If resource exhaustion is caused by a temporary shortage or by temporarily heightened demand, the condition may well
    be recoverable. It is a matter of judgment on the part of the API designer whether a given instance of
    resource exhaustion is likely to allow for recovery. If you believe a condition is likely to allow for recovery, use
    a checked exception; if not, use a runtime exception If it isn’t clear whether recovery is possible, you’re probably
    better off using an unchecked exception, for reasons discussed in Item 71.

!!!!
    While the Java Language Specification does not require it, there is a strong convention that errors are reserved for
    use by the JVM to indicate resource deficiencies, invariant failures, or other conditions that make it impossible to
    continue execution. Given the almost universal acceptance of this convention, it’s best not to implement any new Error
    subclasses. Therefore, all of the unchecked throwables you implement should subclass RuntimeException (directly or
    indirectly). Not only shouldn’t you define Error subclasses, but with the exception of AssertionError, you shouldn’t
    throw them either.

!!!
    Because checked exceptions generally indicate recoverable conditions, it’s especially important for them to provide
    methods that furnish information to help the caller recover from the exceptional condition. For example, suppose a checked
    exception is thrown when an attempt to make a purchase with a gift card fails due to insufficient funds. The exception
    should provide an accessor method to query the amount of the shortfall. This will enable the caller to relay the amount
    to the shopper. See Item 75 for more on this topic.

    To summarize, throw checked exceptions for recoverable conditions and unchecked exceptions for programming errors.
    When in doubt, throw unchecked exceptions. Don’t define any throwables that are neither checked exceptions nor
    runtime exceptions. Provide methods on your checked exceptions to aid in recovery.


Item 71 - Avoid unnecessary use of checked exceptions

    Many Java programmers dislike checked exceptions, but used properly, they can improve APIs and programs. Unlike
    return codes and unchecked exceptions, they force programmers to deal with problems, enhancing reliability. That said,
    overuse of checked exceptions in APIs can make them far less pleasant to use. If a method throws checked exceptions,
    the code that invokes it must handle them in one or more catch blocks, or declare that it throws them and let them
    propagate outward. Either way, it  places a burden on the user of the API. The burden increased in Java 8, as methods
    throwing checked exceptions can’t be used directly in streams (Items 45–48).

    This burden may be justified if the exceptional condition cannot be prevented by proper use of the API and the
    programmer using the API can take some useful action once confronted with the exception. Unless both of these conditions
    are met, an unchecked exception is appropriate.
    As a litmus test, ask yourself how the programmer will handle the exception. Is this the best that can be done?

    If the programmer can do no better, an unchecked exception is called for.

    it pays to ask yourself if there is a way to avoid the checked exception.

    The easiest way to eliminate a checked exception is to return an optional of the desired result type (Item 55).
    Instead of throwing a checked exception, the method simply returns an empty optional. The disadvantage of this technique is
    that the method can’t return any additional information detailing its inability to perform the desired computation.
    Exceptions, by contrast, have descriptive types, and can export methods to provide additional information (Item 70).

    In summary, when used sparingly, checked exceptions can increase the reliability of programs; when overused, they
    make APIs painful to use. If callers won’t be able to recover from failures, throw unchecked exceptions. If recovery
    may be possible and you want to force callers to handle exceptional conditions, first consider returning an optional.
    Only if this would provide insufficient information in the case of failure should you throw a checked exception.


Item 72 - Favor the use of standard exceptions

    An attribute that distinguishes expert programmers from less experienced ones is
    that experts strive for and usually achieve a high degree of code reuse. Exceptions
    are no exception to the rule that code reuse is a good thing. The Java libraries provide
    a set of exceptions that covers most of the exception-throwing needs of most APIs.

    A close second is that programs using your API are easier to read because they aren’t cluttered with
    unfamiliar exceptions. Last (and least), fewer exception classes means a smaller memory footprint and less time spent
    loading classes.
!!
    The most commonly reused exception type is IllegalArgumentException (Item 49). This is generally the exception to
    throw when the caller passes in an argument whose value is inappropriate. For example, this would be the exception
    to throw if the caller passed a negative number in a parameter representing the number of times some action was to
    be repeated

    Another commonly reused exception is IllegalStateException. This is generally the exception to throw if the invocation
    is illegal because of the state of the receiving object. For example, this would be the exception to throw if the
    caller attempted to use some object before it had been properly initialized.

!!
    If a caller passes null in some parameter for which null values are prohibited, convention dictates that
    NullPointerException be thrown rather than IllegalArgumentException. Similarly, if a caller passes an out-of-range value in
    a parameter representing an index into a sequence, IndexOutOfBoundsException should be thrown rather than
    IllegalArgumentException.

    For example, it would be appropriate to reuse ArithmeticException and NumberFormatException if you were
    implementing arithmetic objects such as complex numbers or rational numbers.

!!!!!
    Do not reuse Exception, RuntimeException, Throwable, or Error directly.
    Treat these classes as if they were abstract. You can't reliably test for these exceptions because they are superclasses
    of other exceptions that a method may throw.


Item 73 - Throw exceptions appropriate to the abstraction

    It is disconcerting when a method throws an exception that has no apparent connection to the task that it performs.
    This often happens when a method propagates an exception thrown by a lower-level abstraction. Not only is it
    disconcerting, but it pollutes the API of the higher layer with implementation details. If the implementation of the
    higher layer changes in a later release, the exceptions it throws will change too, potentially breaking existing client
    programs.
!!!
    To avoid this problem, higher layers should catch lower-level exceptions and, in their place, throw exceptions that
    can be explained in terms of the higher-level abstraction. This idiom is known as exception translation:

        // Exception Translation
        try {
            ... // Use lower-level abstraction to do our bidding
        } catch (LowerLevelException e) {
            throw new HigherLevelException(...);
        }

!!
    A special form of exception translation called exception chaining is called for in cases where the lower-level
    exception might be helpful to someone debugging the problem that caused the higher-level exception. The lower-level
    exception (the cause) is passed to the higher-level exception, which provides an accessor method (Throwable’s getCause
    method) to retrieve the lower-level exception:

        // Exception Chaining
        try {
            ... // Use lower-level abstraction to do our bidding
        } catch (LowerLevelException cause) {
            throw new HigherLevelException(cause);
        }

    The higher-level exception’s constructor passes the cause to a chaining-aware
    superclass constructor, so it is ultimately passed to one of Throwable’s chainingaware constructors, such as
    Throwable(Throwable):

        // Exception with chaining-aware constructor
        class HigherLevelException extends Exception {
            HigherLevelException(Throwable cause) {
                super(cause);
            }
        }
!!
    While exception translation is superior to mindless propagation of exceptions from lower layers, it should not be overused.
    Where possible, the best way to deal with exceptions from lower layers is to avoid them, by ensuring that lower-level
    methods succeed. Sometimes you can do this by checking the validity of the higher-level method’s parameters before
    passing them on to lower layers.

!!!
    If it is impossible to prevent exceptions from lower layers, the next best thing is to have the higher layer silently
    work around these exceptions, insulating the caller of the higher-level method from lower-level problems. Under these
    circumstances, it may be appropriate to log the exception using some appropriate logging facility such as
    java.util.logging. This allows programmers to investigate the problem, while insulating client code and the users from it.

    In summary, if it isn’t feasible to prevent or to handle exceptions from lower layers, use exception translation,
    unless the lower-level method happens to guarantee that all of its exceptions are appropriate to the higher level. Chaining
    provides the best of both worlds: it allows you to throw an appropriate higher-level
    exception, while capturing the underlying cause for failure analysis (Item 75).


Item 74 - Document all exceptions thrown by each method

    A description of the exceptions thrown by a method is an important part of the documentation required to use the
    method properly. Therefore, it is critically important that you take the time to carefully document all of the
    exceptions thrown by each method (Item 56).
!!!
    Always declare checked exceptions individually, and document precisely the conditions under which each one is thrown
    using the Javadoc @throws tag.
    Don’t take the shortcut of declaring that a method throws some superclass of multiple exception classes that it can
    throw. As an extreme example, don’t declare that a public method throws Exception or, worse, throws Throwable.

!!!
    While the language does not require programmers to declare the unchecked exceptions that a method is capable of
    throwing, it is wise to document them as carefully as the checked exceptions. Unchecked exceptions generally represent
    programming errors (Item 70), and familiarizing programmers with all of the errors they can make helps them avoid
    making these errors.
    A well-documented list of the unchecked exceptions that a method can throw effectively describes the
    preconditions for its successful execution.

    It should be noted that documenting all of the unchecked exceptions that each
    method can throw is an ideal, not always achievable in the real world.

    It is particularly important that methods in interfaces document the unchecked
    exceptions they may throw. This documentation forms a part of the interface’s
    general contract and enables common behavior among multiple implementations
    of the interface.

    Use the Javadoc @throws tag to document each exception that a method can throw, but do not use the throws keyword
    on unchecked exceptions.

    If an exception is thrown by many methods in a class for the same reason, you can document the exception in the
    class’s documentation comment rather than documenting it individually for each method.

    In summary, document every exception that can be thrown by each method
    that you write. This is true for unchecked as well as checked exceptions, and for
    abstract as well as concrete methods. This documentation should take the form of
    @throws tags in doc comments. Declare each checked exception individually in a
    method’s throws clause, but do not declare unchecked exceptions. If you fail to
    document the exceptions that your methods can throw, it will be difficult or
    impossible for others to make effective use of your classes and interfaces


Item 75 - Include failure-capture information in detail messages

    When a program fails due to an uncaught exception, the system automatically prints
    out the exception’s stack trace. The stack trace contains the exception’s string
    representation, the result of invoking its toString method. This typically consists
    of the exception’s class name followed by its detail message.

    it is critically important that the exception’s toString method return as much information as possible concerning
    the cause of the failure. In other words, the detail message of an exception should capture the failure for
    subsequent analysis.

    To capture a failure, the detail message of an exception should contain the
    values of all parameters and fields that contributed to the exception. For
    example, the detail message of an IndexOutOfBoundsException should contain
    the lower bound, the upper bound, and the index value that failed to lie between
    the bounds. This information tells a lot about the failure

!!!
    One caveat concerns security-sensitive information. Because stack traces may be seen by many people in the process
    of diagnosing and fixing software issues, do not include passwords, encryption keys, and the like in detail messages.

    The detail message of an exception should not be confused with a user-level error message, which must be intelligible
    to end users. Unlike a user-level error message, the detail message is primarily for the benefit of programmers or site
    reliability engineers, when analyzing a failure.

    One way to ensure that exceptions contain adequate failure-capture information in their detail messages is to require
    this information in their constructors instead of a string detail message. The detail message can then be
    generated automatically to include the information. For example, instead of a String constructor,
    IndexOutOfBoundsException could have had a constructor that looks like this
        (see source code example in IndexOutOfBoundsException from pck item74)

!!!
    As suggested in Item 70, it may be appropriate for an exception to provide accessor methods for its failure-capture
    information (lowerBound, upperBound, and index in the above example). It is more important to provide such accessor
    methods on checked exceptions than unchecked, because the failure-capture information could be useful in recovering
    from the failure. It is rare (although not inconceivable) that a programmer might want programmatic access to the details
    of an unchecked exception.


Item 76 - Strive for failure atomicity

!!!!
    After an object throws an exception, it is generally desirable that the object still be in
    a well-defined, usable state, even if the failure occurred in the midst of performing
    an operation. This is especially true for checked exceptions, from which the caller is
    expected to recover. Generally speaking, a failed method invocation should leave
    the object in the state that it was in prior to the invocation. A method with this
    property is said to be failure-atomic.

    There are several ways to achieve this effect. The simplest is to design
    immutable objects (Item 17). If an object is immutable, failure atomicity is free. If
    an operation fails, it may prevent a new object from getting created, but it will
    never leave an existing object in an inconsistent state, because the state of each
    object is consistent when it is created and can’t be modified thereafter
!!!
    For methods that operate on mutable objects, the most common way to
    achieve failure atomicity is to check parameters for validity before performing the
    operation (Item 49). This causes most exceptions to get thrown before object
    modification commences. For example, consider the Stack.pop method in Item 7:

        public Object pop() {
        if (size == 0)
            throw new EmptyStackException();
        Object result = elements[--size];
        elements[size] = null; // Eliminate obsolete reference
        return result;
        }

    If the initial size check were eliminated, the method would still throw an exception when it attempted to pop an
    element from an empty stack. It would, however, leave the size field in an inconsistent (negative) state, causing
    any future method invocations on the object to fail. Additionally, the ArrayIndexOutOfBoundsException thrown by the
    pop method would be inappropriate to the abstraction (Item 73).

!!!
    A closely related approach to achieving failure atomicity is to order the computation so that any part that may fail
    takes place before any part that modifies the object.
!!
    A third approach to achieving failure atomicity is to perform the operation on a temporary copy of the object and to
    replace the contents of the object with the temporary copy once the operation is complete. This approach occurs naturally
    when the computation can be performed more quickly once the data has been stored in a temporary data structure. For
    example, some sorting functions copy their input list into an array prior to sorting to reduce the cost of accessing
    elements in the inner loop of the sort. This is done for performance, but as an
    added benefit, it ensures that the input list will be untouched if the sort fails.

!!!
    While failure atomicity is generally desirable, it is not always achievable. For example, if two threads attempt to
    modify the same object concurrently without proper synchronization, the object may be left in an inconsistent state.
    It would therefore be wrong to assume that an object was still usable after catching a ConcurrentModificationException.
    Errors are unrecoverable, so you need not even attempt to preserve failure atomicity when throwing AssertionError.

    Even where failure atomicity is possible, it is not always desirable. For some operations, it would significantly
    increase the cost or complexity. That said, it is often both free and easy to achieve failure atomicity once you’re
    aware of the issue.

    In summary, as a rule, any generated exception that is part of a method’s specification should leave the object in
    the same state it was in prior to the method invocation. Where this rule is violated, the API documentation should clearly
    indicate what state the object will be left in. Unfortunately, plenty of existing API documentation fails to live
    up to this ideal.


Item 77 - Don't ignore exceptions

    While this advice may seem obvious, it is violated often enough that it bears repeating. When the designers of an
    API declare a method to throw an exception, they are trying to tell you something. Don’t ignore it! It is easy to
    ignore exceptions by surrounding a method invocation with a try statement whose catch block is empty:

        // Empty catch block ignores exception - Highly suspect!
        try {
            ...
        } catch (SomeException e) {
        }

!!!
    An empty catch block defeats the purpose of exceptions, which is to force you to handle exceptional conditions.
    Ignoring an exception is analogous to ignoring a fire alarm—and turning it off so no one else gets a chance to see if
    there’s a real fire.
    Whenever you see an empty catch block, alarm bells should go off in your head.

!!!!
    If you choose to ignore an exception, the catch block should contain a comment explaining why it is appropriate to
    do so, and the variable should be named ignored:
!!
    It may be wise to log the exception, so that you can investigate the matter if these exceptions happen often

    Whether an exception represents a predictable exceptional condition or a programming error, ignoring it with an
    empty catch block will result in a program that continues silently in the face of error. The program might then fail at an
    arbitrary time in the future, at a point in the code that bears no apparent relation to  the source of the problem.
    Properly handling an exception can avert failure entirely. Merely letting an exception propagate outward can at least
    cause the program to fail swiftly, preserving information to aid in debugging the failure.


===============================================================================================================
===============================================================================================================
Chapter 11 - Concurrency

THREADS allow multiple activities to proceed concurrently. Concurrent programming is harder than single-threaded programming,
because more things can go wrong, and failures can be hard to reproduce. You can’t avoid concurrency. It is
inherent in the platform and a requirement if you are to obtain good performance from multicore processors, which are
now ubiquitous.


Item 78 - Synchronize access to shared mutable data

!!
    The synchronized keyword ensures that only a single thread can execute a method or block at one time.

    Many programmers think of synchronization solely as a means of mutual exclusion, to prevent an object from being
    seen in an inconsistent state by one thread while it’s being modified by another. In this view, an object is
    created in a consistent state (Item 17) and locked by the methods that access it. These methods observe the state
    and optionally cause a state transition, transforming the object from one consistent state to another. Proper use
    of synchronization guarantees that no method will ever observe the object in an inconsistent state
!!!
    This view is correct, but it’s only half the story. Without synchronization, one thread’s changes might not be
    visible to other threads. Not only does synchronization prevent threads from observing an object in an inconsistent
    state, but it ensures that each thread entering a synchronized method or block sees the effects
    of all previous modifications that were guarded by the same lock.

    The language specification guarantees that reading or writing a variable is atomic unless the variable is of type
    long or double. In other words, reading a variable other than a long or double is guaranteed to return a
    value that was stored into that variable by some thread, even if multiple threads modify the variable concurrently
    and without synchronization.
!!!
    Synchronization is required for reliable communication between threads as well as for mutual exclusion. This is due to
    a part of the language specification known as the memory model, which specifies when and how changes made by one
    thread become visible to others
!!
    The libraries provide the Thread.stop method, but this method was deprecated long ago because it is inherently
    unsafe—its use can result in data corruption. Do not use Thread.stop.

    A recommended way to stop one thread from another is to have the first thread poll a boolean field that is
    initially false but can be set to true by the second thread to indicate that the first thread is to stop itself.
    Because reading and writing a boolean field is atomic, some programmers dispense (remove or do not use) with
    synchronization when accessing the field
        (!!! this is very bad...see code example class StopThread which runs forever)

    In the absence of synchronization, it’s quite acceptable for the virtual machine to transform this code:
        while (!stopRequested)
            i++;
    into this code:
        if (!stopRequested)
            while (true)
                i++;
    This optimization is known as hoisting, and it is precisely what the OpenJDK Server VM does. The result is a
    liveness failure: the program fails to make progress.

!!!!
    Note that both the write method (requestStop) and the read method (stopRequested) are synchronized. It is not
    sufficient to synchronize only the write method! Synchronization is not guaranteed to work unless both read and
    write operations are synchronized. Occasionally a program that synchronizes only writes (or reads) may appear to
    work on some machines, but in this case, appearances are deceiving
!!!!
    The actions of the synchronized methods in StopThread would be atomic even without synchronization. In other
    words, the synchronization on these methods is used solely for its communication effects, not for mutual exclusion.
    While the cost of synchronizing on each iteration of the loop is small, there is a correct alternative that is
    less verbose and whose performance is likely to be better.
    The locking in the second version of StopThread can be omitted if stopRequested is declared volatile.
    While the volatile modifier performs no mutual exclusion, it guarantees that any thread that reads the field will
    see the most recently written value.

    You do have to be careful when using volatile. Consider the following method, which is supposed to generate serial
    numbers:
        // Broken - requires synchronization!
        private static volatile int nextSerialNumber = 0;
        public static int generateSerialNumber() {
            return nextSerialNumber++;
        }

!!!!
    The problem is that the increment operator (++) is not atomic. It performs two operations on the nextSerialNumber
    field: first it reads the value, and then it writes back a new value, equal to the old value plus one. If a second
    thread reads the field between the time a thread reads the old value and writes back a new one,
    the second thread will see the same value as the first and return the same serial number.
    This is a safety failure: the program computes the wrong results.

    One way to fix generateSerialNumber (method from above) is to add the synchronized modifier to its declaration.
    This ensures that multiple invocations won’t be interleaved and that each invocation of the method will see the
    effects of all previous invocations.
    Once you’ve done that, you can and should remove the volatile modifier from nextSerialNumber.

    Better still, follow the advice in Item 59 and use the class AtomicLong, which is part of java.util.concurrent.atomic.
    This package provides primitives for lock-free, thread-safe programming on single variables. While volatile provides
    only the communication effects of synchronization, this package also provides atomicity. This is exactly what we
    want for generateSerialNumber, and it is likely to outperform the synchronized version:
        // Lock-free synchronization with java.util.concurrent.atomic
        private static final AtomicLong nextSerialNum = new AtomicLong();
        public static long generateSerialNumber() {
            return nextSerialNum.getAndIncrement();
        }

!!!!!
    The best way to avoid the problems discussed in this item is not to share mutable data.
    Either share immutable data (Item 17) or don’t share at all.
    In other words, confine mutable data to a single thread. If you adopt this policy, it is important to document it
    so that the policy is maintained as your program evolves.
    It is also important to have a deep understanding of the frameworks and libraries you’re using because they may
    introduce threads that you are unaware of.
!!
    objects are said to be "effectively immutable" : It is acceptable for one thread to modify a data object for a while
    and then to share it with other threads, synchronizing only the act of sharing the object reference. Other threads
    can then read the object without further synchronization so long as it isn’t modified again
!!
    Transferring such an object reference from one thread to others is called "safe publication". There are many ways
    to safely publish an object reference: you can store it in a static field as part of class initialization;
    you can store it in a volatile field, a final field, or a field that is accessed with normal locking; or you can
    put it into a concurrent collection (Item 81).

    In summary, when multiple threads share mutable data, each thread that reads or writes the data must perform
    synchronization. In the absence of synchronization, there is no guarantee that one thread’s changes will be visible
    to another thread. The penalties for failing to synchronize shared mutable data are liveness and safety failures.
    These failures are among the most difficult to debug.
    They can be intermittent and timing-dependent, and program behavior can vary radically from one VM to another.
    If you need only inter-thread communication, and not mutual exclusion, the volatile modifier is an acceptable form
    of synchronization, but it can be tricky to use correctly


Item 79 - Avoid excessive synchronization

!!
    Item 78 warns of the dangers of insufficient synchronization. This item concerns the opposite problem. Depending on
    the situation, excessive synchronization can cause reduced performance, deadlock, or even nondeterministic behavior

!!!
    To avoid liveness and safety failures, never cede control to the client within a synchronized method or block.
    In other words, inside a synchronized region, do not invoke a method that is designed to be overridden, or one provided
    by a client in the form of a function object (Item 24).
    From the perspective of the class with the synchronized region, such methods are alien.
    The class has no knowledge of what the method does and has no control over it. Depending on
    what an alien method does, calling it from a synchronized region can cause exceptions, deadlocks, or data corruption

    Invoking alien methods from within synchronized regions has caused many deadlocks in real systems, such as GUI toolkits.
!!
    In fact, there’s a better way to move the alien method invocations out of the
    synchronized block. The libraries provide a concurrent collection (Item 81)
    known as CopyOnWriteArrayList that is tailor-made for this purpose. This List
    implementation is a variant of ArrayList in which all modification operations are
    implemented by making a fresh copy of the entire underlying array. Because the
    internal array is never modified, iteration requires no locking and is very fast. For
    most uses, the performance of CopyOnWriteArrayList would be atrocious, but
    it’s perfect for observer lists, which are rarely modified and often traversed

!!!!!
    An alien method might run for an arbitrarily long period. If
    the alien method were invoked from a synchronized region, other threads would be denied access to the protected
    resource unnecessarily.
!!! As a rule, you should do as little work as possible inside synchronized regions. Obtain the lock, examine the shared
    data, transform it as necessary, and drop the lock. If you must perform some time-consuming activity, find a way to
    move it out of the synchronized region without violating the guidelines in Item 78.

!!  The first part of this item was about correctness.
    Now let’s take a brief look at performance. While the cost of synchronization has plummeted since the early
    days of Java, it is more important than ever not to oversynchronize

    If you are writing a mutable class, you have two options: you can omit all synchronization and allow the client to
    synchronize externally if concurrent use is desired, or you can synchronize internally, making the class
    thread-safe (Item 82).
    You should choose the latter option only if you can achieve significantly higher concurrency with internal
    synchronization than you could by having the client lock the entire object externally.
    The collections in java.util (with the exception of the obsolete Vector and Hashtable) take the former approach,
    while those in java.util.concurrent take the latter (Item 81).

    When in doubt, do not synchronize your class, but document that it is not thread-safe.

    If you do synchronize your class internally, you can use various techniques to achieve high concurrency, such as
    lock splitting, lock striping, and nonblocking concurrency control. These techniques are beyond the scope of this
    book, but they are discussed elsewhere.

!!!
    If a method modifies a static field and there is any possibility that the method will be called from multiple threads,
    you must synchronize access to the field internally (unless the class can tolerate nondeterministic behavior). It is not
    possible for a multithreaded client to perform external synchronization on such a method, because unrelated clients
    can invoke the method without synchronization.
    The field is essentially a global variable even if it is private because it can be read and modified by unrelated
    clients. The nextSerialNumber field used by the method generateSerialNumber in Item 78 exemplifies this situation.

    In summary, to avoid deadlock and data corruption, never call an alien method from within a synchronized region.
    More generally, keep the amount of work that you do from within synchronized regions to a minimum.
    When you are designing a mutable class, think about whether it should do its own synchronization. In the
    multicore era, it is more important than ever not to over synchronize. Synchronize your class internally only if
    there is a good reason to do so, and document your decision clearly (Item 82).


Item 80 - Prefer executors, tasks, and streams to threads

    The first edition of this book contained code for a simple work queue [Bloch01,
    Item 49]. This class allowed clients to enqueue work for asynchronous processing
    by a background thread. Luckily, there is no reason to write this sort of code anymore.

    By the time the second edition of this book came out, java.util.concurrent had been added to Java. This package
    contains an Executor Framework, which is a flexible interface-based task execution facility. Creating a work queue
    that is better in every way than the one in the first edition of this book requires but a single line of code:
        ExecutorService exec = Executors.newSingleThreadExecutor();
    Here is how to submit a runnable for execution:
        exec.execute(runnable);
    And here is how to tell the executor to terminate gracefully (if you fail to do this, it is likely that your VM will
    not exit):
        exec.shutdown();
!!!
    You can do many more things with an executor service. For example, you can wait for a particular task to complete
    (with the get method, as shown in Item 79, page 319), you can wait for any or all of a collection of tasks to complete
    (using the invokeAny or invokeAll methods), you can wait for the executor service to terminate (using the
    awaitTermination method), you can retrieve the results of tasks one by one as they complete (using an
    ExecutorCompletionService), you can schedule tasks to run at a particular time or to run periodically (using a
    ScheduledThreadPoolExecutor), and so on

    If you want more than one thread to process requests from the queue, simply call a different static factory that
    creates a different kind of executor service called a thread pool. You can create a thread pool with a fixed or
    variable number of threads. The java.util.concurrent.Executors class contains static factories
    that provide most of the executors you’ll ever need.

    Choosing the executor service for a particular application can be tricky. For a small program, or a lightly loaded
    server, Executors.newCachedThreadPool is generally a good choice because it demands no configuration and generally “does
    the right thing.” But a cached thread pool is not a good choice for a heavily loaded production server!
    Therefore, in a heavily loaded production server, you are much better off using Executors.newFixedThreadPool, which
    gives you a pool with a fixed number of threads, or using the ThreadPoolExecutor class directly, for maximum control.

!!!!!
    you should generally refrain from working directly with threads. When you work directly with threads, a Thread serves
    as both a unit of work and the mechanism for executing it. In the executor framework, the unit of work and the execution
    mechanism are separate. The key abstraction is the unit of work, which is the task.
    There are two kinds of tasks: Runnable and its close cousin, Callable (which is like Runnable, except that it returns
    a value and can throw arbitrary exceptions).
!!! The general mechanism for executing tasks is the executor service. If you think in terms of tasks and let an executor
    service execute them for you, you gain the flexibility to select an appropriate execution policy to meet your needs and to
    change the policy if your needs change. In essence, the Executor Framework does for execution what the Collections
    Framework did for aggregation.

!!! In Java 7, the Executor Framework was extended to support fork-join tasks, which are run by a special kind of
    executor service known as a fork-join pool. A fork-join task, represented by a ForkJoinTask instance, may be split up into
    smaller subtasks, and the threads comprising a ForkJoinPool not only process these tasks but “steal” tasks from one
    another to ensure that all threads remain busy, resulting in higher CPU utilization, higher throughput, and lower latency.
    Writing and tuning fork-join tasks is tricky. Parallel streams (Item 48) are written atop fork join pools and allow
    you to take advantage of their performance benefits with little effort, assuming they are appropriate for the task at hand

    reader is directed to Java Concurrency in Practice


Item 81 - Prefer concurrency utilities to "wait" and "notify"

    The first edition of this book devoted an item to the correct use of wait and notify. Its advice is still valid and
    is summarized at end of this item, but this advice is far less important than it once was. This is because there is
    far less reason to use wait and notify. Since Java 5, the platform has provided higher-level concurrency utilities
    that do the sorts of things you formerly had to hand-code atop wait and notify.
!!  Given the difficulty of using wait and notify correctly, you should use the higher-level concurrency utilities instead.

!!!!
    The higher-level utilities in java.util.concurrent fall into three categories: the Executor Framework, which was
    covered briefly in Item 80; concurrent collections; and synchronizers. Concurrent collections and synchronizers are
    covered briefly in this item

    The concurrent collections are high-performance concurrent implementations of standard collection interfaces such
    as List, Queue, and Map. To provide high concurrency, these implementations manage their own synchronization internally
    (Item 79). Therefore, it is impossible to exclude concurrent activity from a concurrent collection; locking it will
    only slow the program

    Because you can’t exclude concurrent activity on concurrent collections, you can’t atomically compose method
    invocations on them either. Therefore, concurrent collection interfaces were outfitted with state-dependent modify
    operations, which combine several primitives into a single atomic operation. These operations
    proved sufficiently useful on concurrent collections that they were added to the
    corresponding collection interfaces in Java 8, using default methods (Item 21).

!!!
    Besides offering excellent concurrency, ConcurrentHashMap is very fast.
    Concurrent collections make synchronized collections largely obsolete.
    For example, use ConcurrentHashMap in preference to Collections.synchronizedMap. Simply replacing synchronized maps
    with concurrent maps can dramatically increase the performance of concurrent applications
!!!!
    Synchronizers are objects that enable threads to wait for one another, allowing them to coordinate their activities.
    The most commonly used synchronizers are CountDownLatch and Semaphore. Less commonly used are CyclicBarrier and
    Exchanger. The most powerful synchronizer is Phaser

!!   Countdown latches are single-use barriers that allow one or more threads to wait for one or more other threads to
    do something. The sole constructor for CountDownLatch takes an int that is the number of times the countDown method
    must be invoked on the latch before all waiting threads are allowed to proceed.

    When the last worker thread is ready to run the action, the timer thread “fires the starting gun,” allowing the worker
    threads to perform the action.
    As soon as the last worker thread finishes performing the action, the timer thread stops the clock. Implementing this
    logic directly on top of wait and notify would be messy to say the least, but it is surprisingly straightforward on top of
    CountDownLatch

        (see  code example in ConcurrentTimer)

    This item only scratches the surface of what you can do with the concurrency
    utilities. For example, the three countdown latches in the previous example could
    be replaced by a single CyclicBarrier or Phaser instance. The resulting code
    would be a bit more concise but perhaps more difficult to understand.

    Always use the wait loop idiom to invoke the wait method; never invoke it outside of a loop. The loop serves to
    test the condition before and after waiting.

    In summary, using wait and notify directly is like programming in “concurrency assembly language,” as compared to
    the higher-level language provided by java.util.concurrent. There is seldom, if ever, a reason to use wait and
    notify in new code. If you maintain code that uses wait and notify, make sure that it always invokes "wait" from
    within a "while loop" using the standard idiom.
    The notifyAll method should generally be used in preference to "notify". If "notify" is used, great care must be
    taken to ensure liveness.


Item 82 - Document thread safety

    How a class behaves when its methods are used concurrently is an important part
    of its contract with its clients. If you fail to document this aspect of a class’s
    behavior, its users will be forced to make assumptions. If these assumptions are
    wrong, the resulting program may perform insufficient synchronization (Item 78)
    or excessive synchronization (Item 79). In either case, serious errors may result

!!!
    You may hear it said that you can tell if a method is thread-safe by looking for the "synchronized" modifier in
    its documentation. This is wrong on several counts.
    The presence of the synchronized modifier in a method declaration is an implementation detail, not a part of its API.
    It does not reliably indicate that a method is thread-safe.

!!!
    Moreover, the claim that the presence of the synchronized modifier is sufficient to document thread safety embodies
    the misconception that thread safety is an all-or-nothing property. In fact, there are several levels of thread safety.
    To enable safe concurrent use, a class must clearly document what level of thread safety it supports. The following
    list summarizes levels of thread safety.
    It is not exhaustive but covers the common cases:
        • Immutable — Instances of this class appear constant. No external synchronization is necessary. Examples include
            String, Long, and BigInteger (Item 17).
        • Unconditionally thread-safe — Instances of this class are mutable, but the class has sufficient internal
            synchronization that its instances can be used concurrently without the need for any external synchronization.
            Examples include AtomicLong and ConcurrentHashMap.
        • Conditionally thread-safe — Like unconditionally thread-safe, except that some methods require external
            synchronization for safe concurrent use. Examples include the collections returned by the Collections.synchronized
            wrappers, whose iterators require external synchronization.
        • Not thread-safe — Instances of this class are mutable. To use them concurrently, clients must surround each method
            invocation (or invocation sequence) with external synchronization of the clients’ choosing. Examples include the
            general-purpose collection implementations, such as ArrayList and HashMap.
        • Thread-hostile — This class is unsafe for concurrent use even if every method invocation is surrounded by external
            synchronization. Thread hostility usually results from modifying static data without synchronization. No one
            writes a thread-hostile class on purpose; such classes typically result from the failure to consider
            concurrency. When a class or method is found to be thread-hostile, it is typically fixed or deprecated. The
            generateSerialNumber method in Item 78 would be thread-hostile in the absence of internal synchronization

    The description of a class’s thread safety generally belongs in the class’s doc comment, but methods with special
    thread safety properties should describe these properties in their own documentation comments

    Lock fields should always be declared final. This is true whether you use an ordinary monitor lock (as shown above)
    or a lock from the java.util.concurrent.locks package.

    To summarize, every class should clearly document its thread safety properties with a carefully worded prose
    description or a thread safety annotation. The synchronized modifier plays no part in this documentation. Conditionally
    threadsafe classes must document which method invocation sequences require external synchronization and which lock
    to acquire when executing these sequences. If you write an unconditionally thread-safe class, consider using a private
    lock object in place of synchronized methods. This protects you against synchronization interference by clients and
    subclasses and gives you more flexibility to adopt a sophisticated approach to concurrency control in a later release.


Item 83 - Use lazy initialization judiciously

    Lazy initialization is the act of delaying the initialization of a field until its value is
    needed. If the value is never needed, the field is never initialized. This technique is
    applicable to both static and instance fields. While lazy initialization is primarily
    an optimization, it can also be used to break harmful circularities in class and instance initialization
!!
    As is the case for most optimizations, the best advice for lazy initialization is “don’t do it unless you need to”
    (Item 67). Lazy initialization is a double-edged sword. It decreases the cost of initializing a class or creating an
    instance, at the expense of increasing the cost of accessing the lazily initialized field.

    That said, lazy initialization has its uses. If a field is accessed only on a fraction of the instances of a class
    and it is costly to initialize the field, then lazy initialization may be worthwhile. The only way to know for sure
    is to measure the performance of the class with and without lazy initialization.
!!
    Under most circumstances, normal initialization is preferable to lazy initialization.

!!!
    In the presence of multiple threads, lazy initialization is tricky. If two or more threads share a lazily initialized
    field, it is critical that some form of synchronization be employed, or severe bugs can result (Item 78).

    If you need to use lazy initialization for performance on a static field, use the lazy initialization holder class
    idiom. This idiom exploits the guarantee that a class will not be initialized until it is used
        (see code examples, class Initialization)
!!!
    If you need to use lazy initialization for performance on an instance field, use the double-check idiom. This idiom
    avoids the cost of locking when accessing the field after initialization (Item 79). The idea behind the idiom is to
    check the value of the field twice (hence the name double-check): once without locking and then, if the field
    appears to be uninitialized, a second time with locking. Only if the second check indicates that the field is
    uninitialized does the call initialize the field. Because there is no locking once the field is initialized, it is
    critical that the field be declared volatile (Item 78).
        (see code examples, class Initialization)

    In summary, you should initialize most fields normally, not lazily. If you must initialize a field lazily in order
    to achieve your performance goals or to break a harmful initialization circularity, then use the appropriate lazy
    initialization technique. For instance fields, it is the double-check idiom; for static fields, the
    lazy initialization holder class idiom. For instance fields that can tolerate repeated initialization, you may also
    consider the single-check idiom.


Item 84 - Don't depend on the Thread scheduler

    When many threads are runnable, the thread scheduler determines which ones get to run and for how long. Any reasonable
    operating system will try to make this determination fairly, but the policy can vary. Therefore, well-written programs
    shouldn’t depend on the details of this policy.
!!! Any program that relies on the thread scheduler for correctness or performance is likely to be nonportable.

    The main technique for keeping the number of runnable threads low is to have each thread do some useful work, and
    then wait for more. Threads should not run if they aren’t doing useful work. In terms of the Executor Framework
    (Item 80), this means sizing thread pools appropriately and keeping tasks short, but not too short, or dispatching
    overhead will harm performance.
!!
    Threads should not busy-wait, repeatedly checking a shared object waiting for its state to change
        (see code example in SlowCountdownLatch)

    A related technique, to which similar caveats apply, is adjusting thread priorities. Thread priorities are among the
    least portable features of Java. It is not  unreasonable to tune the responsiveness of an application by tweaking a few
    thread priorities, but it is rarely necessary and is not portable. It is unreasonable to attempt to solve a serious
    liveness problem by adjusting thread priorities. The problem is likely to return until you find and fix the
    underlying cause.

    In summary, do not depend on the thread scheduler for the correctness of your program. The resulting program will be
    neither robust nor portable. As a corollary, do not rely on Thread.yield or thread priorities. These facilities are
    merely hints to the scheduler. Thread priorities may be used sparingly to improve the quality of
    service of an already working program, but they should never be used to “fix” a program that barely works.


===============================================================================================================
===============================================================================================================
Chapter 12 - Serialization

THIS chapter concerns object serialization, which is Java’s framework for encoding objects as byte streams (serializing)
and reconstructing objects from their encodings (deserializing). Once an object has been serialized, its encoding
can be sent from one VM to another or stored on disk for later deserialization. This chapter focuses on the dangers of
serialization and how to minimize them.


Item 85 - Prefer alternatives to Java serialization

    While the promise of distributed objects with little effort on the part of the programmer was appealing, the price
    was invisible constructors and blurred lines between API and implementation, with the potential for problems
    with correctness, performance, security, and maintenance. Proponents believed the benefits outweighed the risks,
    but history has shown otherwise

    The vulnerabilities discussed in the early 2000s were transformed into serious exploits over the next decade, famously
    including a ransomware attack on the San Francisco Metropolitan Transit Agency Municipal Railway that shut down the
    entire fare collection system for two days in November 2016
!!!
    Object graphs are deserialized by invoking the readObject method on an ObjectInputStream. This method is essentially a
    magic constructor that can be made to instantiate objects of almost any type on the class path, so long as the type
    implements the Serializable interface. In the process of deserializing a byte stream, this method can execute code
    from any of these types, so the code for all of these types is part of the attack surface.
!!!!
    Java deserialization is a clear and present danger as it is widely used both directly by applications and indirectly
    by Java subsystems such as RMI (Remote Method Invocation), JMX (Java Management Extension), and
    JMS (Java Messaging System). Deserialization of untrusted streams can result in remote code execution (RCE),
    denial-of-service (DoS), and a range of other exploits. Applications can be vulnerable to these attacks even if they
    did nothing wrong
!!
    Attackers and security researchers study the serializable types in the Java libraries and in commonly used third-party
    libraries, looking for methods invoked during deserialization that perform potentially dangerous activities. Such methods
    are known as gadgets. Multiple gadgets can be used in concert, to form a gadget chain. From time to time, a gadget
    chain is discovered that is sufficiently powerful to allow an attacker to execute arbitrary native code on the
    underlying hardware, given only the opportunity to submit a carefully crafted byte stream for deserialization.

    Without using any gadgets, you can easily mount a denial-of-service attack by causing the deserialization of a short
    stream that requires a long time to deserialize. Such streams are known as deserialization bombs
        (see source code in DeserializationBomb class)
!!!!!
    So what can you do defend against these problems? You open yourself up to attack whenever you deserialize a byte
    stream that you don’t trust. The best way to avoid serialization exploits is never to deserialize anything. In the
    words of the computer named Joshua in the 1983 movie WarGames, “the only winning move is not to play.” There is no
    reason to use Java serialization in any new system you write

    The leading cross-platform structured data representations are JSON [JSON] and Protocol Buffers, also known as
    protobuf [Protobuf]. JSON was designed by Douglas Crockford for browser-server communication, and protocol buffers
    were designed by Google for storing and interchanging structured data among its servers. Even though these
    representations are sometimes called language-neutral, JSON was originally developed for JavaScript and protobuf
    for C++; both representations retain vestiges of their origins.

    The most significant differences between JSON and protobuf are that JSON is text-based and human-readable, whereas
    protobuf is binary and substantially more efficient;
!!
    If you can’t avoid Java serialization entirely, perhaps because you’re working in the context of a legacy system
    that requires it, your next best alternative is to never deserialize untrusted data. In particular, you should never
    accept RMI traffic from untrusted sources. The official secure coding guidelines for Java say
    “Deserialization of untrusted data is inherently dangerous and should be avoided.”
    This sentence is set in large, bold, italic, red type, and it is the only text in the entire document that gets this
    treatment [Java-secure].
!!!
    If you can’t avoid serialization and you aren’t absolutely certain of the safety of the data you’re deserializing,
    use the object deserialization filtering added in Java 9 and backported to earlier releases (java.io.ObjectInputFilter).
    This facility lets you specify a filter that is applied to data streams before they’re deserialized. It operates at
    the class granularity, letting you accept or reject certain classes. Accepting classes by default and rejecting a
    list of potentially dangerous  ones is known as blacklisting; rejecting classes by default and accepting a list of
    those that are presumed safe is known as whitelisting. Prefer whitelisting to blacklisting, as blacklisting only
    protects you against known threats.
!!
    The filtering facility will also protect you against excessive memory usage, and excessively deep object graphs,
    but it will not protect you against serialization bombs like the one shown above.

    In summary, serialization is dangerous and should be avoided. If you are designing a system from scratch, use
    a cross-platform structured-data representation such as JSON or protobuf instead. Do not deserialize untrusted data.
    If you must do so, use object deserialization filtering, but be aware that it is not guaranteed to thwart all attacks.
    Avoid writing serializable classes. If you must do so, exercise great caution.


Item 86 - Implement Serializable with great caution

    Allowing a class’s instances to be serialized can be as simple as adding the words implements Serializable to its
    declaration. Because this is so easy to do, there was a common misconception that serialization requires little
    effort on the part of the programmer. The truth is far more complex.
!!
    A major cost of implementing Serializable is that it decreases the flexibility to change a class’s implementation once
    it has been released. When a class implements Serializable, its byte-stream encoding (or serialized form)
    becomes part of its exported API. Once you distribute a class widely, you are generally required to support the
    serialized form forever, just as you are required to support all other parts of the exported API.

    If you do not make the effort to design a custom serialized form but merely accept the default, the serialized form
    will forever be tied to the class’s original internal representation. In other words, if you accept the default
    serialized form, the class’s private and package-private instance fields become part of its exported API, and the
    practice of minimizing access to fields (Item 15) loses its effectiveness as a tool for information hiding

!!
    If you opt to make a class serializable, you should carefully design a high-quality serialized form that
    you’re willing to live with for the long haul (Items 87, 90).

    A simple example of the constraints on evolution imposed by serializability concerns stream unique identifiers,
    more commonly known as serial version UIDs. Every serializable class has a unique identification number associated with
    it. If you do not specify this number by declaring a static final long field named serialVersionUID, the system
    automatically generates it at runtime by applying a cryptographic hash function (SHA-1) to the structure of the
    class. This value is  affected by the names of the class, the interfaces it implements, and most of its
    members, including synthetic members generated by the compiler. If you change
    any of these things, for example, by adding a convenience method, the generated serial version UID changes. If you
    fail to declare a serial version UID, compatibility will be broken, resulting in an InvalidClassException at runtime.

!!
    A second cost of implementing Serializable is that it increases the likelihood of bugs and security holes (Item 85).
    Relying on the default deserialization mechanism can easily leave objects open to invariant corruption and illegal
    access (Item 88).
!!
    A third cost of implementing Serializable is that it increases the testing burden associated with releasing a new
    version of a class.

    Classes designed for inheritance (Item 19) should rarely implement Serializable, and interfaces should rarely extend
    it. Violating this rule places a substantial burden on anyone who extends the class or implements the interface.
    There are times when it is appropriate to violate the rule.

    To summarize, the ease of implementing Serializable is specious. Unless a class is to be used only in a protected
    environment where versions will never have to interoperate and servers will never be exposed to untrusted data,
    implementing Serializable is a serious commitment that should be made with great care. Extra
    caution is warranted if a class permits inheritance.


Item 87 - Consider using a custom serialized form

    Do not accept the default serialized form without first considering whether it is appropriate

    The default serialized form is likely to be appropriate if an object’s physical representation is identical to its
    logical content. For example, the default  serialized form would be reasonable for the following class, which
    simplistically represents a person’s name:

        // Good candidate for default serialized form
        public class Name implements Serializable {
            /**
            * Last name. Must be non-null.
            * @serial
            */
            private final String lastName;
            /**
            * First name. Must be non-null.
            * @serial
            */
            private final String firstName;
            /**
            * Middle name, or null if there is none.
            * @serial
            */
            private final String middleName;
            ... // Remainder omitted
        }

    Even if you decide that the default serialized form is appropriate, you often must provide a readObject method to
    ensure invariants and security. In the case of Name, the readObject method must ensure that the fields lastName
    and firstName are non-null. This issue is discussed at length in Items 88 and 90
    Note that there are documentation comments on the lastName, firstName, and middleName fields, even though they are
    private. That is because these private fields define a public API, which is the serialized form of the class, and
    this public API must be documented.
!!!!
    Using the default serialized form when an object’s physical representation differs substantially from its logical
    data content has four disadvantages:
        • It permanently ties the exported API to the current internal representation. In the above example, the private
            StringList.Entry class becomes part of the public API. If the representation is changed in a future release, the
            StringList class will still need to accept the linked list representation on input and generate it on output.
            The class will never be rid of all the code dealing with linked list entries, even if it doesn’t use them anymore.
        • It can consume excessive space. In the above example, the serialized form  unnecessarily represents each entry in
            the linked list and all the links. These entries and links are mere implementation details, not worthy of
            inclusion in the serialized form. Because the serialized form is excessively large, writing it
            to disk or sending it across the network will be excessively slow.
        • It can consume excessive time. The serialization logic has no knowledge of the topology of the object graph,
            so it must go through an expensive graph traversal. In the example above, it would be sufficient simply to
            follow the next references.
        • It can cause stack overflows. The default serialization procedure performs a recursive traversal of the object
            graph, which can cause stack overflows even for moderately sized object graphs. Serializing a StringList
            instance with 1,000–1,800 elements generates a StackOverflowError on my machine.
            Surprisingly, the minimum list size for which serialization causes a stack
            overflow varies from run to run (on my machine). The minimum list size that
            exhibits this problem may depend on the platform implementation and
            command-line flags; some implementations may not have this problem at all.

    Whether or not you use the default serialized form, you must impose any synchronization on object serialization that
    you would impose on any other method that reads the entire state of the object. So, for example, if you have a
    thread-safe object (Item 82) that achieves its thread safety by synchronizing every method and you elect to use the
    default serialized form, use the following writeObject method:
        // writeObject for synchronized class with default serialized form
        private synchronized void writeObject(ObjectOutputStream s) throws IOException {
            s.defaultWriteObject();
        }
!!
    Regardless of what serialized form you choose, declare an explicit serial version UID in every serializable class
    you write. This eliminates the serial version UID as a potential source of incompatibility (Item 86). There is also a
    small performance benefit. If no serial version UID is provided, an expensive computation is performed to generate
    one at runtime.
    Do not change the serial version UID unless you want to break compatibility with all existing serialized instances of
    a class.

    To summarize, if you have decided that a class should be serializable (Item 86), think hard about what the serialized
    form should be. Use the default serialized form only if it is a reasonable description of the logical state of the
    object; otherwise design a custom serialized form that aptly describes the object. You should allocate as much time
    to designing the serialized form of a class as you allocate to designing an exported method (Item 51). Just as you can’t
    eliminate exported methods from future versions, you can’t eliminate fields from the serialized form; they must be
    preserved forever to ensure serialization compatibility. Choosing the wrong serialized form can have a permanent, negative
    impact on the complexity and performance of a class.


Item 88 - Write readObject methods defensively

!!!
    The problem is that the readObject method is effectively another public constructor, and it demands all of the same
    care as any other constructor. Just as a constructor must check its arguments for validity (Item 49) and make defensive
    copies of parameters where appropriate (Item 50), so must a readObject method.
    If a readObject method fails to do either of these things, it is a relatively simple matter for an attacker to violate
    the class’s invariants.

    Loosely speaking, readObject is a constructor that takes a byte stream as its sole parameter. In normal use, the
    byte stream is generated by serializing a normally constructed instance. The problem arises when readObject is presented
    with a byte stream that is artificially constructed to generate an object that violates the invariants of its class.
    Such a byte stream can be used to create an impossible object, which could not have been created using a normal constructor.
!!
    To fix this problem, provide a readObject method for Period that calls defaultReadObject and then checks the validity
    of the deserialized object. If the validity check fails, the readObject method throws InvalidObjectException,
    preventing the deserialization from completing:

        // readObject method with validity checking - insufficient!
        private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException {
            s.defaultReadObject();
            // Check that our invariants are satisfied
            if (start.compareTo(end) > 0)
                throw new InvalidObjectException(start +" after "+ end);
        }
!!!!
    The source of the problem is that Period’s readObject method is not doing enough defensive copying. When an object
    is deserialized, it is critical to defensively copy any field containing an object reference that a client must
    not possess. Therefore, every serializable immutable class containing private mutable components must defensively
    copy these components in its readObject method. The following readObject method suffices to ensure Period’s invariants
    and to maintain its immutability

        // readObject method with defensive copying and validity checking
        private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException {
            s.defaultReadObject();

            // Defensively copy our mutable components
            start = new Date(start.getTime());
            end = new Date(end.getTime());

            // Check that our invariants are satisfied
            if (start.compareTo(end) > 0)
                throw new InvalidObjectException(start +" after "+ end);
        }
    Note also that defensive copying is not possible for final fields. To use the readObject method, we must make the
    start and end fields non final. This is unfortunate, but it is the lesser of two evils

    Here is a simple litmus test for deciding whether the default readObject method is acceptable for a class: would
    you feel comfortable adding a public constructor that took as parameters the values for each nontransient field in
    the object and stored the values in the fields with no validation whatsoever? If not, you must
    provide a readObject method, and it must perform all the validity checking and defensive copying that would be
    required of a constructor. Alternatively, you can use the serialization proxy pattern (Item 90). This pattern is
    highly recommended because it takes much of the effort out of safe deserialization.

    To summarize, anytime you write a readObject method, adopt the mind-set that you are writing a public constructor
    that must produce a valid instance regardless of what byte stream it is given. Do not assume that the byte stream
    represents an actual serialized instance. While the examples in this item concern a class that
    uses the default serialized form, all of the issues that were raised apply equally to classes with custom serialized
    forms. Here, in summary form, are the guidelines for writing a readObject method:
        • For classes with object reference fields that must remain private, defensively copy each object in such a
            field. Mutable components of immutable classes fall into this category.
        • Check any invariants and throw an InvalidObjectException if a check fails. The checks should follow any defensive copying.
        • If an entire object graph must be validated after it is deserialized, use the ObjectInputValidation interface
            (not discussed in this book).
        • Do not invoke any overridable methods in the class, directly or indirectly.


Item 89 - For instance control, prefer enum types to readResolve

    Item 3 describes the Singleton pattern and gives the following example of a singleton class. This class restricts
    access to its constructor to ensure that only a single instance is ever created:
        public class Elvis {
            public static final Elvis INSTANCE = new Elvis();
            private Elvis() { ... }
            public void leaveTheBuilding() { ... }
        }
    As noted in Item 3, this class would no longer be a singleton if the words "implements Serializable" were added to
    its declaration

    If the Elvis class is made to implement Serializable, the following readResolve method suffices to guarantee the
    singleton property:
        // readResolve for instance control - you can do better!
        private Object readResolve() {
            // Return the one true Elvis and let the garbage collector take care of the Elvis impersonator.
            return INSTANCE;
        }
!!!
    This method ignores the deserialized object, returning the distinguished Elvis instance that was created when the
    class was initialized. Therefore, the serialized form of an Elvis instance need not contain any real data; all
    instance fields should be declared transient. In fact, if you depend on readResolve for instance control, all
    instance fields with object reference types must be declared transient. Otherwise, it is possible for a determined
    attacker to secure a reference to the deserialized object before its readResolve method is run, using a
    technique that is somewhat similar to the MutablePeriod attack in Item 88.

        (BOOK Explains how such an attack would be performed)

    You could fix the problem by declaring the favoriteSongs field transient, but you’re better off fixing it by
    making Elvis a single-element enum type (Item 3). As demonstrated by the ElvisStealer attack, using a readResolve
    method to prevent a “temporary” deserialized instance from being accessed by an attacker is fragile and demands great care

    To summarize, use enum types to enforce instance control invariants wherever possible. If this is not possible and you
    need a class to be both serializable and instance-controlled, you must provide a readResolve method and ensure that all
    of the class’s instance fields are either primitive or transient.


Item 90 - Consider serialization proxies instead of serialized instances

    As mentioned in Items 85 and 86 and discussed throughout this chapter, the decision to implement Serializable increases
    the likelihood of bugs and security problems as it allows instances to be created using an extralinguistic mechanism
    in place of ordinary constructors. There is, however, a technique that greatly reduces these risks.
!!  This technique is known as the serialization proxy pattern.

    The serialization proxy pattern is reasonably straightforward. First, design a private static nested class that
    concisely represents the logical state of an instance of the enclosing class. This nested class is known as the
    serialization proxy of the enclosing class. It should have a single constructor, whose parameter type is the
    enclosing class. This constructor merely copies the data from its argument: it need not do any consistency checking
    or defensive copying. By design, the default serialized form of the serialization proxy is the perfect serialized
    form of the enclosing class. Both the enclosing class and its serialization proxy must be declared to implement
    Serializable

!!!
    Like the defensive copying approach (page 357), the serialization proxy approach stops the bogus byte-stream
    attack (page 354) and the internal field theft attack (page 356) dead in their tracks. Unlike the two previous
    approaches, this one allows the fields of Period to be final, which is required in order for the
    Period class to be truly immutable (Item 17).

    There is another way in which the serialization proxy pattern is more powerful
    than defensive copying in readObject. The serialization proxy pattern allows the
    deserialized instance to have a different class from the originally serialized
    instance. You might not think that this would be useful in practice, but it is.

    Consider the case of EnumSet (Item 36). This class has no public constructors,
    only static factories. From the client’s perspective, they return EnumSet instances,
    but in the current OpenJDK implementation, they return one of two subclasses,
    depending on the size of the underlying enum type. If the underlying enum type
    has sixty-four or fewer elements, the static factories return a RegularEnumSet;
    otherwise, they return a JumboEnumSet.
        (code is in the book)

    The serialization proxy pattern has two limitations. It is not compatible with classes that are extendable by their
    users (Item 19). Also, it is not compatible with some classes whose object graphs contain circularities: if you
    attempt to invoke a method on such an object from within its serialization proxy’s readResolve
    method, you’ll get a ClassCastException because you don’t have the object yet, only its serialization proxy.

    In summary, consider the serialization proxy pattern whenever you find yourself having to write a readObject or
    writeObject method on a class that is not extendable by its clients. This pattern is perhaps the easiest way to robustly
    serialize objects with nontrivial invariants.


TODO    every programmer should be familiar with  the basics of java.lang, java.util, and java.io, and their subpackages
        Several libraries bear special mention. The collections framework and the streams library (Items 45–48) should be
        part of every programmer’s basic toolkit, as should parts of the concurrency utilities in java.util.concurrent.
        (GO through these)
TODO
    Make a list of all items, sort of a TLDR, and add also the summary paragraf or something else important for that item
    the point would be to have that easy access list, when you need to come back to some issues

https://stackoverflow.com/questions/11823773/understanding-the-concept-behind-service-provider-framework-like-jdbc-using-the
https://stackoverflow.com/questions/20772869/what-is-the-use-of-linkedhashmap-removeeldestentry

https://www.baeldung.com/introduction-to-autovalue      Google’s open source AutoValue framework - used to generated hashCode equals and other code
https://chromium.googlesource.com/external/github.com/google/auto/+/auto-value-1.6.2/value/userguide/index.md

Regarding item 24 - https://www.baeldung.com/java-anonymous-classes
                    https://www.baeldung.com/java-nested-classes

Regarding item 78 - https://stackoverflow.com/questions/517532/writing-long-and-double-is-not-atomic-in-java
    "It's not atomic because it's a multiple-step operation at the machine code level. That is, longs and doubles are
     longer than the processor's word length."